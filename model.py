"""
model.py

Single-file "model" module for the 5-file DAPS refactor.

This file preserves *full* upstream DAPS model functionality while keeping the
rest of the refactor in only five Python files:

  - main.py              (sampling + CLI orchestration)
  - forward_operators.py (forward operators incl. BKSE nonlinear blur)
  - data.py              (dataset/dataloader)
  - model.py             (this file: DDPM + LDM + Stable Diffusion)
  - misc.py              (schedulers/PF-ODE/MCMC/evaluator/utils)

Key design points:
- No duplicated scheduler code here: Stable Diffusion uses VPScheduler from misc.py.
- Upstream LDM configs reference dotted targets like "model.ldm...". To keep those
  configs working without a package directory, we embed the upstream `model/`
  subtree (ddpm/ldm/edm/precond) as *in-memory submodules* served by a meta-path
  importer.
- The *top* of the file is normal readable code (registry + model wrappers).
  The embedded source table is appended at the end.

Expected external deps match upstream requirements.txt: torch, numpy, omegaconf,
pytorch_lightning, einops, diffusers/transformers, etc.

"""


from __future__ import annotations

import importlib
import importlib.abc
import importlib.machinery
import os
import sys
import warnings
from abc import abstractmethod
from typing import Any, Dict, Optional

import torch
import torch.nn as nn
from torch.nn import functional as F

# Scheduler lives in misc.py (no duplication here).
from misc import VPScheduler


# -----------------------------------------------------------------------------
# Embedded submodule importer
# -----------------------------------------------------------------------------

class _EmbeddedModuleLoader(importlib.abc.Loader):
    def __init__(self, fullname: str, source: str, is_pkg: bool):
        self.fullname = fullname
        self.source = source
        self.is_pkg = is_pkg

    def create_module(self, spec):  # noqa: D401
        # Default module creation semantics.
        return None

    def exec_module(self, module) -> None:
        module.__file__ = f"<embedded:{self.fullname}>"
        module.__loader__ = self
        # Mark packages so relative imports work.
        if self.is_pkg:
            module.__path__ = []  # type: ignore[attr-defined]
        pkg = self.fullname.rpartition(".")[0]
        module.__package__ = pkg if pkg else self.fullname
        code = compile(self.source, module.__file__, "exec")
        exec(code, module.__dict__)  # noqa: S102


class _EmbeddedModuleFinder(importlib.abc.MetaPathFinder):
    def __init__(self, sources: Dict[str, str]):
        self._sources = sources

    def find_spec(self, fullname: str, path=None, target=None):
        if fullname not in self._sources:
            return None
        source = self._sources[fullname]
        # Package if any child module exists.
        is_pkg = any(k.startswith(fullname + ".") for k in self._sources.keys())
        loader = _EmbeddedModuleLoader(fullname, source, is_pkg=is_pkg)
        spec = importlib.machinery.ModuleSpec(fullname, loader, is_package=is_pkg)
        if is_pkg:
            spec.submodule_search_locations = []
        return spec


def _ensure_model_is_package() -> None:
    """
    Make this single file behave like a package so that imports like:
        import model.ldm.models.diffusion.ddpm
    work.
    """
    m = sys.modules[__name__]
    if not hasattr(m, "__path__"):
        m.__path__ = []  # type: ignore[attr-defined]
    spec = getattr(m, "__spec__", None)
    if spec is not None and getattr(spec, "submodule_search_locations", None) is None:
        spec.submodule_search_locations = []  # type: ignore[attr-defined]


def _install_embedded_importer() -> None:
    _ensure_model_is_package()
    for f in sys.meta_path:
        if isinstance(f, _EmbeddedModuleFinder):
            return
    sys.meta_path.insert(0, _EmbeddedModuleFinder(_EMBEDDED_SOURCES))


# -----------------------------------------------------------------------------
# Model registry (same API as upstream `model/__init__.py`)
# -----------------------------------------------------------------------------

__MODEL__: Dict[str, Any] = {}


def register_model(name: str):
    def wrapper(cls):
        if name in __MODEL__ and __MODEL__[name] is not cls:
            warnings.warn(f"Model '{name}' is already registered.", UserWarning)
        __MODEL__[name] = cls
        cls.name = name
        return cls
    return wrapper


def get_model(name: str, **kwargs):
    _install_embedded_importer()
    if name not in __MODEL__:
        raise NameError(f"Model '{name}' is not registered.")
    return __MODEL__[name](**kwargs)


# -----------------------------------------------------------------------------
# Base interfaces (verbatim from upstream, with typing)
# -----------------------------------------------------------------------------

class DiffusionModel(nn.Module):
    """
    Base Diffusion Model class.
    Requires overriding either 'score' or 'tweedie' method.
    """
    def __init__(self):
        super().__init__()
        if (self.score.__func__ is DiffusionModel.score and
            self.tweedie.__func__ is DiffusionModel.tweedie):
            raise NotImplementedError("Either 'score' or 'tweedie' method must be overridden.")

    def score(self, x, sigma):
        d = self.tweedie(x, sigma)
        return (d - x) / sigma ** 2

    def tweedie(self, x, sigma):
        return x + self.score(x, sigma) * sigma ** 2

    def get_in_shape(self):
        raise NotImplementedError


class LatentDiffusionModel(nn.Module):
    """
    Base Latent Diffusion Model class.
    Requires overriding either 'score' or 'tweedie' method and 'encode', 'decode' methods.
    """
    def __init__(self):
        super().__init__()
        if (self.score.__func__ is LatentDiffusionModel.score and
            self.tweedie.__func__ is LatentDiffusionModel.tweedie):
            raise NotImplementedError("Either 'score' or 'tweedie' method must be overridden.")

    @abstractmethod
    def encode(self, x0):
        raise NotImplementedError

    @abstractmethod
    def decode(self, z0):
        raise NotImplementedError

    def score(self, z, sigma):
        d = self.tweedie(z, sigma)
        return (d - z) / sigma ** 2

    def tweedie(self, z, sigma):
        return z + self.score(z, sigma) * sigma ** 2

    def get_in_shape(self):
        raise NotImplementedError


# -----------------------------------------------------------------------------
# LDM config instantiation helpers (upstream behavior)
# -----------------------------------------------------------------------------

def get_obj_from_str(string: str, reload: bool = False):
    module, cls = string.rsplit(".", 1)
    if reload:
        module_imp = importlib.import_module(module)
        importlib.reload(module_imp)
    return getattr(importlib.import_module(module, package=None), cls)


def instantiate_from_config(config: Any):
    if "target" not in config:
        if config == "__is_first_stage__":
            return None
        if config == "__is_unconditional__":
            return None
        raise KeyError("Expected key `target` to instantiate.")
    return get_obj_from_str(config["target"])(**config.get("params", dict()))


def load_model_from_config(config: Any, ckpt: str, device: str = "cuda", train: bool = False):
    """
    Load a CompVis-style LDM from an OmegaConf/dict config and a checkpoint path.
    Matches upstream DAPS behavior, but allows choosing `device`.
    """
    from omegaconf import OmegaConf
    if isinstance(config, dict):
        config = OmegaConf.create(config)

    print(f"Loading model from {ckpt}")
    pl_sd = torch.load(ckpt, map_location="cpu")
    sd = pl_sd["state_dict"] if isinstance(pl_sd, dict) and "state_dict" in pl_sd else pl_sd

    model = instantiate_from_config(config.model)
    model.load_state_dict(sd, strict=False)

    model.to(device)
    model.train() if train else model.eval()
    return model


# -----------------------------------------------------------------------------
# Concrete models (wrappers)
# -----------------------------------------------------------------------------

@register_model(name="ddpm")
class DDPM(DiffusionModel):
    """
    Pixel DDPM wrapper (upstream: model.DDPM).
    """
    def __init__(self, model_config: Dict[str, Any], device: str = "cuda", requires_grad: bool = False):
        super().__init__()
        # Create the network from embedded ddpm modules.
        from model.ddpm.unet import create_model  # type: ignore
        from model.precond import VPPrecond  # type: ignore

        self.model = VPPrecond(
            model=create_model(**model_config),
            learn_sigma=model_config["learn_sigma"],
            conditional=model_config["class_cond"],
        ).to(device)
        self.model.eval()
        self.model.requires_grad_(requires_grad)
        self.image_size = model_config["image_size"]

    def tweedie(self, x, sigma):
        return self.model(x, torch.as_tensor(sigma).to(x.device))

    def get_in_shape(self):
        return (3, self.image_size, self.image_size)


@register_model(name="ldm")
class LDM(LatentDiffusionModel):
    """
    Latent Diffusion Model wrapper (upstream: model.LDM).
    """
    def __init__(self, ldm_config: Any, diffusion_path: str, device: str = "cuda", requires_grad: bool = False):
        super().__init__()
        from omegaconf import OmegaConf
        from model.precond import VPPrecond, LatentDMWrapper  # type: ignore

        if isinstance(ldm_config, dict):
            ldm_config = OmegaConf.create(ldm_config)

        self.net = LatentDMWrapper(load_model_from_config(ldm_config, diffusion_path, device=device)).to(device)
        self.is_conditional = not (ldm_config.model.params.cond_stage_config == "__is_unconditional__")
        label_dim = 1 if self.is_conditional else 0
        self.model = VPPrecond(label_dim=label_dim, model=self.net, conditional=self.is_conditional).to(device)

        self.image_size = ldm_config.model.params.image_size
        self.latent_channels = ldm_config.model.params.first_stage_config.params.embed_dim

        self.model.eval()
        self.model.requires_grad_(requires_grad)

    def encode(self, x0):
        return self.model.model.encode(x0)

    def decode(self, z0):
        return self.model.model.decode(z0)

    def tweedie(self, x, sigma):
        class_labels = None
        if self.is_conditional:
            # For ImageNet conditional checkpoint; upstream uses class 1000 placeholder.
            class_labels = self.net.get_condition(torch.as_tensor([1000]).to(x.device))
        return self.model(x, torch.as_tensor(sigma).to(x.device), class_labels=class_labels)

    def get_in_shape(self):
        return (self.latent_channels, self.image_size, self.image_size)


@register_model(name="sdm")
class StableDiffusionModel(LatentDiffusionModel):
    """
    Stable Diffusion wrapper (upstream: model.StableDiffusionModel), using diffusers.

    Notes:
    - Requires diffusers/transformers/safetensors installed.
    - Uses fixed prompt classifier-free guidance (CFG).
    """
    def __init__(
        self,
        model_id: str = "sd2-community/stable-diffusion-2-1",
        inner_resolution: int = 768,
        target_resolution: int = 256,
        guidance_scale: float = 7.5,
        prompt: str = "a natural looking human face",
        device: str = "cuda",
        hf_home: str = "checkpoints/.cache/huggingface",
    ):
        super().__init__()
        try:
            from diffusers import StableDiffusionPipeline
        except Exception as e:  # noqa: BLE001
            raise ImportError("diffusers is required for StableDiffusionModel. Install requirements.txt.") from e

        os.environ.setdefault("HF_HOME", hf_home)
        pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)
        self.pipe = pipe.to(device)
        self.vae = self.pipe.vae
        self.guidance_scale = guidance_scale
        self.prompt = prompt
        self.device = device
        self.unet = self.pipe.unet
        self.latent_scale = self.pipe.vae.config.scaling_factor
        self.dtype = torch.float16
        self.resolution = inner_resolution
        self.target_resolution = target_resolution

        # scheduling (match upstream: cores.scheduler.VPScheduler -> misc.VPScheduler)
        scheduler = pipe.scheduler
        self.scheduler = VPScheduler(
            num_steps=scheduler.config.num_train_timesteps,
            beta_max=scheduler.config.beta_end * scheduler.config.num_train_timesteps,
            beta_min=scheduler.config.beta_start * scheduler.config.num_train_timesteps,
            epsilon=0,
            beta_type=scheduler.config.beta_schedule,
        )
        self.prediction_type = scheduler.config.prediction_type
        self.unet.requires_grad_(False)

    def get_noise_prediction(self, latent_model_input, model_output, sigma):
        alpha = (1 / (sigma ** 2 + 1))
        if self.prediction_type == "epsilon":
            noise_pred = model_output
        elif self.prediction_type == "v_prediction":
            noise_pred = alpha.sqrt() * model_output + (1 - alpha).sqrt() * latent_model_input
        else:
            raise NotImplementedError
        return noise_pred

    def encode(self, x0):
        source_dtype = x0.dtype
        x0 = x0.to(self.dtype)
        x0 = F.interpolate(x0, size=self.resolution, mode="bilinear", align_corners=False)
        latents = (self.vae.encode(x0).latent_dist.sample() * self.latent_scale).to(source_dtype)
        return latents

    def decode(self, z0):
        source_dtype = z0.dtype
        z0 = z0.to(self.dtype)
        x0 = self.vae.decode(z0 / self.latent_scale).sample.to(source_dtype)
        x0 = F.interpolate(x0, size=self.target_resolution, mode="bilinear", align_corners=False)
        return x0

    def tweedie(self, z, sigma, c: Optional[str] = None):
        if c is None:
            c = self.prompt
        source_dtype = z.dtype
        latent = z.to(self.dtype)

        sigma = torch.as_tensor(sigma, device=z.device, dtype=self.dtype).view(-1, *([1] * len(latent.shape[1:])))

        # preconditioning (match upstream)
        c_skip = 1
        c_out = -sigma
        c_in = 1 / (sigma ** 2 + 1).sqrt()
        c_noise = (self.scheduler.num_steps - 1) * self.scheduler.get_sigma_inv(sigma)

        # 1) encode prompt
        prompt_embeds, negative_prompt_embeds = self.pipe.encode_prompt(
            prompt=c,
            device=z.device,
            num_images_per_prompt=1,
            do_classifier_free_guidance=True,
        )
        # replicate for batch
        prompt_embeds = torch.cat([negative_prompt_embeds] * z.shape[0] + [prompt_embeds] * z.shape[0], dim=0)

        # 2) unet
        latent_model_input = torch.cat([latent] * 2) * c_in
        t_input = c_noise.flatten()
        model_output = self.unet(latent_model_input, t_input, encoder_hidden_states=prompt_embeds, return_dict=False)[0]
        noise_pred = self.get_noise_prediction(latent_model_input, model_output, sigma)

        # 3) CFG
        noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)
        noise_pred = noise_pred_uncond + self.guidance_scale * (noise_pred_text - noise_pred_uncond)

        denoised = c_skip * z + c_out * noise_pred.to(source_dtype)
        return denoised

    def get_in_shape(self):
        num_channels_latents = self.pipe.unet.config.in_channels
        latents = self.pipe.prepare_latents(
            1, num_channels_latents, self.resolution, self.resolution, self.dtype, self.device, None, None
        )
        return latents.shape[1:]

_EMBEDDED_SOURCES: Dict[str, str] = {
    'model.ddpm': '',
    'model.ddpm.fp16_util': '"""\nHelpers to train with 16-bit precision.\n"""\n\nimport numpy as np\nimport torch as th\nimport torch.nn as nn\nfrom torch._utils import _flatten_dense_tensors, _unflatten_dense_tensors\n\nINITIAL_LOG_LOSS_SCALE = 20.0\n\n\ndef convert_module_to_f16(l):\n    """\n    Convert primitive modules to float16.\n    """\n    if isinstance(l, (nn.Conv1d, nn.Conv2d, nn.Conv3d)):\n        l.weight.data = l.weight.data.half()\n        if l.bias is not None:\n            l.bias.data = l.bias.data.half()\n\n\ndef convert_module_to_f32(l):\n    """\n    Convert primitive modules to float32, undoing convert_module_to_f16().\n    """\n    if isinstance(l, (nn.Conv1d, nn.Conv2d, nn.Conv3d)):\n        l.weight.data = l.weight.data.float()\n        if l.bias is not None:\n            l.bias.data = l.bias.data.float()\n\n\ndef make_master_params(param_groups_and_shapes):\n    """\n    Copy model parameters into a (differently-shaped) list of full-precision\n    parameters.\n    """\n    master_params = []\n    for param_group, shape in param_groups_and_shapes:\n        master_param = nn.Parameter(\n            _flatten_dense_tensors(\n                [param.detach().float() for (_, param) in param_group]\n            ).view(shape)\n        )\n        master_param.requires_grad = True\n        master_params.append(master_param)\n    return master_params\n\n\ndef model_grads_to_master_grads(param_groups_and_shapes, master_params):\n    """\n    Copy the gradients from the model parameters into the master parameters\n    from make_master_params().\n    """\n    for master_param, (param_group, shape) in zip(\n        master_params, param_groups_and_shapes\n    ):\n        master_param.grad = _flatten_dense_tensors(\n            [param_grad_or_zeros(param) for (_, param) in param_group]\n        ).view(shape)\n\n\ndef master_params_to_model_params(param_groups_and_shapes, master_params):\n    """\n    Copy the master parameter data back into the model parameters.\n    """\n    # Without copying to a list, if a generator is passed, this will\n    # silently not copy any parameters.\n    for master_param, (param_group, _) in zip(master_params, param_groups_and_shapes):\n        for (_, param), unflat_master_param in zip(\n            param_group, unflatten_master_params(param_group, master_param.view(-1))\n        ):\n            param.detach().copy_(unflat_master_param)\n\n\ndef unflatten_master_params(param_group, master_param):\n    return _unflatten_dense_tensors(master_param, [param for (_, param) in param_group])\n\n\ndef get_param_groups_and_shapes(named_model_params):\n    named_model_params = list(named_model_params)\n    scalar_vector_named_params = (\n        [(n, p) for (n, p) in named_model_params if p.ndim <= 1],\n        (-1),\n    )\n    matrix_named_params = (\n        [(n, p) for (n, p) in named_model_params if p.ndim > 1],\n        (1, -1),\n    )\n    return [scalar_vector_named_params, matrix_named_params]\n\n\ndef master_params_to_state_dict(\n    model, param_groups_and_shapes, master_params, use_fp16\n):\n    if use_fp16:\n        state_dict = model.state_dict()\n        for master_param, (param_group, _) in zip(\n            master_params, param_groups_and_shapes\n        ):\n            for (name, _), unflat_master_param in zip(\n                param_group, unflatten_master_params(param_group, master_param.view(-1))\n            ):\n                assert name in state_dict\n                state_dict[name] = unflat_master_param\n    else:\n        state_dict = model.state_dict()\n        for i, (name, _value) in enumerate(model.named_parameters()):\n            assert name in state_dict\n            state_dict[name] = master_params[i]\n    return state_dict\n\n\ndef state_dict_to_master_params(model, state_dict, use_fp16):\n    if use_fp16:\n        named_model_params = [\n            (name, state_dict[name]) for name, _ in model.named_parameters()\n        ]\n        param_groups_and_shapes = get_param_groups_and_shapes(named_model_params)\n        master_params = make_master_params(param_groups_and_shapes)\n    else:\n        master_params = [state_dict[name] for name, _ in model.named_parameters()]\n    return master_params\n\n\ndef zero_master_grads(master_params):\n    for param in master_params:\n        param.grad = None\n\n\ndef zero_grad(model_params):\n    for param in model_params:\n        # Taken from https://pytorch.org/docs/stable/_modules/torch/optim/optimizer.html#Optimizer.add_param_group\n        if param.grad is not None:\n            param.grad.detach_()\n            param.grad.zero_()\n\n\ndef param_grad_or_zeros(param):\n    if param.grad is not None:\n        return param.grad.data.detach()\n    else:\n        return th.zeros_like(param)\n\n\nclass MixedPrecisionTrainer:\n    def __init__(\n        self,\n        *,\n        model,\n        use_fp16=False,\n        fp16_scale_growth=1e-3,\n        initial_lg_loss_scale=INITIAL_LOG_LOSS_SCALE,\n    ):\n        self.model = model\n        self.use_fp16 = use_fp16\n        self.fp16_scale_growth = fp16_scale_growth\n\n        self.model_params = list(self.model.parameters())\n        self.master_params = self.model_params\n        self.param_groups_and_shapes = None\n        self.lg_loss_scale = initial_lg_loss_scale\n\n        if self.use_fp16:\n            self.param_groups_and_shapes = get_param_groups_and_shapes(\n                self.model.named_parameters()\n            )\n            self.master_params = make_master_params(self.param_groups_and_shapes)\n            self.model.convert_to_fp16()\n\n    def zero_grad(self):\n        zero_grad(self.model_params)\n\n    def backward(self, loss: th.Tensor):\n        if self.use_fp16:\n            loss_scale = 2 ** self.lg_loss_scale\n            (loss * loss_scale).backward()\n        else:\n            loss.backward()\n\n    def optimize(self, opt: th.optim.Optimizer):\n        if self.use_fp16:\n            return self._optimize_fp16(opt)\n        else:\n            return self._optimize_normal(opt)\n\n    def _optimize_fp16(self, opt: th.optim.Optimizer):\n        logger.logkv_mean("lg_loss_scale", self.lg_loss_scale)\n        model_grads_to_master_grads(self.param_groups_and_shapes, self.master_params)\n        grad_norm, param_norm = self._compute_norms(grad_scale=2 ** self.lg_loss_scale)\n        if check_overflow(grad_norm):\n            self.lg_loss_scale -= 1\n            logger.log(f"Found NaN, decreased lg_loss_scale to {self.lg_loss_scale}")\n            zero_master_grads(self.master_params)\n            return False\n\n        logger.logkv_mean("grad_norm", grad_norm)\n        logger.logkv_mean("param_norm", param_norm)\n\n        self.master_params[0].grad.mul_(1.0 / (2 ** self.lg_loss_scale))\n        opt.step()\n        zero_master_grads(self.master_params)\n        master_params_to_model_params(self.param_groups_and_shapes, self.master_params)\n        self.lg_loss_scale += self.fp16_scale_growth\n        return True\n\n    def _optimize_normal(self, opt: th.optim.Optimizer):\n        grad_norm, param_norm = self._compute_norms()\n        logger.logkv_mean("grad_norm", grad_norm)\n        logger.logkv_mean("param_norm", param_norm)\n        opt.step()\n        return True\n\n    def _compute_norms(self, grad_scale=1.0):\n        grad_norm = 0.0\n        param_norm = 0.0\n        for p in self.master_params:\n            with th.no_grad():\n                param_norm += th.norm(p, p=2, dtype=th.float32).item() ** 2\n                if p.grad is not None:\n                    grad_norm += th.norm(p.grad, p=2, dtype=th.float32).item() ** 2\n        return np.sqrt(grad_norm) / grad_scale, np.sqrt(param_norm)\n\n    def master_params_to_state_dict(self, master_params):\n        return master_params_to_state_dict(\n            self.model, self.param_groups_and_shapes, master_params, self.use_fp16\n        )\n\n    def state_dict_to_master_params(self, state_dict):\n        return state_dict_to_master_params(self.model, state_dict, self.use_fp16)\n\n\ndef check_overflow(value):\n    return (value == float("inf")) or (value == -float("inf")) or (value != value)\n',
    'model.ddpm.nn': '"""\nVarious utilities for neural networks.\n"""\n\nimport math\n\nimport torch as th\nimport torch.nn as nn\n\n\n# PyTorch 1.7 has SiLU, but we support PyTorch 1.5.\nclass SiLU(nn.Module):\n    def forward(self, x):\n        return x * th.sigmoid(x)\n\n\nclass GroupNorm32(nn.GroupNorm):\n    def forward(self, x):\n        return super().forward(x.float()).type(x.dtype)\n\n\ndef conv_nd(dims, *args, **kwargs):\n    """\n    Create a 1D, 2D, or 3D convolution module.\n    """\n    if dims == 1:\n        return nn.Conv1d(*args, **kwargs)\n    elif dims == 2:\n        return nn.Conv2d(*args, **kwargs)\n    elif dims == 3:\n        return nn.Conv3d(*args, **kwargs)\n    raise ValueError(f"unsupported dimensions: {dims}")\n\n\ndef linear(*args, **kwargs):\n    """\n    Create a linear module.\n    """\n    return nn.Linear(*args, **kwargs)\n\n\ndef avg_pool_nd(dims, *args, **kwargs):\n    """\n    Create a 1D, 2D, or 3D average pooling module.\n    """\n    if dims == 1:\n        return nn.AvgPool1d(*args, **kwargs)\n    elif dims == 2:\n        return nn.AvgPool2d(*args, **kwargs)\n    elif dims == 3:\n        return nn.AvgPool3d(*args, **kwargs)\n    raise ValueError(f"unsupported dimensions: {dims}")\n\n\ndef update_ema(target_params, source_params, rate=0.99):\n    """\n    Update target parameters to be closer to those of source parameters using\n    an exponential moving average.\n\n    :param target_params: the target parameter sequence.\n    :param source_params: the source parameter sequence.\n    :param rate: the EMA rate (closer to 1 means slower).\n    """\n    for targ, src in zip(target_params, source_params):\n        targ.detach().mul_(rate).add_(src, alpha=1 - rate)\n\n\ndef zero_module(module):\n    """\n    Zero out the parameters of a module and return it.\n    """\n    for p in module.parameters():\n        p.detach().zero_()\n    return module\n\n\ndef scale_module(module, scale):\n    """\n    Scale the parameters of a module and return it.\n    """\n    for p in module.parameters():\n        p.detach().mul_(scale)\n    return module\n\n\ndef mean_flat(tensor):\n    """\n    Take the mean over all non-batch dimensions.\n    """\n    return tensor.mean(dim=list(range(1, len(tensor.shape))))\n\n\ndef normalization(channels):\n    """\n    Make a standard normalization layer.\n\n    :param channels: number of input channels.\n    :return: an nn.Module for normalization.\n    """\n    return GroupNorm32(32, channels)\n\n\ndef timestep_embedding(timesteps, dim, max_period=10000):\n    """\n    Create sinusoidal timestep embeddings.\n\n    :param timesteps: a 1-D Tensor of N indices, one per batch element.\n                      These may be fractional.\n    :param dim: the dimension of the output.\n    :param max_period: controls the minimum frequency of the embeddings.\n    :return: an [N x dim] Tensor of positional embeddings.\n    """\n    half = dim // 2\n    freqs = th.exp(\n        -math.log(max_period) * th.arange(start=0, end=half, dtype=th.float32) / half\n    ).to(device=timesteps.device)\n    args = timesteps[:, None].float() * freqs[None]\n    embedding = th.cat([th.cos(args), th.sin(args)], dim=-1)\n    if dim % 2:\n        embedding = th.cat([embedding, th.zeros_like(embedding[:, :1])], dim=-1)\n    return embedding\n\n\ndef checkpoint(func, inputs, params, flag):\n    """\n    Gradient checkpointing helper.\n\n    NOTE: This repository is arranged for *sampling/inference*. CLAMP/LatentCLAMP\n    rely on torch.func (functorch) transforms (vjp/jvp). Custom autograd.Function\n    checkpoint implementations are not compatible with these transforms unless\n    they implement `setup_context`. The original guided-diffusion checkpoint\n    helper therefore breaks under torch.func.vjp/jvp.\n\n    For simplicity and robustness we DISABLE checkpointing here and always run\n    the function normally. This has no effect on correctness for inference.\n    """\n    return func(*inputs)\n\n\nclass CheckpointFunction(th.autograd.Function):\n    @staticmethod\n    def forward(ctx, run_function, length, *args):\n        ctx.run_function = run_function\n        ctx.input_tensors = list(args[:length])\n        ctx.input_params = list(args[length:])\n        with th.no_grad():\n            output_tensors = ctx.run_function(*ctx.input_tensors)\n        return output_tensors\n\n    @staticmethod\n    def backward(ctx, *output_grads):\n        ctx.input_tensors = [x.detach().requires_grad_(True) for x in ctx.input_tensors]\n        with th.enable_grad():\n            # Fixes a bug where the first op in run_function modifies the\n            # Tensor storage in place, which is not allowed for detach()\'d\n            # Tensors.\n            shallow_copies = [x.view_as(x) for x in ctx.input_tensors]\n            output_tensors = ctx.run_function(*shallow_copies)\n        input_grads = th.autograd.grad(\n            output_tensors,\n            ctx.input_tensors + ctx.input_params,\n            output_grads,\n            allow_unused=True,\n        )\n        # NOTE: Do NOT delete ctx.input_tensors/params.\n        # CLAMP/torch.func.vjp may call backward multiple times on a retained graph.\n        return (None, None) + input_grads\n',
    'model.ddpm.unet': 'from abc import abstractmethod\n\nimport math\n\nimport numpy as np\nimport torch as th\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport functools\n\nfrom .fp16_util import convert_module_to_f16, convert_module_to_f32\nfrom .nn import (\n    checkpoint,\n    conv_nd,\n    linear,\n    avg_pool_nd,\n    zero_module,\n    normalization,\n    timestep_embedding,\n)\n\n\nNUM_CLASSES = 1000\n\ndef create_model(\n    image_size,\n    num_channels,\n    num_res_blocks,\n    channel_mult="",\n    learn_sigma=False,\n    class_cond=False,\n    use_checkpoint=False,\n    attention_resolutions="16",\n    num_heads=1,\n    num_head_channels=-1,\n    num_heads_upsample=-1,\n    use_scale_shift_norm=False,\n    dropout=0,\n    resblock_updown=False,\n    use_fp16=False,\n    use_new_attention_order=False,\n    model_path=\'\',\n    grayscale=False,\n):\n    if channel_mult == "":\n        if image_size == 512:\n            channel_mult = (0.5, 1, 1, 2, 2, 4, 4)\n        elif image_size == 256:\n            channel_mult = (1, 1, 2, 2, 4, 4)\n        elif image_size == 128:\n            channel_mult = (1, 1, 2, 3, 4)\n        elif image_size == 64:\n            channel_mult = (1, 2, 3, 4)\n        else:\n            raise ValueError(f"unsupported image size: {image_size}")\n    else:\n        channel_mult = tuple(int(ch_mult) for ch_mult in channel_mult.split(","))\n\n    attention_ds = []\n    if isinstance(attention_resolutions, int):\n        attention_ds.append(image_size // attention_resolutions)\n    elif isinstance(attention_resolutions, str):\n        for res in attention_resolutions.split(","):\n            attention_ds.append(image_size // int(res))\n    else:\n        raise NotImplementedError\n\n    in_channels = 1 if grayscale else 3\n    out_channels = 2 * in_channels if learn_sigma else in_channels\n\n    model= UNetModel(\n        image_size=image_size,\n        in_channels=in_channels,\n        model_channels=num_channels,\n        out_channels=out_channels,\n        num_res_blocks=num_res_blocks,\n        attention_resolutions=tuple(attention_ds),\n        dropout=dropout,\n        channel_mult=channel_mult,\n        num_classes=(NUM_CLASSES if class_cond else None),\n        use_checkpoint=use_checkpoint,\n        use_fp16=use_fp16,\n        num_heads=num_heads,\n        num_head_channels=num_head_channels,\n        num_heads_upsample=num_heads_upsample,\n        use_scale_shift_norm=use_scale_shift_norm,\n        resblock_updown=resblock_updown,\n        use_new_attention_order=use_new_attention_order,\n    )\n\n    try:\n        model.load_state_dict(th.load(model_path, map_location=\'cpu\'))\n    except Exception as e:\n        print(f"Got exception: {e} / Randomly initialize")\n    return model\n\nclass AttentionPool2d(nn.Module):\n    """\n    Adapted from CLIP: https://github.com/openai/CLIP/blob/main/clip/model.py\n    """\n\n    def __init__(\n        self,\n        spacial_dim: int,\n        embed_dim: int,\n        num_heads_channels: int,\n        output_dim: int = None,\n    ):\n        super().__init__()\n        self.positional_embedding = nn.Parameter(\n            th.randn(embed_dim, spacial_dim ** 2 + 1) / embed_dim ** 0.5\n        )\n        self.qkv_proj = conv_nd(1, embed_dim, 3 * embed_dim, 1)\n        self.c_proj = conv_nd(1, embed_dim, output_dim or embed_dim, 1)\n        self.num_heads = embed_dim // num_heads_channels\n        self.attention = QKVAttention(self.num_heads)\n\n    def forward(self, x):\n        b, c, *_spatial = x.shape\n        x = x.reshape(b, c, -1)  # NC(HW)\n        x = th.cat([x.mean(dim=-1, keepdim=True), x], dim=-1)  # NC(HW+1)\n        x = x + self.positional_embedding[None, :, :].to(x.dtype)  # NC(HW+1)\n        x = self.qkv_proj(x)\n        x = self.attention(x)\n        x = self.c_proj(x)\n        return x[:, :, 0]\n\n\nclass TimestepBlock(nn.Module):\n    """\n    Any module where forward() takes timestep embeddings as a second argument.\n    """\n\n    @abstractmethod\n    def forward(self, x, emb):\n        """\n        Apply the module to `x` given `emb` timestep embeddings.\n        """\n\n\nclass TimestepEmbedSequential(nn.Sequential, TimestepBlock):\n    """\n    A sequential module that passes timestep embeddings to the children that\n    support it as an extra input.\n    """\n\n    def forward(self, x, emb):\n        for layer in self:\n            if isinstance(layer, TimestepBlock):\n                x = layer(x, emb)\n            else:\n                x = layer(x)\n        return x\n\n\nclass Upsample(nn.Module):\n    """\n    An upsampling layer with an optional convolution.\n\n    :param channels: channels in the inputs and outputs.\n    :param use_conv: a bool determining if a convolution is applied.\n    :param dims: determines if the signal is 1D, 2D, or 3D. If 3D, then\n                 upsampling occurs in the inner-two dimensions.\n    """\n\n    def __init__(self, channels, use_conv, dims=2, out_channels=None):\n        super().__init__()\n        self.channels = channels\n        self.out_channels = out_channels or channels\n        self.use_conv = use_conv\n        self.dims = dims\n        if use_conv:\n            self.conv = conv_nd(dims, self.channels, self.out_channels, 3, padding=1)\n\n    def forward(self, x):\n        assert x.shape[1] == self.channels\n        if self.dims == 3:\n            x = F.interpolate(\n                x, (x.shape[2], x.shape[3] * 2, x.shape[4] * 2), mode="nearest"\n            )\n        else:\n            x = F.interpolate(x, scale_factor=2, mode="nearest")\n        if self.use_conv:\n            x = self.conv(x)\n        return x\n\n\nclass Downsample(nn.Module):\n    """\n    A downsampling layer with an optional convolution.\n\n    :param channels: channels in the inputs and outputs.\n    :param use_conv: a bool determining if a convolution is applied.\n    :param dims: determines if the signal is 1D, 2D, or 3D. If 3D, then\n                 downsampling occurs in the inner-two dimensions.\n    """\n\n    def __init__(self, channels, use_conv, dims=2, out_channels=None):\n        super().__init__()\n        self.channels = channels\n        self.out_channels = out_channels or channels\n        self.use_conv = use_conv\n        self.dims = dims\n        stride = 2 if dims != 3 else (1, 2, 2)\n        if use_conv:\n            self.op = conv_nd(\n                dims, self.channels, self.out_channels, 3, stride=stride, padding=1\n            )\n        else:\n            assert self.channels == self.out_channels\n            self.op = avg_pool_nd(dims, kernel_size=stride, stride=stride)\n\n    def forward(self, x):\n        assert x.shape[1] == self.channels\n        return self.op(x)\n\n\nclass ResBlock(TimestepBlock):\n    """\n    A residual block that can optionally change the number of channels.\n\n    :param channels: the number of input channels.\n    :param emb_channels: the number of timestep embedding channels.\n    :param dropout: the rate of dropout.\n    :param out_channels: if specified, the number of out channels.\n    :param use_conv: if True and out_channels is specified, use a spatial\n        convolution instead of a smaller 1x1 convolution to change the\n        channels in the skip connection.\n    :param dims: determines if the signal is 1D, 2D, or 3D.\n    :param use_checkpoint: if True, use gradient checkpointing on this module.\n    :param up: if True, use this block for upsampling.\n    :param down: if True, use this block for downsampling.\n    """\n\n    def __init__(\n        self,\n        channels,\n        emb_channels,\n        dropout,\n        out_channels=None,\n        use_conv=False,\n        use_scale_shift_norm=False,\n        dims=2,\n        use_checkpoint=False,\n        up=False,\n        down=False,\n    ):\n        super().__init__()\n        self.channels = channels\n        self.emb_channels = emb_channels\n        self.dropout = dropout\n        self.out_channels = out_channels or channels\n        self.use_conv = use_conv\n        self.use_checkpoint = use_checkpoint\n        self.use_scale_shift_norm = use_scale_shift_norm\n\n        self.in_layers = nn.Sequential(\n            normalization(channels),\n            nn.SiLU(),\n            conv_nd(dims, channels, self.out_channels, 3, padding=1),\n        )\n\n        self.updown = up or down\n\n        if up:\n            self.h_upd = Upsample(channels, False, dims)\n            self.x_upd = Upsample(channels, False, dims)\n        elif down:\n            self.h_upd = Downsample(channels, False, dims)\n            self.x_upd = Downsample(channels, False, dims)\n        else:\n            self.h_upd = self.x_upd = nn.Identity()\n\n        self.emb_layers = nn.Sequential(\n            nn.SiLU(),\n            linear(\n                emb_channels,\n                2 * self.out_channels if use_scale_shift_norm else self.out_channels,\n            ),\n        )\n        self.out_layers = nn.Sequential(\n            normalization(self.out_channels),\n            nn.SiLU(),\n            nn.Dropout(p=dropout),\n            zero_module(\n                conv_nd(dims, self.out_channels, self.out_channels, 3, padding=1)\n            ),\n        )\n\n        if self.out_channels == channels:\n            self.skip_connection = nn.Identity()\n        elif use_conv:\n            self.skip_connection = conv_nd(\n                dims, channels, self.out_channels, 3, padding=1\n            )\n        else:\n            self.skip_connection = conv_nd(dims, channels, self.out_channels, 1)\n\n    def forward(self, x, emb):\n        """\n        Apply the block to a Tensor, conditioned on a timestep embedding.\n\n        :param x: an [N x C x ...] Tensor of features.\n        :param emb: an [N x emb_channels] Tensor of timestep embeddings.\n        :return: an [N x C x ...] Tensor of outputs.\n        """\n        return checkpoint(\n            self._forward, (x, emb), self.parameters(), self.use_checkpoint\n        )\n\n    def _forward(self, x, emb):\n        if self.updown:\n            in_rest, in_conv = self.in_layers[:-1], self.in_layers[-1]\n            h = in_rest(x)\n            h = self.h_upd(h)\n            x = self.x_upd(x)\n            h = in_conv(h)\n        else:\n            h = self.in_layers(x)\n        emb_out = self.emb_layers(emb).type(h.dtype)\n        while len(emb_out.shape) < len(h.shape):\n            emb_out = emb_out[..., None]\n        if self.use_scale_shift_norm:\n            out_norm, out_rest = self.out_layers[0], self.out_layers[1:]\n            scale, shift = th.chunk(emb_out, 2, dim=1)\n            h = out_norm(h) * (1 + scale) + shift\n            h = out_rest(h)\n        else:\n            h = h + emb_out\n            h = self.out_layers(h)\n        return self.skip_connection(x) + h\n\n\nclass AttentionBlock(nn.Module):\n    """\n    An attention block that allows spatial positions to attend to each other.\n\n    Originally ported from here, but adapted to the N-d case.\n    https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/models/unet.py#L66.\n    """\n\n    def __init__(\n        self,\n        channels,\n        num_heads=1,\n        num_head_channels=-1,\n        use_checkpoint=False,\n        use_new_attention_order=False,\n    ):\n        super().__init__()\n        self.channels = channels\n        if num_head_channels == -1:\n            self.num_heads = num_heads\n        else:\n            assert (\n                channels % num_head_channels == 0\n            ), f"q,k,v channels {channels} is not divisible by num_head_channels {num_head_channels}"\n            self.num_heads = channels // num_head_channels\n        self.use_checkpoint = use_checkpoint\n        self.norm = normalization(channels)\n        self.qkv = conv_nd(1, channels, channels * 3, 1)\n        if use_new_attention_order:\n            # split qkv before split heads\n            self.attention = QKVAttention(self.num_heads)\n        else:\n            # split heads before split qkv\n            self.attention = QKVAttentionLegacy(self.num_heads)\n\n        self.proj_out = zero_module(conv_nd(1, channels, channels, 1))\n\n    def forward(self, x):\n        return checkpoint(self._forward, (x,), self.parameters(), True)\n\n    def _forward(self, x):\n        b, c, *spatial = x.shape\n        x = x.reshape(b, c, -1)\n        qkv = self.qkv(self.norm(x))\n        h = self.attention(qkv)\n        h = self.proj_out(h)\n        return (x + h).reshape(b, c, *spatial)\n\n\ndef count_flops_attn(model, _x, y):\n    """\n    A counter for the `thop` package to count the operations in an\n    attention operation.\n    Meant to be used like:\n        macs, params = thop.profile(\n            model,\n            inputs=(inputs, timestamps),\n            custom_ops={QKVAttention: QKVAttention.count_flops},\n        )\n    """\n    b, c, *spatial = y[0].shape\n    num_spatial = int(np.prod(spatial))\n    # We perform two matmuls with the same number of ops.\n    # The first computes the weight matrix, the second computes\n    # the combination of the value vectors.\n    matmul_ops = 2 * b * (num_spatial ** 2) * c\n    model.total_ops += th.DoubleTensor([matmul_ops])\n\n\nclass QKVAttentionLegacy(nn.Module):\n    """\n    A module which performs QKV attention. Matches legacy QKVAttention + input/ouput heads shaping\n    """\n\n    def __init__(self, n_heads):\n        super().__init__()\n        self.n_heads = n_heads\n\n    def forward(self, qkv):\n        """\n        Apply QKV attention.\n\n        :param qkv: an [N x (H * 3 * C) x T] tensor of Qs, Ks, and Vs.\n        :return: an [N x (H * C) x T] tensor after attention.\n        """\n        bs, width, length = qkv.shape\n        assert width % (3 * self.n_heads) == 0\n        ch = width // (3 * self.n_heads)\n        q, k, v = qkv.reshape(bs * self.n_heads, ch * 3, length).split(ch, dim=1)\n        scale = 1 / math.sqrt(math.sqrt(ch))\n        weight = th.einsum(\n            "bct,bcs->bts", q * scale, k * scale\n        )  # More stable with f16 than dividing afterwards\n        weight = th.softmax(weight.float(), dim=-1).type(weight.dtype)\n        a = th.einsum("bts,bcs->bct", weight, v)\n        return a.reshape(bs, -1, length)\n\n    @staticmethod\n    def count_flops(model, _x, y):\n        return count_flops_attn(model, _x, y)\n\n\nclass QKVAttention(nn.Module):\n    """\n    A module which performs QKV attention and splits in a different order.\n    """\n\n    def __init__(self, n_heads):\n        super().__init__()\n        self.n_heads = n_heads\n\n    def forward(self, qkv):\n        """\n        Apply QKV attention.\n\n        :param qkv: an [N x (3 * H * C) x T] tensor of Qs, Ks, and Vs.\n        :return: an [N x (H * C) x T] tensor after attention.\n        """\n        bs, width, length = qkv.shape\n        assert width % (3 * self.n_heads) == 0\n        ch = width // (3 * self.n_heads)\n        q, k, v = qkv.chunk(3, dim=1)\n        scale = 1 / math.sqrt(math.sqrt(ch))\n        weight = th.einsum(\n            "bct,bcs->bts",\n            (q * scale).view(bs * self.n_heads, ch, length),\n            (k * scale).view(bs * self.n_heads, ch, length),\n        )  # More stable with f16 than dividing afterwards\n        weight = th.softmax(weight.float(), dim=-1).type(weight.dtype)\n        a = th.einsum("bts,bcs->bct", weight, v.reshape(bs * self.n_heads, ch, length))\n        return a.reshape(bs, -1, length)\n\n    @staticmethod\n    def count_flops(model, _x, y):\n        return count_flops_attn(model, _x, y)\n\n\nclass UNetModel(nn.Module):\n    """\n    The full UNet model with attention and timestep embedding.\n\n    :param in_channels: channels in the input Tensor.\n    :param model_channels: base channel count for the model.\n    :param out_channels: channels in the output Tensor.\n    :param num_res_blocks: number of residual blocks per downsample.\n    :param attention_resolutions: a collection of downsample rates at which\n        attention will take place. May be a set, list, or tuple.\n        For example, if this contains 4, then at 4x downsampling, attention\n        will be used.\n    :param dropout: the dropout probability.\n    :param channel_mult: channel multiplier for each level of the UNet.\n    :param conv_resample: if True, use learned convolutions for upsampling and\n        downsampling.\n    :param dims: determines if the signal is 1D, 2D, or 3D.\n    :param num_classes: if specified (as an int), then this model will be\n        class-conditional with `num_classes` classes.\n    :param use_checkpoint: use gradient checkpointing to reduce memory usage.\n    :param num_heads: the number of attention heads in each attention layer.\n    :param num_heads_channels: if specified, ignore num_heads and instead use\n                               a fixed channel width per attention head.\n    :param num_heads_upsample: works with num_heads to set a different number\n                               of heads for upsampling. Deprecated.\n    :param use_scale_shift_norm: use a FiLM-like conditioning mechanism.\n    :param resblock_updown: use residual blocks for up/downsampling.\n    :param use_new_attention_order: use a different attention pattern for potentially\n                                    increased efficiency.\n    """\n\n    def __init__(\n        self,\n        image_size,\n        in_channels,\n        model_channels,\n        out_channels,\n        num_res_blocks,\n        attention_resolutions,\n        dropout=0,\n        channel_mult=(1, 2, 4, 8),\n        conv_resample=True,\n        dims=2,\n        num_classes=None,\n        use_checkpoint=False,\n        use_fp16=False,\n        num_heads=1,\n        num_head_channels=-1,\n        num_heads_upsample=-1,\n        use_scale_shift_norm=False,\n        resblock_updown=False,\n        use_new_attention_order=False,\n    ):\n        super().__init__()\n\n        if num_heads_upsample == -1:\n            num_heads_upsample = num_heads\n\n        self.image_size = image_size\n        self.in_channels = in_channels\n        self.model_channels = model_channels\n        self.out_channels = out_channels\n        self.num_res_blocks = num_res_blocks\n        self.attention_resolutions = attention_resolutions\n        self.dropout = dropout\n        self.channel_mult = channel_mult\n        self.conv_resample = conv_resample\n        self.num_classes = num_classes\n        self.use_checkpoint = use_checkpoint\n        self.dtype = th.float16 if use_fp16 else th.float32\n        self.num_heads = num_heads\n        self.num_head_channels = num_head_channels\n        self.num_heads_upsample = num_heads_upsample\n\n        time_embed_dim = model_channels * 4\n        self.time_embed = nn.Sequential(\n            linear(model_channels, time_embed_dim),\n            nn.SiLU(),\n            linear(time_embed_dim, time_embed_dim),\n        )\n\n        if self.num_classes is not None:\n            self.label_emb = nn.Embedding(num_classes, time_embed_dim)\n\n        ch = input_ch = int(channel_mult[0] * model_channels)\n        self.input_blocks = nn.ModuleList(\n            [TimestepEmbedSequential(conv_nd(dims, in_channels, ch, 3, padding=1))]\n        )\n        self._feature_size = ch\n        input_block_chans = [ch]\n        ds = 1\n        for level, mult in enumerate(channel_mult):\n            for _ in range(num_res_blocks):\n                layers = [\n                    ResBlock(\n                        ch,\n                        time_embed_dim,\n                        dropout,\n                        out_channels=int(mult * model_channels),\n                        dims=dims,\n                        use_checkpoint=use_checkpoint,\n                        use_scale_shift_norm=use_scale_shift_norm,\n                    )\n                ]\n                ch = int(mult * model_channels)\n                if ds in attention_resolutions:\n                    layers.append(\n                        AttentionBlock(\n                            ch,\n                            use_checkpoint=use_checkpoint,\n                            num_heads=num_heads,\n                            num_head_channels=num_head_channels,\n                            use_new_attention_order=use_new_attention_order,\n                        )\n                    )\n                self.input_blocks.append(TimestepEmbedSequential(*layers))\n                self._feature_size += ch\n                input_block_chans.append(ch)\n            if level != len(channel_mult) - 1:\n                out_ch = ch\n                self.input_blocks.append(\n                    TimestepEmbedSequential(\n                        ResBlock(\n                            ch,\n                            time_embed_dim,\n                            dropout,\n                            out_channels=out_ch,\n                            dims=dims,\n                            use_checkpoint=use_checkpoint,\n                            use_scale_shift_norm=use_scale_shift_norm,\n                            down=True,\n                        )\n                        if resblock_updown\n                        else Downsample(\n                            ch, conv_resample, dims=dims, out_channels=out_ch\n                        )\n                    )\n                )\n                ch = out_ch\n                input_block_chans.append(ch)\n                ds *= 2\n                self._feature_size += ch\n\n        self.middle_block = TimestepEmbedSequential(\n            ResBlock(\n                ch,\n                time_embed_dim,\n                dropout,\n                dims=dims,\n                use_checkpoint=use_checkpoint,\n                use_scale_shift_norm=use_scale_shift_norm,\n            ),\n            AttentionBlock(\n                ch,\n                use_checkpoint=use_checkpoint,\n                num_heads=num_heads,\n                num_head_channels=num_head_channels,\n                use_new_attention_order=use_new_attention_order,\n            ),\n            ResBlock(\n                ch,\n                time_embed_dim,\n                dropout,\n                dims=dims,\n                use_checkpoint=use_checkpoint,\n                use_scale_shift_norm=use_scale_shift_norm,\n            ),\n        )\n        self._feature_size += ch\n\n        self.output_blocks = nn.ModuleList([])\n        for level, mult in list(enumerate(channel_mult))[::-1]:\n            for i in range(num_res_blocks + 1):\n                ich = input_block_chans.pop()\n                layers = [\n                    ResBlock(\n                        ch + ich,\n                        time_embed_dim,\n                        dropout,\n                        out_channels=int(model_channels * mult),\n                        dims=dims,\n                        use_checkpoint=use_checkpoint,\n                        use_scale_shift_norm=use_scale_shift_norm,\n                    )\n                ]\n                ch = int(model_channels * mult)\n                if ds in attention_resolutions:\n                    layers.append(\n                        AttentionBlock(\n                            ch,\n                            use_checkpoint=use_checkpoint,\n                            num_heads=num_heads_upsample,\n                            num_head_channels=num_head_channels,\n                            use_new_attention_order=use_new_attention_order,\n                        )\n                    )\n                if level and i == num_res_blocks:\n                    out_ch = ch\n                    layers.append(\n                        ResBlock(\n                            ch,\n                            time_embed_dim,\n                            dropout,\n                            out_channels=out_ch,\n                            dims=dims,\n                            use_checkpoint=use_checkpoint,\n                            use_scale_shift_norm=use_scale_shift_norm,\n                            up=True,\n                        )\n                        if resblock_updown\n                        else Upsample(ch, conv_resample, dims=dims, out_channels=out_ch)\n                    )\n                    ds //= 2\n                self.output_blocks.append(TimestepEmbedSequential(*layers))\n                self._feature_size += ch\n\n        self.out = nn.Sequential(\n            normalization(ch),\n            nn.SiLU(),\n            zero_module(conv_nd(dims, input_ch, out_channels, 3, padding=1)),\n        )\n\n    def convert_to_fp16(self):\n        """\n        Convert the torso of the model to float16.\n        """\n        self.input_blocks.apply(convert_module_to_f16)\n        self.middle_block.apply(convert_module_to_f16)\n        self.output_blocks.apply(convert_module_to_f16)\n\n    def convert_to_fp32(self):\n        """\n        Convert the torso of the model to float32.\n        """\n        self.input_blocks.apply(convert_module_to_f32)\n        self.middle_block.apply(convert_module_to_f32)\n        self.output_blocks.apply(convert_module_to_f32)\n\n    def forward(self, x, timesteps, y=None):\n        """\n        Apply the model to an input batch.\n\n        :param x: an [N x C x ...] Tensor of inputs.\n        :param timesteps: a 1-D batch of timesteps.\n        :param y: an [N] Tensor of labels, if class-conditional.\n        :return: an [N x C x ...] Tensor of outputs.\n        """\n        assert (y is not None) == (\n            self.num_classes is not None\n        ), "must specify y if and only if the model is class-conditional"\n\n        hs = []\n        emb = self.time_embed(timestep_embedding(timesteps, self.model_channels))\n\n        if self.num_classes is not None:\n            assert y.shape == (x.shape[0],)\n            emb = emb + self.label_emb(y)\n\n        h = x.type(self.dtype)\n        for module in self.input_blocks:\n            h = module(h, emb)\n            hs.append(h)\n        h = self.middle_block(h, emb)\n        for module in self.output_blocks:\n            h = th.cat([h, hs.pop()], dim=1)\n            h = module(h, emb)\n        h = h.type(x.dtype)\n        return self.out(h)\n\n\nclass SuperResModel(UNetModel):\n    """\n    A UNetModel that performs super-resolution.\n\n    Expects an extra kwarg `low_res` to condition on a low-resolution image.\n    """\n\n    def __init__(self, image_size, in_channels, *args, **kwargs):\n        super().__init__(image_size, in_channels * 2, *args, **kwargs)\n\n    def forward(self, x, timesteps, low_res=None, **kwargs):\n        _, _, new_height, new_width = x.shape\n        upsampled = F.interpolate(low_res, (new_height, new_width), mode="bilinear")\n        x = th.cat([x, upsampled], dim=1)\n        return super().forward(x, timesteps, **kwargs)\n\n\nclass EncoderUNetModel(nn.Module):\n    """\n    The half UNet model with attention and timestep embedding.\n\n    For usage, see UNet.\n    """\n\n    def __init__(\n        self,\n        image_size,\n        in_channels,\n        model_channels,\n        out_channels,\n        num_res_blocks,\n        attention_resolutions,\n        dropout=0,\n        channel_mult=(1, 2, 4, 8),\n        conv_resample=True,\n        dims=2,\n        use_checkpoint=False,\n        use_fp16=False,\n        num_heads=1,\n        num_head_channels=-1,\n        num_heads_upsample=-1,\n        use_scale_shift_norm=False,\n        resblock_updown=False,\n        use_new_attention_order=False,\n        pool="adaptive",\n    ):\n        super().__init__()\n\n        if num_heads_upsample == -1:\n            num_heads_upsample = num_heads\n\n        self.in_channels = in_channels\n        self.model_channels = model_channels\n        self.out_channels = out_channels\n        self.num_res_blocks = num_res_blocks\n        self.attention_resolutions = attention_resolutions\n        self.dropout = dropout\n        self.channel_mult = channel_mult\n        self.conv_resample = conv_resample\n        self.use_checkpoint = use_checkpoint\n        self.dtype = th.float16 if use_fp16 else th.float32\n        self.num_heads = num_heads\n        self.num_head_channels = num_head_channels\n        self.num_heads_upsample = num_heads_upsample\n\n        time_embed_dim = model_channels * 4\n        self.time_embed = nn.Sequential(\n            linear(model_channels, time_embed_dim),\n            nn.SiLU(),\n            linear(time_embed_dim, time_embed_dim),\n        )\n\n        ch = int(channel_mult[0] * model_channels)\n        self.input_blocks = nn.ModuleList(\n            [TimestepEmbedSequential(conv_nd(dims, in_channels, ch, 3, padding=1))]\n        )\n        self._feature_size = ch\n        input_block_chans = [ch]\n        ds = 1\n        for level, mult in enumerate(channel_mult):\n            for _ in range(num_res_blocks):\n                layers = [\n                    ResBlock(\n                        ch,\n                        time_embed_dim,\n                        dropout,\n                        out_channels=int(mult * model_channels),\n                        dims=dims,\n                        use_checkpoint=use_checkpoint,\n                        use_scale_shift_norm=use_scale_shift_norm,\n                    )\n                ]\n                ch = int(mult * model_channels)\n                if ds in attention_resolutions:\n                    layers.append(\n                        AttentionBlock(\n                            ch,\n                            use_checkpoint=use_checkpoint,\n                            num_heads=num_heads,\n                            num_head_channels=num_head_channels,\n                            use_new_attention_order=use_new_attention_order,\n                        )\n                    )\n                self.input_blocks.append(TimestepEmbedSequential(*layers))\n                self._feature_size += ch\n                input_block_chans.append(ch)\n            if level != len(channel_mult) - 1:\n                out_ch = ch\n                self.input_blocks.append(\n                    TimestepEmbedSequential(\n                        ResBlock(\n                            ch,\n                            time_embed_dim,\n                            dropout,\n                            out_channels=out_ch,\n                            dims=dims,\n                            use_checkpoint=use_checkpoint,\n                            use_scale_shift_norm=use_scale_shift_norm,\n                            down=True,\n                        )\n                        if resblock_updown\n                        else Downsample(\n                            ch, conv_resample, dims=dims, out_channels=out_ch\n                        )\n                    )\n                )\n                ch = out_ch\n                input_block_chans.append(ch)\n                ds *= 2\n                self._feature_size += ch\n\n        self.middle_block = TimestepEmbedSequential(\n            ResBlock(\n                ch,\n                time_embed_dim,\n                dropout,\n                dims=dims,\n                use_checkpoint=use_checkpoint,\n                use_scale_shift_norm=use_scale_shift_norm,\n            ),\n            AttentionBlock(\n                ch,\n                use_checkpoint=use_checkpoint,\n                num_heads=num_heads,\n                num_head_channels=num_head_channels,\n                use_new_attention_order=use_new_attention_order,\n            ),\n            ResBlock(\n                ch,\n                time_embed_dim,\n                dropout,\n                dims=dims,\n                use_checkpoint=use_checkpoint,\n                use_scale_shift_norm=use_scale_shift_norm,\n            ),\n        )\n        self._feature_size += ch\n        self.pool = pool\n        if pool == "adaptive":\n            self.out = nn.Sequential(\n                normalization(ch),\n                nn.SiLU(),\n                nn.AdaptiveAvgPool2d((1, 1)),\n                zero_module(conv_nd(dims, ch, out_channels, 1)),\n                nn.Flatten(),\n            )\n        elif pool == "attention":\n            assert num_head_channels != -1\n            self.out = nn.Sequential(\n                normalization(ch),\n                nn.SiLU(),\n                AttentionPool2d(\n                    (image_size // ds), ch, num_head_channels, out_channels\n                ),\n            )\n        elif pool == "spatial":\n            self.out = nn.Sequential(\n                nn.Linear(self._feature_size, 2048),\n                nn.ReLU(),\n                nn.Linear(2048, self.out_channels),\n            )\n        elif pool == "spatial_v2":\n            self.out = nn.Sequential(\n                nn.Linear(self._feature_size, 2048),\n                normalization(2048),\n                nn.SiLU(),\n                nn.Linear(2048, self.out_channels),\n            )\n        else:\n            raise NotImplementedError(f"Unexpected {pool} pooling")\n\n    def convert_to_fp16(self):\n        """\n        Convert the torso of the model to float16.\n        """\n        self.input_blocks.apply(convert_module_to_f16)\n        self.middle_block.apply(convert_module_to_f16)\n\n    def convert_to_fp32(self):\n        """\n        Convert the torso of the model to float32.\n        """\n        self.input_blocks.apply(convert_module_to_f32)\n        self.middle_block.apply(convert_module_to_f32)\n\n    def forward(self, x, timesteps):\n        """\n        Apply the model to an input batch.\n\n        :param x: an [N x C x ...] Tensor of inputs.\n        :param timesteps: a 1-D batch of timesteps.\n        :return: an [N x K] Tensor of outputs.\n        """\n        emb = self.time_embed(timestep_embedding(timesteps, self.model_channels))\n\n        results = []\n        h = x.type(self.dtype)\n        for module in self.input_blocks:\n            h = module(h, emb)\n            if self.pool.startswith("spatial"):\n                results.append(h.type(x.dtype).mean(dim=(2, 3)))\n        h = self.middle_block(h, emb)\n        if self.pool.startswith("spatial"):\n            results.append(h.type(x.dtype).mean(dim=(2, 3)))\n            h = th.cat(results, axis=-1)\n            return self.out(h)\n        else:\n            h = h.type(x.dtype)\n            return self.out(h)\n\n\nclass NLayerDiscriminator(nn.Module):\n    def __init__(self, input_nc, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d, use_sigmoid=False):\n        super(NLayerDiscriminator, self).__init__()\n        if type(norm_layer) == functools.partial:\n            use_bias = norm_layer.func == nn.InstanceNorm2d\n        else:\n            use_bias = norm_layer == nn.InstanceNorm2d\n\n        kw = 4\n        padw = 1\n        sequence = [\n            nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw),\n            nn.LeakyReLU(0.2, True)\n        ]\n\n        nf_mult = 1\n        nf_mult_prev = 1\n        for n in range(1, n_layers):\n            nf_mult_prev = nf_mult\n            nf_mult = min(2**n, 8)\n            sequence += [\n                nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult,\n                          kernel_size=kw, stride=2, padding=padw, bias=use_bias),\n                norm_layer(ndf * nf_mult),\n                nn.LeakyReLU(0.2, True)\n            ]\n\n        nf_mult_prev = nf_mult\n        nf_mult = min(2**n_layers, 8)\n        sequence += [\n            nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult,\n                      kernel_size=kw, stride=2, padding=padw, bias=use_bias),\n            norm_layer(ndf * nf_mult),\n            nn.LeakyReLU(0.2, True)\n        ]\n\n        sequence += [nn.Conv2d(ndf * nf_mult, 1, kernel_size=kw, stride=2, padding=padw)] + [nn.Dropout(0.5)]\n        if use_sigmoid:\n            sequence += [nn.Sigmoid()]\n\n        self.model = nn.Sequential(*sequence)\n\n    def forward(self, input):\n        return self.model(input)\n\n\nclass GANLoss(nn.Module):\n    """Define different GAN objectives.\n\n    The GANLoss class abstracts away the need to create the target label tensor\n    that has the same size as the input.\n    """\n\n    def __init__(self, gan_mode, target_real_label=1.0, target_fake_label=0.0):\n        """ Initialize the GANLoss class.\n\n        Parameters:\n            gan_mode (str) - - the type of GAN objective. It currently supports vanilla, lsgan, and wgangp.\n            target_real_label (bool) - - label for a real image\n            target_fake_label (bool) - - label of a fake image\n\n        Note: Do not use sigmoid as the last layer of Discriminator.\n        LSGAN needs no sigmoid. vanilla GANs will handle it with BCEWithLogitsLoss.\n        """\n        super(GANLoss, self).__init__()\n        self.register_buffer(\'real_label\', th.tensor(target_real_label))\n        self.register_buffer(\'fake_label\', th.tensor(target_fake_label))\n        self.gan_mode = gan_mode\n        if gan_mode == \'lsgan\':\n            self.loss = nn.MSELoss()\n        elif gan_mode == \'vanilla\':\n            self.loss = nn.BCEWithLogitsLoss()\n        elif gan_mode in [\'wgangp\']:\n            self.loss = None\n        else:\n            raise NotImplementedError(\'gan mode %s not implemented\' % gan_mode)\n\n    def get_target_tensor(self, prediction, target_is_real):\n        """Create label tensors with the same size as the input.\n\n        Parameters:\n            prediction (tensor) - - tpyically the prediction from a discriminator\n            target_is_real (bool) - - if the ground truth label is for real images or fake images\n\n        Returns:\n            A label tensor filled with ground truth label, and with the size of the input\n        """\n\n        if target_is_real:\n            target_tensor = self.real_label\n        else:\n            target_tensor = self.fake_label\n        return target_tensor.expand_as(prediction)\n\n    def __call__(self, prediction, target_is_real):\n        """Calculate loss given Discriminator\'s output and grount truth labels.\n\n        Parameters:\n            prediction (tensor) - - tpyically the prediction output from a discriminator\n            target_is_real (bool) - - if the ground truth label is for real images or fake images\n\n        Returns:\n            the calculated loss.\n        """\n        if self.gan_mode in [\'lsgan\', \'vanilla\']:\n            target_tensor = self.get_target_tensor(prediction, target_is_real)\n            loss = self.loss(prediction, target_tensor)\n        elif self.gan_mode == \'wgangp\':\n            if target_is_real:\n                loss = -prediction.mean()\n            else:\n                loss = prediction.mean()\n        return loss\n\n\ndef cal_gradient_penalty(netD, real_data, fake_data, device, type=\'mixed\', constant=1.0, lambda_gp=10.0):\n    """Calculate the gradient penalty loss, used in WGAN-GP paper https://arxiv.org/abs/1704.00028\n\n    Arguments:\n        netD (network)              -- discriminator network\n        real_data (tensor array)    -- real images\n        fake_data (tensor array)    -- generated images from the generator\n        device (str)                -- GPU / CPU: from torch.device(\'cuda:{}\'.format(self.gpu_ids[0])) if self.gpu_ids else torch.device(\'cpu\')\n        type (str)                  -- if we mix real and fake data or not [real | fake | mixed].\n        constant (float)            -- the constant used in formula ( | |gradient||_2 - constant)^2\n        lambda_gp (float)           -- weight for this loss\n\n    Returns the gradient penalty loss\n    """\n    if lambda_gp > 0.0:\n        if type == \'real\':   # either use real images, fake images, or a linear interpolation of two.\n            interpolatesv = real_data\n        elif type == \'fake\':\n            interpolatesv = fake_data\n        elif type == \'mixed\':\n            alpha = th.rand(real_data.shape[0], 1, device=device)\n            alpha = alpha.expand(real_data.shape[0], real_data.nelement() // real_data.shape[0]).contiguous().view(*real_data.shape)\n            interpolatesv = alpha * real_data + ((1 - alpha) * fake_data)\n        else:\n            raise NotImplementedError(\'{} not implemented\'.format(type))\n        interpolatesv.requires_grad_(True)\n        disc_interpolates = netD(interpolatesv)\n        gradients = th.autograd.grad(outputs=disc_interpolates, inputs=interpolatesv,\n                                     grad_outputs=th.ones(disc_interpolates.size()).to(device),\n                                     create_graph=True, retain_graph=True, only_inputs=True)\n        gradients = gradients[0].view(real_data.size(0), -1)  # flat the data\n        gradient_penalty = (((gradients + 1e-16).norm(2, dim=1) - constant) ** 2).mean() * lambda_gp        # added eps\n        return gradient_penalty, gradients\n    else:\n        return 0.0, None\n',
    'model.edm': '',
    'model.edm.dnnlib': '# Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n#\n# This work is licensed under a Creative Commons\n# Attribution-NonCommercial-ShareAlike 4.0 International License.\n# You should have received a copy of the license along with this\n# work. If not, see http://creativecommons.org/licenses/by-nc-sa/4.0/\n\nfrom .util import EasyDict, make_cache_dir_path\n',
    'model.edm.dnnlib.util': '# Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n#\n# This work is licensed under a Creative Commons\n# Attribution-NonCommercial-ShareAlike 4.0 International License.\n# You should have received a copy of the license along with this\n# work. If not, see http://creativecommons.org/licenses/by-nc-sa/4.0/\n\n"""Miscellaneous utility classes and functions."""\n\nimport ctypes\nimport fnmatch\nimport importlib\nimport inspect\nimport numpy as np\nimport os\nimport shutil\nimport sys\nimport types\nimport io\nimport pickle\nimport re\nimport requests\nimport html\nimport hashlib\nimport glob\nimport tempfile\nimport urllib\nimport urllib.request\nimport uuid\n\nfrom distutils.util import strtobool\nfrom typing import Any, List, Tuple, Union, Optional\n\n\n# Util classes\n# ------------------------------------------------------------------------------------------\n\n\nclass EasyDict(dict):\n    """Convenience class that behaves like a dict but allows access with the attribute syntax."""\n\n    def __getattr__(self, name: str) -> Any:\n        try:\n            return self[name]\n        except KeyError:\n            raise AttributeError(name)\n\n    def __setattr__(self, name: str, value: Any) -> None:\n        self[name] = value\n\n    def __delattr__(self, name: str) -> None:\n        del self[name]\n\n\nclass Logger(object):\n    """Redirect stderr to stdout, optionally print stdout to a file, and optionally force flushing on both stdout and the file."""\n\n    def __init__(self, file_name: Optional[str] = None, file_mode: str = "w", should_flush: bool = True):\n        self.file = None\n\n        if file_name is not None:\n            self.file = open(file_name, file_mode)\n\n        self.should_flush = should_flush\n        self.stdout = sys.stdout\n        self.stderr = sys.stderr\n\n        sys.stdout = self\n        sys.stderr = self\n\n    def __enter__(self) -> "Logger":\n        return self\n\n    def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -> None:\n        self.close()\n\n    def write(self, text: Union[str, bytes]) -> None:\n        """Write text to stdout (and a file) and optionally flush."""\n        if isinstance(text, bytes):\n            text = text.decode()\n        if len(text) == 0: # workaround for a bug in VSCode debugger: sys.stdout.write(\'\'); sys.stdout.flush() => crash\n            return\n\n        if self.file is not None:\n            self.file.write(text)\n\n        self.stdout.write(text)\n\n        if self.should_flush:\n            self.flush()\n\n    def flush(self) -> None:\n        """Flush written text to both stdout and a file, if open."""\n        if self.file is not None:\n            self.file.flush()\n\n        self.stdout.flush()\n\n    def close(self) -> None:\n        """Flush, close possible files, and remove stdout/stderr mirroring."""\n        self.flush()\n\n        # if using multiple loggers, prevent closing in wrong order\n        if sys.stdout is self:\n            sys.stdout = self.stdout\n        if sys.stderr is self:\n            sys.stderr = self.stderr\n\n        if self.file is not None:\n            self.file.close()\n            self.file = None\n\n\n# Cache directories\n# ------------------------------------------------------------------------------------------\n\n_dnnlib_cache_dir = None\n\ndef set_cache_dir(path: str) -> None:\n    global _dnnlib_cache_dir\n    _dnnlib_cache_dir = path\n\ndef make_cache_dir_path(*paths: str) -> str:\n    if _dnnlib_cache_dir is not None:\n        return os.path.join(_dnnlib_cache_dir, *paths)\n    if \'DNNLIB_CACHE_DIR\' in os.environ:\n        return os.path.join(os.environ[\'DNNLIB_CACHE_DIR\'], *paths)\n    if \'HOME\' in os.environ:\n        return os.path.join(os.environ[\'HOME\'], \'.cache\', \'dnnlib\', *paths)\n    if \'USERPROFILE\' in os.environ:\n        return os.path.join(os.environ[\'USERPROFILE\'], \'.cache\', \'dnnlib\', *paths)\n    return os.path.join(tempfile.gettempdir(), \'.cache\', \'dnnlib\', *paths)\n\n# Small util functions\n# ------------------------------------------------------------------------------------------\n\n\ndef format_time(seconds: Union[int, float]) -> str:\n    """Convert the seconds to human readable string with days, hours, minutes and seconds."""\n    s = int(np.rint(seconds))\n\n    if s < 60:\n        return "{0}s".format(s)\n    elif s < 60 * 60:\n        return "{0}m {1:02}s".format(s // 60, s % 60)\n    elif s < 24 * 60 * 60:\n        return "{0}h {1:02}m {2:02}s".format(s // (60 * 60), (s // 60) % 60, s % 60)\n    else:\n        return "{0}d {1:02}h {2:02}m".format(s // (24 * 60 * 60), (s // (60 * 60)) % 24, (s // 60) % 60)\n\n\ndef format_time_brief(seconds: Union[int, float]) -> str:\n    """Convert the seconds to human readable string with days, hours, minutes and seconds."""\n    s = int(np.rint(seconds))\n\n    if s < 60:\n        return "{0}s".format(s)\n    elif s < 60 * 60:\n        return "{0}m {1:02}s".format(s // 60, s % 60)\n    elif s < 24 * 60 * 60:\n        return "{0}h {1:02}m".format(s // (60 * 60), (s // 60) % 60)\n    else:\n        return "{0}d {1:02}h".format(s // (24 * 60 * 60), (s // (60 * 60)) % 24)\n\n\ndef ask_yes_no(question: str) -> bool:\n    """Ask the user the question until the user inputs a valid answer."""\n    while True:\n        try:\n            print("{0} [y/n]".format(question))\n            return strtobool(input().lower())\n        except ValueError:\n            pass\n\n\ndef tuple_product(t: Tuple) -> Any:\n    """Calculate the product of the tuple elements."""\n    result = 1\n\n    for v in t:\n        result *= v\n\n    return result\n\n\n_str_to_ctype = {\n    "uint8": ctypes.c_ubyte,\n    "uint16": ctypes.c_uint16,\n    "uint32": ctypes.c_uint32,\n    "uint64": ctypes.c_uint64,\n    "int8": ctypes.c_byte,\n    "int16": ctypes.c_int16,\n    "int32": ctypes.c_int32,\n    "int64": ctypes.c_int64,\n    "float32": ctypes.c_float,\n    "float64": ctypes.c_double\n}\n\n\ndef get_dtype_and_ctype(type_obj: Any) -> Tuple[np.dtype, Any]:\n    """Given a type name string (or an object having a __name__ attribute), return matching Numpy and ctypes types that have the same size in bytes."""\n    type_str = None\n\n    if isinstance(type_obj, str):\n        type_str = type_obj\n    elif hasattr(type_obj, "__name__"):\n        type_str = type_obj.__name__\n    elif hasattr(type_obj, "name"):\n        type_str = type_obj.name\n    else:\n        raise RuntimeError("Cannot infer type name from input")\n\n    assert type_str in _str_to_ctype.keys()\n\n    my_dtype = np.dtype(type_str)\n    my_ctype = _str_to_ctype[type_str]\n\n    assert my_dtype.itemsize == ctypes.sizeof(my_ctype)\n\n    return my_dtype, my_ctype\n\n\ndef is_pickleable(obj: Any) -> bool:\n    try:\n        with io.BytesIO() as stream:\n            pickle.dump(obj, stream)\n        return True\n    except:\n        return False\n\n\n# Functionality to import modules/objects by name, and call functions by name\n# ------------------------------------------------------------------------------------------\n\ndef get_module_from_obj_name(obj_name: str) -> Tuple[types.ModuleType, str]:\n    """Searches for the underlying module behind the name to some python object.\n    Returns the module and the object name (original name with module part removed)."""\n\n    # allow convenience shorthands, substitute them by full names\n    obj_name = re.sub("^np.", "numpy.", obj_name)\n    obj_name = re.sub("^tf.", "tensorflow.", obj_name)\n\n    # list alternatives for (module_name, local_obj_name)\n    parts = obj_name.split(".")\n    name_pairs = [(".".join(parts[:i]), ".".join(parts[i:])) for i in range(len(parts), 0, -1)]\n\n    # try each alternative in turn\n    for module_name, local_obj_name in name_pairs:\n        try:\n            module = importlib.import_module(module_name) # may raise ImportError\n            get_obj_from_module(module, local_obj_name) # may raise AttributeError\n            return module, local_obj_name\n        except:\n            pass\n\n    # maybe some of the modules themselves contain errors?\n    for module_name, _local_obj_name in name_pairs:\n        try:\n            importlib.import_module(module_name) # may raise ImportError\n        except ImportError:\n            if not str(sys.exc_info()[1]).startswith("No module named \'" + module_name + "\'"):\n                raise\n\n    # maybe the requested attribute is missing?\n    for module_name, local_obj_name in name_pairs:\n        try:\n            module = importlib.import_module(module_name) # may raise ImportError\n            get_obj_from_module(module, local_obj_name) # may raise AttributeError\n        except ImportError:\n            pass\n\n    # we are out of luck, but we have no idea why\n    raise ImportError(obj_name)\n\n\ndef get_obj_from_module(module: types.ModuleType, obj_name: str) -> Any:\n    """Traverses the object name and returns the last (rightmost) python object."""\n    if obj_name == \'\':\n        return module\n    obj = module\n    for part in obj_name.split("."):\n        obj = getattr(obj, part)\n    return obj\n\n\ndef get_obj_by_name(name: str) -> Any:\n    """Finds the python object with the given name."""\n    module, obj_name = get_module_from_obj_name(name)\n    return get_obj_from_module(module, obj_name)\n\n\ndef call_func_by_name(*args, func_name: str = None, **kwargs) -> Any:\n    """Finds the python object with the given name and calls it as a function."""\n    assert func_name is not None\n    func_obj = get_obj_by_name(func_name)\n    assert callable(func_obj)\n    return func_obj(*args, **kwargs)\n\n\ndef construct_class_by_name(*args, class_name: str = None, **kwargs) -> Any:\n    """Finds the python class with the given name and constructs it with the given arguments."""\n    return call_func_by_name(*args, func_name=class_name, **kwargs)\n\n\ndef get_module_dir_by_obj_name(obj_name: str) -> str:\n    """Get the directory path of the module containing the given object name."""\n    module, _ = get_module_from_obj_name(obj_name)\n    return os.path.dirname(inspect.getfile(module))\n\n\ndef is_top_level_function(obj: Any) -> bool:\n    """Determine whether the given object is a top-level function, i.e., defined at module scope using \'def\'."""\n    return callable(obj) and obj.__name__ in sys.modules[obj.__module__].__dict__\n\n\ndef get_top_level_function_name(obj: Any) -> str:\n    """Return the fully-qualified name of a top-level function."""\n    assert is_top_level_function(obj)\n    module = obj.__module__\n    if module == \'__main__\':\n        module = os.path.splitext(os.path.basename(sys.modules[module].__file__))[0]\n    return module + "." + obj.__name__\n\n\n# File system helpers\n# ------------------------------------------------------------------------------------------\n\ndef list_dir_recursively_with_ignore(dir_path: str, ignores: List[str] = None, add_base_to_relative: bool = False) -> List[Tuple[str, str]]:\n    """List all files recursively in a given directory while ignoring given file and directory names.\n    Returns list of tuples containing both absolute and relative paths."""\n    assert os.path.isdir(dir_path)\n    base_name = os.path.basename(os.path.normpath(dir_path))\n\n    if ignores is None:\n        ignores = []\n\n    result = []\n\n    for root, dirs, files in os.walk(dir_path, topdown=True):\n        for ignore_ in ignores:\n            dirs_to_remove = [d for d in dirs if fnmatch.fnmatch(d, ignore_)]\n\n            # dirs need to be edited in-place\n            for d in dirs_to_remove:\n                dirs.remove(d)\n\n            files = [f for f in files if not fnmatch.fnmatch(f, ignore_)]\n\n        absolute_paths = [os.path.join(root, f) for f in files]\n        relative_paths = [os.path.relpath(p, dir_path) for p in absolute_paths]\n\n        if add_base_to_relative:\n            relative_paths = [os.path.join(base_name, p) for p in relative_paths]\n\n        assert len(absolute_paths) == len(relative_paths)\n        result += zip(absolute_paths, relative_paths)\n\n    return result\n\n\ndef copy_files_and_create_dirs(files: List[Tuple[str, str]]) -> None:\n    """Takes in a list of tuples of (src, dst) paths and copies files.\n    Will create all necessary directories."""\n    for file in files:\n        target_dir_name = os.path.dirname(file[1])\n\n        # will create all intermediate-level directories\n        if not os.path.exists(target_dir_name):\n            os.makedirs(target_dir_name)\n\n        shutil.copyfile(file[0], file[1])\n\n\n# URL helpers\n# ------------------------------------------------------------------------------------------\n\ndef is_url(obj: Any, allow_file_urls: bool = False) -> bool:\n    """Determine whether the given object is a valid URL string."""\n    if not isinstance(obj, str) or not "://" in obj:\n        return False\n    if allow_file_urls and obj.startswith(\'file://\'):\n        return True\n    try:\n        res = requests.compat.urlparse(obj)\n        if not res.scheme or not res.netloc or not "." in res.netloc:\n            return False\n        res = requests.compat.urlparse(requests.compat.urljoin(obj, "/"))\n        if not res.scheme or not res.netloc or not "." in res.netloc:\n            return False\n    except:\n        return False\n    return True\n\n\ndef open_url(url: str, cache_dir: str = None, num_attempts: int = 10, verbose: bool = True, return_filename: bool = False, cache: bool = True) -> Any:\n    """Download the given URL and return a binary-mode file object to access the data."""\n    assert num_attempts >= 1\n    assert not (return_filename and (not cache))\n\n    # Doesn\'t look like an URL scheme so interpret it as a local filename.\n    if not re.match(\'^[a-z]+://\', url):\n        return url if return_filename else open(url, "rb")\n\n    # Handle file URLs.  This code handles unusual file:// patterns that\n    # arise on Windows:\n    #\n    # file:///c:/foo.txt\n    #\n    # which would translate to a local \'/c:/foo.txt\' filename that\'s\n    # invalid.  Drop the forward slash for such pathnames.\n    #\n    # If you touch this code path, you should test it on both Linux and\n    # Windows.\n    #\n    # Some internet resources suggest using urllib.request.url2pathname() but\n    # but that converts forward slashes to backslashes and this causes\n    # its own set of problems.\n    if url.startswith(\'file://\'):\n        filename = urllib.parse.urlparse(url).path\n        if re.match(r\'^/[a-zA-Z]:\', filename):\n            filename = filename[1:]\n        return filename if return_filename else open(filename, "rb")\n\n    assert is_url(url)\n\n    # Lookup from cache.\n    if cache_dir is None:\n        cache_dir = make_cache_dir_path(\'downloads\')\n\n    url_md5 = hashlib.md5(url.encode("utf-8")).hexdigest()\n    if cache:\n        cache_files = glob.glob(os.path.join(cache_dir, url_md5 + "_*"))\n        if len(cache_files) == 1:\n            filename = cache_files[0]\n            return filename if return_filename else open(filename, "rb")\n\n    # Download.\n    url_name = None\n    url_data = None\n    with requests.Session() as session:\n        if verbose:\n            print("Downloading %s ..." % url, end="", flush=True)\n        for attempts_left in reversed(range(num_attempts)):\n            try:\n                with session.get(url) as res:\n                    res.raise_for_status()\n                    if len(res.content) == 0:\n                        raise IOError("No data received")\n\n                    if len(res.content) < 8192:\n                        content_str = res.content.decode("utf-8")\n                        if "download_warning" in res.headers.get("Set-Cookie", ""):\n                            links = [html.unescape(link) for link in content_str.split(\'"\') if "export=download" in link]\n                            if len(links) == 1:\n                                url = requests.compat.urljoin(url, links[0])\n                                raise IOError("Google Drive virus checker nag")\n                        if "Google Drive - Quota exceeded" in content_str:\n                            raise IOError("Google Drive download quota exceeded -- please try again later")\n\n                    match = re.search(r\'filename="([^"]*)"\', res.headers.get("Content-Disposition", ""))\n                    url_name = match[1] if match else url\n                    url_data = res.content\n                    if verbose:\n                        print(" done")\n                    break\n            except KeyboardInterrupt:\n                raise\n            except:\n                if not attempts_left:\n                    if verbose:\n                        print(" failed")\n                    raise\n                if verbose:\n                    print(".", end="", flush=True)\n\n    # Save to cache.\n    if cache:\n        safe_name = re.sub(r"[^0-9a-zA-Z-._]", "_", url_name)\n        safe_name = safe_name[:min(len(safe_name), 128)]\n        cache_file = os.path.join(cache_dir, url_md5 + "_" + safe_name)\n        temp_file = os.path.join(cache_dir, "tmp_" + uuid.uuid4().hex + "_" + url_md5 + "_" + safe_name)\n        os.makedirs(cache_dir, exist_ok=True)\n        with open(temp_file, "wb") as f:\n            f.write(url_data)\n        os.replace(temp_file, cache_file) # atomic\n        if return_filename:\n            return cache_file\n\n    # Return data as file object.\n    assert not return_filename\n    return io.BytesIO(url_data)\n',
    'model.edm.torch_utils': '# Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n#\n# This work is licensed under a Creative Commons\n# Attribution-NonCommercial-ShareAlike 4.0 International License.\n# You should have received a copy of the license along with this\n# work. If not, see http://creativecommons.org/licenses/by-nc-sa/4.0/\n\n# empty\n',
    'model.edm.torch_utils.distributed': "# Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n#\n# This work is licensed under a Creative Commons\n# Attribution-NonCommercial-ShareAlike 4.0 International License.\n# You should have received a copy of the license along with this\n# work. If not, see http://creativecommons.org/licenses/by-nc-sa/4.0/\n\nimport os\nimport torch\nfrom . import training_stats\n\n#----------------------------------------------------------------------------\n\ndef init():\n    if 'MASTER_ADDR' not in os.environ:\n        os.environ['MASTER_ADDR'] = 'localhost'\n    if 'MASTER_PORT' not in os.environ:\n        os.environ['MASTER_PORT'] = '29500'\n    if 'RANK' not in os.environ:\n        os.environ['RANK'] = '0'\n    if 'LOCAL_RANK' not in os.environ:\n        os.environ['LOCAL_RANK'] = '0'\n    if 'WORLD_SIZE' not in os.environ:\n        os.environ['WORLD_SIZE'] = '1'\n\n    backend = 'gloo' if os.name == 'nt' else 'nccl'\n    torch.distributed.init_process_group(backend=backend, init_method='env://')\n    torch.cuda.set_device(int(os.environ.get('LOCAL_RANK', '0')))\n\n    sync_device = torch.device('cuda') if get_world_size() > 1 else None\n    training_stats.init_multiprocessing(rank=get_rank(), sync_device=sync_device)\n\n#----------------------------------------------------------------------------\n\ndef get_rank():\n    return torch.distributed.get_rank() if torch.distributed.is_initialized() else 0\n\n#----------------------------------------------------------------------------\n\ndef get_world_size():\n    return torch.distributed.get_world_size() if torch.distributed.is_initialized() else 1\n\n#----------------------------------------------------------------------------\n\ndef should_stop():\n    return False\n\n#----------------------------------------------------------------------------\n\ndef update_progress(cur, total):\n    _ = cur, total\n\n#----------------------------------------------------------------------------\n\ndef print0(*args, **kwargs):\n    if get_rank() == 0:\n        print(*args, **kwargs)\n\n#----------------------------------------------------------------------------\n",
    'model.edm.torch_utils.misc': "# Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n#\n# This work is licensed under a Creative Commons\n# Attribution-NonCommercial-ShareAlike 4.0 International License.\n# You should have received a copy of the license along with this\n# work. If not, see http://creativecommons.org/licenses/by-nc-sa/4.0/\n\nimport re\nimport contextlib\nimport numpy as np\nimport torch\nimport warnings\nimport dnnlib\n\n#----------------------------------------------------------------------------\n# Cached construction of constant tensors. Avoids CPU=>GPU copy when the\n# same constant is used multiple times.\n\n_constant_cache = dict()\n\ndef constant(value, shape=None, dtype=None, device=None, memory_format=None):\n    value = np.asarray(value)\n    if shape is not None:\n        shape = tuple(shape)\n    if dtype is None:\n        dtype = torch.get_default_dtype()\n    if device is None:\n        device = torch.device('cpu')\n    if memory_format is None:\n        memory_format = torch.contiguous_format\n\n    key = (value.shape, value.dtype, value.tobytes(), shape, dtype, device, memory_format)\n    tensor = _constant_cache.get(key, None)\n    if tensor is None:\n        tensor = torch.as_tensor(value.copy(), dtype=dtype, device=device)\n        if shape is not None:\n            tensor, _ = torch.broadcast_tensors(tensor, torch.empty(shape))\n        tensor = tensor.contiguous(memory_format=memory_format)\n        _constant_cache[key] = tensor\n    return tensor\n\n#----------------------------------------------------------------------------\n# Replace NaN/Inf with specified numerical values.\n\ntry:\n    nan_to_num = torch.nan_to_num # 1.8.0a0\nexcept AttributeError:\n    def nan_to_num(input, nan=0.0, posinf=None, neginf=None, *, out=None): # pylint: disable=redefined-builtin\n        assert isinstance(input, torch.Tensor)\n        if posinf is None:\n            posinf = torch.finfo(input.dtype).max\n        if neginf is None:\n            neginf = torch.finfo(input.dtype).min\n        assert nan == 0\n        return torch.clamp(input.unsqueeze(0).nansum(0), min=neginf, max=posinf, out=out)\n\n#----------------------------------------------------------------------------\n# Symbolic assert.\n\ntry:\n    symbolic_assert = torch._assert # 1.8.0a0 # pylint: disable=protected-access\nexcept AttributeError:\n    symbolic_assert = torch.Assert # 1.7.0\n\n#----------------------------------------------------------------------------\n# Context manager to temporarily suppress known warnings in torch.jit.trace().\n# Note: Cannot use catch_warnings because of https://bugs.python.org/issue29672\n\n@contextlib.contextmanager\ndef suppress_tracer_warnings():\n    flt = ('ignore', None, torch.jit.TracerWarning, None, 0)\n    warnings.filters.insert(0, flt)\n    yield\n    warnings.filters.remove(flt)\n\n#----------------------------------------------------------------------------\n# Assert that the shape of a tensor matches the given list of integers.\n# None indicates that the size of a dimension is allowed to vary.\n# Performs symbolic assertion when used in torch.jit.trace().\n\ndef assert_shape(tensor, ref_shape):\n    if tensor.ndim != len(ref_shape):\n        raise AssertionError(f'Wrong number of dimensions: got {tensor.ndim}, expected {len(ref_shape)}')\n    for idx, (size, ref_size) in enumerate(zip(tensor.shape, ref_shape)):\n        if ref_size is None:\n            pass\n        elif isinstance(ref_size, torch.Tensor):\n            with suppress_tracer_warnings(): # as_tensor results are registered as constants\n                symbolic_assert(torch.equal(torch.as_tensor(size), ref_size), f'Wrong size for dimension {idx}')\n        elif isinstance(size, torch.Tensor):\n            with suppress_tracer_warnings(): # as_tensor results are registered as constants\n                symbolic_assert(torch.equal(size, torch.as_tensor(ref_size)), f'Wrong size for dimension {idx}: expected {ref_size}')\n        elif size != ref_size:\n            raise AssertionError(f'Wrong size for dimension {idx}: got {size}, expected {ref_size}')\n\n#----------------------------------------------------------------------------\n# Function decorator that calls torch.autograd.profiler.record_function().\n\ndef profiled_function(fn):\n    def decorator(*args, **kwargs):\n        with torch.autograd.profiler.record_function(fn.__name__):\n            return fn(*args, **kwargs)\n    decorator.__name__ = fn.__name__\n    return decorator\n\n#----------------------------------------------------------------------------\n# Sampler for torch.utils.data.DataLoader that loops over the dataset\n# indefinitely, shuffling items as it goes.\n\nclass InfiniteSampler(torch.utils.data.Sampler):\n    def __init__(self, dataset, rank=0, num_replicas=1, shuffle=True, seed=0, window_size=0.5):\n        assert len(dataset) > 0\n        assert num_replicas > 0\n        assert 0 <= rank < num_replicas\n        assert 0 <= window_size <= 1\n        super().__init__(dataset)\n        self.dataset = dataset\n        self.rank = rank\n        self.num_replicas = num_replicas\n        self.shuffle = shuffle\n        self.seed = seed\n        self.window_size = window_size\n\n    def __iter__(self):\n        order = np.arange(len(self.dataset))\n        rnd = None\n        window = 0\n        if self.shuffle:\n            rnd = np.random.RandomState(self.seed)\n            rnd.shuffle(order)\n            window = int(np.rint(order.size * self.window_size))\n\n        idx = 0\n        while True:\n            i = idx % order.size\n            if idx % self.num_replicas == self.rank:\n                yield order[i]\n            if window >= 2:\n                j = (i - rnd.randint(window)) % order.size\n                order[i], order[j] = order[j], order[i]\n            idx += 1\n\n#----------------------------------------------------------------------------\n# Utilities for operating with torch.nn.Module parameters and buffers.\n\ndef params_and_buffers(module):\n    assert isinstance(module, torch.nn.Module)\n    return list(module.parameters()) + list(module.buffers())\n\ndef named_params_and_buffers(module):\n    assert isinstance(module, torch.nn.Module)\n    return list(module.named_parameters()) + list(module.named_buffers())\n\n@torch.no_grad()\ndef copy_params_and_buffers(src_module, dst_module, require_all=False):\n    assert isinstance(src_module, torch.nn.Module)\n    assert isinstance(dst_module, torch.nn.Module)\n    src_tensors = dict(named_params_and_buffers(src_module))\n    for name, tensor in named_params_and_buffers(dst_module):\n        assert (name in src_tensors) or (not require_all)\n        if name in src_tensors:\n            tensor.copy_(src_tensors[name])\n\n#----------------------------------------------------------------------------\n# Context manager for easily enabling/disabling DistributedDataParallel\n# synchronization.\n\n@contextlib.contextmanager\ndef ddp_sync(module, sync):\n    assert isinstance(module, torch.nn.Module)\n    if sync or not isinstance(module, torch.nn.parallel.DistributedDataParallel):\n        yield\n    else:\n        with module.no_sync():\n            yield\n\n#----------------------------------------------------------------------------\n# Check DistributedDataParallel consistency across processes.\n\ndef check_ddp_consistency(module, ignore_regex=None):\n    assert isinstance(module, torch.nn.Module)\n    for name, tensor in named_params_and_buffers(module):\n        fullname = type(module).__name__ + '.' + name\n        if ignore_regex is not None and re.fullmatch(ignore_regex, fullname):\n            continue\n        tensor = tensor.detach()\n        if tensor.is_floating_point():\n            tensor = nan_to_num(tensor)\n        other = tensor.clone()\n        torch.distributed.broadcast(tensor=other, src=0)\n        assert (tensor == other).all(), fullname\n\n#----------------------------------------------------------------------------\n# Print summary table of module hierarchy.\n\ndef print_module_summary(module, inputs, max_nesting=3, skip_redundant=True):\n    assert isinstance(module, torch.nn.Module)\n    assert not isinstance(module, torch.jit.ScriptModule)\n    assert isinstance(inputs, (tuple, list))\n\n    # Register hooks.\n    entries = []\n    nesting = [0]\n    def pre_hook(_mod, _inputs):\n        nesting[0] += 1\n    def post_hook(mod, _inputs, outputs):\n        nesting[0] -= 1\n        if nesting[0] <= max_nesting:\n            outputs = list(outputs) if isinstance(outputs, (tuple, list)) else [outputs]\n            outputs = [t for t in outputs if isinstance(t, torch.Tensor)]\n            entries.append(dnnlib.EasyDict(mod=mod, outputs=outputs))\n    hooks = [mod.register_forward_pre_hook(pre_hook) for mod in module.modules()]\n    hooks += [mod.register_forward_hook(post_hook) for mod in module.modules()]\n\n    # Run module.\n    outputs = module(*inputs)\n    for hook in hooks:\n        hook.remove()\n\n    # Identify unique outputs, parameters, and buffers.\n    tensors_seen = set()\n    for e in entries:\n        e.unique_params = [t for t in e.mod.parameters() if id(t) not in tensors_seen]\n        e.unique_buffers = [t for t in e.mod.buffers() if id(t) not in tensors_seen]\n        e.unique_outputs = [t for t in e.outputs if id(t) not in tensors_seen]\n        tensors_seen |= {id(t) for t in e.unique_params + e.unique_buffers + e.unique_outputs}\n\n    # Filter out redundant entries.\n    if skip_redundant:\n        entries = [e for e in entries if len(e.unique_params) or len(e.unique_buffers) or len(e.unique_outputs)]\n\n    # Construct table.\n    rows = [[type(module).__name__, 'Parameters', 'Buffers', 'Output shape', 'Datatype']]\n    rows += [['---'] * len(rows[0])]\n    param_total = 0\n    buffer_total = 0\n    submodule_names = {mod: name for name, mod in module.named_modules()}\n    for e in entries:\n        name = '<top-level>' if e.mod is module else submodule_names[e.mod]\n        param_size = sum(t.numel() for t in e.unique_params)\n        buffer_size = sum(t.numel() for t in e.unique_buffers)\n        output_shapes = [str(list(t.shape)) for t in e.outputs]\n        output_dtypes = [str(t.dtype).split('.')[-1] for t in e.outputs]\n        rows += [[\n            name + (':0' if len(e.outputs) >= 2 else ''),\n            str(param_size) if param_size else '-',\n            str(buffer_size) if buffer_size else '-',\n            (output_shapes + ['-'])[0],\n            (output_dtypes + ['-'])[0],\n        ]]\n        for idx in range(1, len(e.outputs)):\n            rows += [[name + f':{idx}', '-', '-', output_shapes[idx], output_dtypes[idx]]]\n        param_total += param_size\n        buffer_total += buffer_size\n    rows += [['---'] * len(rows[0])]\n    rows += [['Total', str(param_total), str(buffer_total), '-', '-']]\n\n    # Print table.\n    widths = [max(len(cell) for cell in column) for column in zip(*rows)]\n    print()\n    for row in rows:\n        print('  '.join(cell + ' ' * (width - len(cell)) for cell, width in zip(row, widths)))\n    print()\n    return outputs\n\n#----------------------------------------------------------------------------\n",
    'model.edm.torch_utils.persistence': '# Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n#\n# This work is licensed under a Creative Commons\n# Attribution-NonCommercial-ShareAlike 4.0 International License.\n# You should have received a copy of the license along with this\n# work. If not, see http://creativecommons.org/licenses/by-nc-sa/4.0/\n\n"""Facilities for pickling Python code alongside other data.\n\nThe pickled code is automatically imported into a separate Python module\nduring unpickling. This way, any previously exported pickles will remain\nusable even if the original code is no longer available, or if the current\nversion of the code is not consistent with what was originally pickled."""\n\nimport sys\nimport pickle\nimport io\nimport inspect\nimport copy\nimport uuid\nimport types\nimport dnnlib\n\n#----------------------------------------------------------------------------\n\n_version            = 6         # internal version number\n_decorators         = set()     # {decorator_class, ...}\n_import_hooks       = []        # [hook_function, ...]\n_module_to_src_dict = dict()    # {module: src, ...}\n_src_to_module_dict = dict()    # {src: module, ...}\n\n#----------------------------------------------------------------------------\n\ndef persistent_class(orig_class):\n    r"""Class decorator that extends a given class to save its source code\n    when pickled.\n\n    Example:\n\n        from torch_utils import persistence\n\n        @persistence.persistent_class\n        class MyNetwork(torch.nn.Module):\n            def __init__(self, num_inputs, num_outputs):\n                super().__init__()\n                self.fc = MyLayer(num_inputs, num_outputs)\n                ...\n\n        @persistence.persistent_class\n        class MyLayer(torch.nn.Module):\n            ...\n\n    When pickled, any instance of `MyNetwork` and `MyLayer` will save its\n    source code alongside other internal state (e.g., parameters, buffers,\n    and submodules). This way, any previously exported pickle will remain\n    usable even if the class definitions have been modified or are no\n    longer available.\n\n    The decorator saves the source code of the entire Python module\n    containing the decorated class. It does *not* save the source code of\n    any imported modules. Thus, the imported modules must be available\n    during unpickling, also including `torch_utils.persistence` itself.\n\n    It is ok to call functions defined in the same module from the\n    decorated class. However, if the decorated class depends on other\n    classes defined in the same module, they must be decorated as well.\n    This is illustrated in the above example in the case of `MyLayer`.\n\n    It is also possible to employ the decorator just-in-time before\n    calling the constructor. For example:\n\n        cls = MyLayer\n        if want_to_make_it_persistent:\n            cls = persistence.persistent_class(cls)\n        layer = cls(num_inputs, num_outputs)\n\n    As an additional feature, the decorator also keeps track of the\n    arguments that were used to construct each instance of the decorated\n    class. The arguments can be queried via `obj.init_args` and\n    `obj.init_kwargs`, and they are automatically pickled alongside other\n    object state. This feature can be disabled on a per-instance basis\n    by setting `self._record_init_args = False` in the constructor.\n\n    A typical use case is to first unpickle a previous instance of a\n    persistent class, and then upgrade it to use the latest version of\n    the source code:\n\n        with open(\'old_pickle.pkl\', \'rb\') as f:\n            old_net = pickle.load(f)\n        new_net = MyNetwork(*old_obj.init_args, **old_obj.init_kwargs)\n        misc.copy_params_and_buffers(old_net, new_net, require_all=True)\n    """\n    assert isinstance(orig_class, type)\n    if is_persistent(orig_class):\n        return orig_class\n\n    assert orig_class.__module__ in sys.modules\n    orig_module = sys.modules[orig_class.__module__]\n    orig_module_src = _module_to_src(orig_module)\n\n    class Decorator(orig_class):\n        _orig_module_src = orig_module_src\n        _orig_class_name = orig_class.__name__\n\n        def __init__(self, *args, **kwargs):\n            super().__init__(*args, **kwargs)\n            record_init_args = getattr(self, \'_record_init_args\', True)\n            self._init_args = copy.deepcopy(args) if record_init_args else None\n            self._init_kwargs = copy.deepcopy(kwargs) if record_init_args else None\n            assert orig_class.__name__ in orig_module.__dict__\n            _check_pickleable(self.__reduce__())\n\n        @property\n        def init_args(self):\n            assert self._init_args is not None\n            return copy.deepcopy(self._init_args)\n\n        @property\n        def init_kwargs(self):\n            assert self._init_kwargs is not None\n            return dnnlib.EasyDict(copy.deepcopy(self._init_kwargs))\n\n        def __reduce__(self):\n            fields = list(super().__reduce__())\n            fields += [None] * max(3 - len(fields), 0)\n            if fields[0] is not _reconstruct_persistent_obj:\n                meta = dict(type=\'class\', version=_version, module_src=self._orig_module_src, class_name=self._orig_class_name, state=fields[2])\n                fields[0] = _reconstruct_persistent_obj # reconstruct func\n                fields[1] = (meta,) # reconstruct args\n                fields[2] = None # state dict\n            return tuple(fields)\n\n    Decorator.__name__ = orig_class.__name__\n    Decorator.__module__ = orig_class.__module__\n    _decorators.add(Decorator)\n    return Decorator\n\n#----------------------------------------------------------------------------\n\ndef is_persistent(obj):\n    r"""Test whether the given object or class is persistent, i.e.,\n    whether it will save its source code when pickled.\n    """\n    try:\n        if obj in _decorators:\n            return True\n    except TypeError:\n        pass\n    return type(obj) in _decorators # pylint: disable=unidiomatic-typecheck\n\n#----------------------------------------------------------------------------\n\ndef import_hook(hook):\n    r"""Register an import hook that is called whenever a persistent object\n    is being unpickled. A typical use case is to patch the pickled source\n    code to avoid errors and inconsistencies when the API of some imported\n    module has changed.\n\n    The hook should have the following signature:\n\n        hook(meta) -> modified meta\n\n    `meta` is an instance of `dnnlib.EasyDict` with the following fields:\n\n        type:       Type of the persistent object, e.g. `\'class\'`.\n        version:    Internal version number of `torch_utils.persistence`.\n        module_src  Original source code of the Python module.\n        class_name: Class name in the original Python module.\n        state:      Internal state of the object.\n\n    Example:\n\n        @persistence.import_hook\n        def wreck_my_network(meta):\n            if meta.class_name == \'MyNetwork\':\n                print(\'MyNetwork is being imported. I will wreck it!\')\n                meta.module_src = meta.module_src.replace("True", "False")\n            return meta\n    """\n    assert callable(hook)\n    _import_hooks.append(hook)\n\n#----------------------------------------------------------------------------\n\ndef _reconstruct_persistent_obj(meta):\n    r"""Hook that is called internally by the `pickle` module to unpickle\n    a persistent object.\n    """\n    meta = dnnlib.EasyDict(meta)\n    meta.state = dnnlib.EasyDict(meta.state)\n    for hook in _import_hooks:\n        meta = hook(meta)\n        assert meta is not None\n\n    assert meta.version == _version\n    module = _src_to_module(meta.module_src)\n\n    assert meta.type == \'class\'\n    orig_class = module.__dict__[meta.class_name]\n    decorator_class = persistent_class(orig_class)\n    obj = decorator_class.__new__(decorator_class)\n\n    setstate = getattr(obj, \'__setstate__\', None)\n    if callable(setstate):\n        setstate(meta.state) # pylint: disable=not-callable\n    else:\n        obj.__dict__.update(meta.state)\n    return obj\n\n#----------------------------------------------------------------------------\n\ndef _module_to_src(module):\n    r"""Query the source code of a given Python module.\n    """\n    src = _module_to_src_dict.get(module, None)\n    if src is None:\n        src = inspect.getsource(module)\n        _module_to_src_dict[module] = src\n        _src_to_module_dict[src] = module\n    return src\n\ndef _src_to_module(src):\n    r"""Get or create a Python module for the given source code.\n    """\n    module = _src_to_module_dict.get(src, None)\n    if module is None:\n        module_name = "_imported_module_" + uuid.uuid4().hex\n        module = types.ModuleType(module_name)\n        sys.modules[module_name] = module\n        _module_to_src_dict[module] = src\n        _src_to_module_dict[src] = module\n        exec(src, module.__dict__) # pylint: disable=exec-used\n    return module\n\n#----------------------------------------------------------------------------\n\ndef _check_pickleable(obj):\n    r"""Check that the given object is pickleable, raising an exception if\n    it is not. This function is expected to be considerably more efficient\n    than actually pickling the object.\n    """\n    def recurse(obj):\n        if isinstance(obj, (list, tuple, set)):\n            return [recurse(x) for x in obj]\n        if isinstance(obj, dict):\n            return [[recurse(x), recurse(y)] for x, y in obj.items()]\n        if isinstance(obj, (str, int, float, bool, bytes, bytearray)):\n            return None # Python primitive types are pickleable.\n        if f\'{type(obj).__module__}.{type(obj).__name__}\' in [\'numpy.ndarray\', \'torch.Tensor\', \'torch.nn.parameter.Parameter\']:\n            return None # NumPy arrays and PyTorch tensors are pickleable.\n        if is_persistent(obj):\n            return None # Persistent objects are pickleable, by virtue of the constructor check.\n        return obj\n    with io.BytesIO() as f:\n        pickle.dump(recurse(obj), f)\n\n#----------------------------------------------------------------------------\n',
    'model.edm.torch_utils.training_stats': '# Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n#\n# This work is licensed under a Creative Commons\n# Attribution-NonCommercial-ShareAlike 4.0 International License.\n# You should have received a copy of the license along with this\n# work. If not, see http://creativecommons.org/licenses/by-nc-sa/4.0/\n\n"""Facilities for reporting and collecting training statistics across\nmultiple processes and devices. The interface is designed to minimize\nsynchronization overhead as well as the amount of boilerplate in user\ncode."""\n\nimport re\nimport numpy as np\nimport torch\nimport dnnlib\n\nfrom . import misc\n\n#----------------------------------------------------------------------------\n\n_num_moments    = 3             # [num_scalars, sum_of_scalars, sum_of_squares]\n_reduce_dtype   = torch.float32 # Data type to use for initial per-tensor reduction.\n_counter_dtype  = torch.float64 # Data type to use for the internal counters.\n_rank           = 0             # Rank of the current process.\n_sync_device    = None          # Device to use for multiprocess communication. None = single-process.\n_sync_called    = False         # Has _sync() been called yet?\n_counters       = dict()        # Running counters on each device, updated by report(): name => device => torch.Tensor\n_cumulative     = dict()        # Cumulative counters on the CPU, updated by _sync(): name => torch.Tensor\n\n#----------------------------------------------------------------------------\n\ndef init_multiprocessing(rank, sync_device):\n    r"""Initializes `torch_utils.training_stats` for collecting statistics\n    across multiple processes.\n\n    This function must be called after\n    `torch.distributed.init_process_group()` and before `Collector.update()`.\n    The call is not necessary if multi-process collection is not needed.\n\n    Args:\n        rank:           Rank of the current process.\n        sync_device:    PyTorch device to use for inter-process\n                        communication, or None to disable multi-process\n                        collection. Typically `torch.device(\'cuda\', rank)`.\n    """\n    global _rank, _sync_device\n    assert not _sync_called\n    _rank = rank\n    _sync_device = sync_device\n\n#----------------------------------------------------------------------------\n\n@misc.profiled_function\ndef report(name, value):\n    r"""Broadcasts the given set of scalars to all interested instances of\n    `Collector`, across device and process boundaries.\n\n    This function is expected to be extremely cheap and can be safely\n    called from anywhere in the training loop, loss function, or inside a\n    `torch.nn.Module`.\n\n    Warning: The current implementation expects the set of unique names to\n    be consistent across processes. Please make sure that `report()` is\n    called at least once for each unique name by each process, and in the\n    same order. If a given process has no scalars to broadcast, it can do\n    `report(name, [])` (empty list).\n\n    Args:\n        name:   Arbitrary string specifying the name of the statistic.\n                Averages are accumulated separately for each unique name.\n        value:  Arbitrary set of scalars. Can be a list, tuple,\n                NumPy array, PyTorch tensor, or Python scalar.\n\n    Returns:\n        The same `value` that was passed in.\n    """\n    if name not in _counters:\n        _counters[name] = dict()\n\n    elems = torch.as_tensor(value)\n    if elems.numel() == 0:\n        return value\n\n    elems = elems.detach().flatten().to(_reduce_dtype)\n    moments = torch.stack([\n        torch.ones_like(elems).sum(),\n        elems.sum(),\n        elems.square().sum(),\n    ])\n    assert moments.ndim == 1 and moments.shape[0] == _num_moments\n    moments = moments.to(_counter_dtype)\n\n    device = moments.device\n    if device not in _counters[name]:\n        _counters[name][device] = torch.zeros_like(moments)\n    _counters[name][device].add_(moments)\n    return value\n\n#----------------------------------------------------------------------------\n\ndef report0(name, value):\n    r"""Broadcasts the given set of scalars by the first process (`rank = 0`),\n    but ignores any scalars provided by the other processes.\n    See `report()` for further details.\n    """\n    report(name, value if _rank == 0 else [])\n    return value\n\n#----------------------------------------------------------------------------\n\nclass Collector:\n    r"""Collects the scalars broadcasted by `report()` and `report0()` and\n    computes their long-term averages (mean and standard deviation) over\n    user-defined periods of time.\n\n    The averages are first collected into internal counters that are not\n    directly visible to the user. They are then copied to the user-visible\n    state as a result of calling `update()` and can then be queried using\n    `mean()`, `std()`, `as_dict()`, etc. Calling `update()` also resets the\n    internal counters for the next round, so that the user-visible state\n    effectively reflects averages collected between the last two calls to\n    `update()`.\n\n    Args:\n        regex:          Regular expression defining which statistics to\n                        collect. The default is to collect everything.\n        keep_previous:  Whether to retain the previous averages if no\n                        scalars were collected on a given round\n                        (default: True).\n    """\n    def __init__(self, regex=\'.*\', keep_previous=True):\n        self._regex = re.compile(regex)\n        self._keep_previous = keep_previous\n        self._cumulative = dict()\n        self._moments = dict()\n        self.update()\n        self._moments.clear()\n\n    def names(self):\n        r"""Returns the names of all statistics broadcasted so far that\n        match the regular expression specified at construction time.\n        """\n        return [name for name in _counters if self._regex.fullmatch(name)]\n\n    def update(self):\n        r"""Copies current values of the internal counters to the\n        user-visible state and resets them for the next round.\n\n        If `keep_previous=True` was specified at construction time, the\n        operation is skipped for statistics that have received no scalars\n        since the last update, retaining their previous averages.\n\n        This method performs a number of GPU-to-CPU transfers and one\n        `torch.distributed.all_reduce()`. It is intended to be called\n        periodically in the main training loop, typically once every\n        N training steps.\n        """\n        if not self._keep_previous:\n            self._moments.clear()\n        for name, cumulative in _sync(self.names()):\n            if name not in self._cumulative:\n                self._cumulative[name] = torch.zeros([_num_moments], dtype=_counter_dtype)\n            delta = cumulative - self._cumulative[name]\n            self._cumulative[name].copy_(cumulative)\n            if float(delta[0]) != 0:\n                self._moments[name] = delta\n\n    def _get_delta(self, name):\n        r"""Returns the raw moments that were accumulated for the given\n        statistic between the last two calls to `update()`, or zero if\n        no scalars were collected.\n        """\n        assert self._regex.fullmatch(name)\n        if name not in self._moments:\n            self._moments[name] = torch.zeros([_num_moments], dtype=_counter_dtype)\n        return self._moments[name]\n\n    def num(self, name):\n        r"""Returns the number of scalars that were accumulated for the given\n        statistic between the last two calls to `update()`, or zero if\n        no scalars were collected.\n        """\n        delta = self._get_delta(name)\n        return int(delta[0])\n\n    def mean(self, name):\n        r"""Returns the mean of the scalars that were accumulated for the\n        given statistic between the last two calls to `update()`, or NaN if\n        no scalars were collected.\n        """\n        delta = self._get_delta(name)\n        if int(delta[0]) == 0:\n            return float(\'nan\')\n        return float(delta[1] / delta[0])\n\n    def std(self, name):\n        r"""Returns the standard deviation of the scalars that were\n        accumulated for the given statistic between the last two calls to\n        `update()`, or NaN if no scalars were collected.\n        """\n        delta = self._get_delta(name)\n        if int(delta[0]) == 0 or not np.isfinite(float(delta[1])):\n            return float(\'nan\')\n        if int(delta[0]) == 1:\n            return float(0)\n        mean = float(delta[1] / delta[0])\n        raw_var = float(delta[2] / delta[0])\n        return np.sqrt(max(raw_var - np.square(mean), 0))\n\n    def as_dict(self):\n        r"""Returns the averages accumulated between the last two calls to\n        `update()` as an `dnnlib.EasyDict`. The contents are as follows:\n\n            dnnlib.EasyDict(\n                NAME = dnnlib.EasyDict(num=FLOAT, mean=FLOAT, std=FLOAT),\n                ...\n            )\n        """\n        stats = dnnlib.EasyDict()\n        for name in self.names():\n            stats[name] = dnnlib.EasyDict(num=self.num(name), mean=self.mean(name), std=self.std(name))\n        return stats\n\n    def __getitem__(self, name):\n        r"""Convenience getter.\n        `collector[name]` is a synonym for `collector.mean(name)`.\n        """\n        return self.mean(name)\n\n#----------------------------------------------------------------------------\n\ndef _sync(names):\n    r"""Synchronize the global cumulative counters across devices and\n    processes. Called internally by `Collector.update()`.\n    """\n    if len(names) == 0:\n        return []\n    global _sync_called\n    _sync_called = True\n\n    # Collect deltas within current rank.\n    deltas = []\n    device = _sync_device if _sync_device is not None else torch.device(\'cpu\')\n    for name in names:\n        delta = torch.zeros([_num_moments], dtype=_counter_dtype, device=device)\n        for counter in _counters[name].values():\n            delta.add_(counter.to(device))\n            counter.copy_(torch.zeros_like(counter))\n        deltas.append(delta)\n    deltas = torch.stack(deltas)\n\n    # Sum deltas across ranks.\n    if _sync_device is not None:\n        torch.distributed.all_reduce(deltas)\n\n    # Update cumulative values.\n    deltas = deltas.cpu()\n    for idx, name in enumerate(names):\n        if name not in _cumulative:\n            _cumulative[name] = torch.zeros([_num_moments], dtype=_counter_dtype)\n        _cumulative[name].add_(deltas[idx])\n\n    # Return name-value pairs.\n    return [(name, _cumulative[name]) for name in names]\n\n#----------------------------------------------------------------------------\n# Convenience.\n\ndefault_collector = Collector()\n\n#----------------------------------------------------------------------------\n',
    'model.ldm': '',
    'model.ldm.data': '',
    'model.ldm.data.base': "from abc import abstractmethod\nfrom torch.utils.data import Dataset, ConcatDataset, ChainDataset, IterableDataset\n\n\nclass Txt2ImgIterableBaseDataset(IterableDataset):\n    '''\n    Define an interface to make the IterableDatasets for text2img data chainable\n    '''\n    def __init__(self, num_records=0, valid_ids=None, size=256):\n        super().__init__()\n        self.num_records = num_records\n        self.valid_ids = valid_ids\n        self.sample_ids = valid_ids\n        self.size = size\n\n        print(f'{self.__class__.__name__} dataset contains {self.__len__()} examples.')\n\n    def __len__(self):\n        return self.num_records\n\n    @abstractmethod\n    def __iter__(self):\n        pass",
    'model.ldm.data.imagenet': 'import os, yaml, pickle, shutil, tarfile, glob\nimport cv2\nimport albumentations\nimport PIL\nimport numpy as np\nimport torchvision.transforms.functional as TF\nfrom omegaconf import OmegaConf\nfrom functools import partial\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom torch.utils.data import Dataset, Subset\n\nimport taming.data.utils as tdu\nfrom taming.data.imagenet import str_to_indices, give_synsets_from_indices, download, retrieve\nfrom taming.data.imagenet import ImagePaths\n\nfrom model.ldm.modules.image_degradation import degradation_fn_bsr, degradation_fn_bsr_light\n\n\ndef synset2idx(path_to_yaml="data/index_synset.yaml"):\n    with open(path_to_yaml) as f:\n        di2s = yaml.load(f)\n    return dict((v,k) for k,v in di2s.items())\n\n\nclass ImageNetBase(Dataset):\n    def __init__(self, config=None):\n        self.config = config or OmegaConf.create()\n        if not type(self.config)==dict:\n            self.config = OmegaConf.to_container(self.config)\n        self.keep_orig_class_label = self.config.get("keep_orig_class_label", False)\n        self.process_images = True  # if False we skip loading & processing images and self.data contains filepaths\n        self._prepare()\n        self._prepare_synset_to_human()\n        self._prepare_idx_to_synset()\n        self._prepare_human_to_integer_label()\n        self._load()\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, i):\n        return self.data[i]\n\n    def _prepare(self):\n        raise NotImplementedError()\n\n    def _filter_relpaths(self, relpaths):\n        ignore = set([\n            "n06596364_9591.JPEG",\n        ])\n        relpaths = [rpath for rpath in relpaths if not rpath.split("/")[-1] in ignore]\n        if "sub_indices" in self.config:\n            indices = str_to_indices(self.config["sub_indices"])\n            synsets = give_synsets_from_indices(indices, path_to_yaml=self.idx2syn)  # returns a list of strings\n            self.synset2idx = synset2idx(path_to_yaml=self.idx2syn)\n            files = []\n            for rpath in relpaths:\n                syn = rpath.split("/")[0]\n                if syn in synsets:\n                    files.append(rpath)\n            return files\n        else:\n            return relpaths\n\n    def _prepare_synset_to_human(self):\n        SIZE = 2655750\n        URL = "https://heibox.uni-heidelberg.de/f/9f28e956cd304264bb82/?dl=1"\n        self.human_dict = os.path.join(self.root, "synset_human.txt")\n        if (not os.path.exists(self.human_dict) or\n                not os.path.getsize(self.human_dict)==SIZE):\n            download(URL, self.human_dict)\n\n    def _prepare_idx_to_synset(self):\n        URL = "https://heibox.uni-heidelberg.de/f/d835d5b6ceda4d3aa910/?dl=1"\n        self.idx2syn = os.path.join(self.root, "index_synset.yaml")\n        if (not os.path.exists(self.idx2syn)):\n            download(URL, self.idx2syn)\n\n    def _prepare_human_to_integer_label(self):\n        URL = "https://heibox.uni-heidelberg.de/f/2362b797d5be43b883f6/?dl=1"\n        self.human2integer = os.path.join(self.root, "imagenet1000_clsidx_to_labels.txt")\n        if (not os.path.exists(self.human2integer)):\n            download(URL, self.human2integer)\n        with open(self.human2integer, "r") as f:\n            lines = f.read().splitlines()\n            assert len(lines) == 1000\n            self.human2integer_dict = dict()\n            for line in lines:\n                value, key = line.split(":")\n                self.human2integer_dict[key] = int(value)\n\n    def _load(self):\n        with open(self.txt_filelist, "r") as f:\n            self.relpaths = f.read().splitlines()\n            l1 = len(self.relpaths)\n            self.relpaths = self._filter_relpaths(self.relpaths)\n            print("Removed {} files from filelist during filtering.".format(l1 - len(self.relpaths)))\n\n        self.synsets = [p.split("/")[0] for p in self.relpaths]\n        self.abspaths = [os.path.join(self.datadir, p) for p in self.relpaths]\n\n        unique_synsets = np.unique(self.synsets)\n        class_dict = dict((synset, i) for i, synset in enumerate(unique_synsets))\n        if not self.keep_orig_class_label:\n            self.class_labels = [class_dict[s] for s in self.synsets]\n        else:\n            self.class_labels = [self.synset2idx[s] for s in self.synsets]\n\n        with open(self.human_dict, "r") as f:\n            human_dict = f.read().splitlines()\n            human_dict = dict(line.split(maxsplit=1) for line in human_dict)\n\n        self.human_labels = [human_dict[s] for s in self.synsets]\n\n        labels = {\n            "relpath": np.array(self.relpaths),\n            "synsets": np.array(self.synsets),\n            "class_label": np.array(self.class_labels),\n            "human_label": np.array(self.human_labels),\n        }\n\n        if self.process_images:\n            self.size = retrieve(self.config, "size", default=256)\n            self.data = ImagePaths(self.abspaths,\n                                   labels=labels,\n                                   size=self.size,\n                                   random_crop=self.random_crop,\n                                   )\n        else:\n            self.data = self.abspaths\n\n\nclass ImageNetTrain(ImageNetBase):\n    NAME = "ILSVRC2012_train"\n    URL = "http://www.image-net.org/challenges/LSVRC/2012/"\n    AT_HASH = "a306397ccf9c2ead27155983c254227c0fd938e2"\n    FILES = [\n        "ILSVRC2012_img_train.tar",\n    ]\n    SIZES = [\n        147897477120,\n    ]\n\n    def __init__(self, process_images=True, data_root=None, **kwargs):\n        self.process_images = process_images\n        self.data_root = data_root\n        super().__init__(**kwargs)\n\n    def _prepare(self):\n        if self.data_root:\n            self.root = os.path.join(self.data_root, self.NAME)\n        else:\n            cachedir = os.environ.get("XDG_CACHE_HOME", os.path.expanduser("~/.cache"))\n            self.root = os.path.join(cachedir, "autoencoders/data", self.NAME)\n\n        self.datadir = os.path.join(self.root, "data")\n        self.txt_filelist = os.path.join(self.root, "filelist.txt")\n        self.expected_length = 1281167\n        self.random_crop = retrieve(self.config, "ImageNetTrain/random_crop",\n                                    default=True)\n        if not tdu.is_prepared(self.root):\n            # prep\n            print("Preparing dataset {} in {}".format(self.NAME, self.root))\n\n            datadir = self.datadir\n            if not os.path.exists(datadir):\n                path = os.path.join(self.root, self.FILES[0])\n                if not os.path.exists(path) or not os.path.getsize(path)==self.SIZES[0]:\n                    import academictorrents as at\n                    atpath = at.get(self.AT_HASH, datastore=self.root)\n                    assert atpath == path\n\n                print("Extracting {} to {}".format(path, datadir))\n                os.makedirs(datadir, exist_ok=True)\n                with tarfile.open(path, "r:") as tar:\n                    tar.extractall(path=datadir)\n\n                print("Extracting sub-tars.")\n                subpaths = sorted(glob.glob(os.path.join(datadir, "*.tar")))\n                for subpath in tqdm(subpaths):\n                    subdir = subpath[:-len(".tar")]\n                    os.makedirs(subdir, exist_ok=True)\n                    with tarfile.open(subpath, "r:") as tar:\n                        tar.extractall(path=subdir)\n\n            filelist = glob.glob(os.path.join(datadir, "**", "*.JPEG"))\n            filelist = [os.path.relpath(p, start=datadir) for p in filelist]\n            filelist = sorted(filelist)\n            filelist = "\\n".join(filelist)+"\\n"\n            with open(self.txt_filelist, "w") as f:\n                f.write(filelist)\n\n            tdu.mark_prepared(self.root)\n\n\nclass ImageNetValidation(ImageNetBase):\n    NAME = "ILSVRC2012_validation"\n    URL = "http://www.image-net.org/challenges/LSVRC/2012/"\n    AT_HASH = "5d6d0df7ed81efd49ca99ea4737e0ae5e3a5f2e5"\n    VS_URL = "https://heibox.uni-heidelberg.de/f/3e0f6e9c624e45f2bd73/?dl=1"\n    FILES = [\n        "ILSVRC2012_img_val.tar",\n        "validation_synset.txt",\n    ]\n    SIZES = [\n        6744924160,\n        1950000,\n    ]\n\n    def __init__(self, process_images=True, data_root=None, **kwargs):\n        self.data_root = data_root\n        self.process_images = process_images\n        super().__init__(**kwargs)\n\n    def _prepare(self):\n        if self.data_root:\n            self.root = os.path.join(self.data_root, self.NAME)\n        else:\n            cachedir = os.environ.get("XDG_CACHE_HOME", os.path.expanduser("~/.cache"))\n            self.root = os.path.join(cachedir, "autoencoders/data", self.NAME)\n        self.datadir = os.path.join(self.root, "data")\n        self.txt_filelist = os.path.join(self.root, "filelist.txt")\n        self.expected_length = 50000\n        self.random_crop = retrieve(self.config, "ImageNetValidation/random_crop",\n                                    default=False)\n        if not tdu.is_prepared(self.root):\n            # prep\n            print("Preparing dataset {} in {}".format(self.NAME, self.root))\n\n            datadir = self.datadir\n            if not os.path.exists(datadir):\n                path = os.path.join(self.root, self.FILES[0])\n                if not os.path.exists(path) or not os.path.getsize(path)==self.SIZES[0]:\n                    import academictorrents as at\n                    atpath = at.get(self.AT_HASH, datastore=self.root)\n                    assert atpath == path\n\n                print("Extracting {} to {}".format(path, datadir))\n                os.makedirs(datadir, exist_ok=True)\n                with tarfile.open(path, "r:") as tar:\n                    tar.extractall(path=datadir)\n\n                vspath = os.path.join(self.root, self.FILES[1])\n                if not os.path.exists(vspath) or not os.path.getsize(vspath)==self.SIZES[1]:\n                    download(self.VS_URL, vspath)\n\n                with open(vspath, "r") as f:\n                    synset_dict = f.read().splitlines()\n                    synset_dict = dict(line.split() for line in synset_dict)\n\n                print("Reorganizing into synset folders")\n                synsets = np.unique(list(synset_dict.values()))\n                for s in synsets:\n                    os.makedirs(os.path.join(datadir, s), exist_ok=True)\n                for k, v in synset_dict.items():\n                    src = os.path.join(datadir, k)\n                    dst = os.path.join(datadir, v)\n                    shutil.move(src, dst)\n\n            filelist = glob.glob(os.path.join(datadir, "**", "*.JPEG"))\n            filelist = [os.path.relpath(p, start=datadir) for p in filelist]\n            filelist = sorted(filelist)\n            filelist = "\\n".join(filelist)+"\\n"\n            with open(self.txt_filelist, "w") as f:\n                f.write(filelist)\n\n            tdu.mark_prepared(self.root)\n\n\n\nclass ImageNetSR(Dataset):\n    def __init__(self, size=None,\n                 degradation=None, downscale_f=4, min_crop_f=0.5, max_crop_f=1.,\n                 random_crop=True):\n        """\n        Imagenet Superresolution Dataloader\n        Performs following ops in order:\n        1.  crops a crop of size s from image either as random or center crop\n        2.  resizes crop to size with cv2.area_interpolation\n        3.  degrades resized crop with degradation_fn\n\n        :param size: resizing to size after cropping\n        :param degradation: degradation_fn, e.g. cv_bicubic or bsrgan_light\n        :param downscale_f: Low Resolution Downsample factor\n        :param min_crop_f: determines crop size s,\n          where s = c * min_img_side_len with c sampled from interval (min_crop_f, max_crop_f)\n        :param max_crop_f: ""\n        :param data_root:\n        :param random_crop:\n        """\n        self.base = self.get_base()\n        assert size\n        assert (size / downscale_f).is_integer()\n        self.size = size\n        self.LR_size = int(size / downscale_f)\n        self.min_crop_f = min_crop_f\n        self.max_crop_f = max_crop_f\n        assert(max_crop_f <= 1.)\n        self.center_crop = not random_crop\n\n        self.image_rescaler = albumentations.SmallestMaxSize(max_size=size, interpolation=cv2.INTER_AREA)\n\n        self.pil_interpolation = False # gets reset later if incase interp_op is from pillow\n\n        if degradation == "bsrgan":\n            self.degradation_process = partial(degradation_fn_bsr, sf=downscale_f)\n\n        elif degradation == "bsrgan_light":\n            self.degradation_process = partial(degradation_fn_bsr_light, sf=downscale_f)\n\n        else:\n            interpolation_fn = {\n            "cv_nearest": cv2.INTER_NEAREST,\n            "cv_bilinear": cv2.INTER_LINEAR,\n            "cv_bicubic": cv2.INTER_CUBIC,\n            "cv_area": cv2.INTER_AREA,\n            "cv_lanczos": cv2.INTER_LANCZOS4,\n            "pil_nearest": PIL.Image.NEAREST,\n            "pil_bilinear": PIL.Image.BILINEAR,\n            "pil_bicubic": PIL.Image.BICUBIC,\n            "pil_box": PIL.Image.BOX,\n            "pil_hamming": PIL.Image.HAMMING,\n            "pil_lanczos": PIL.Image.LANCZOS,\n            }[degradation]\n\n            self.pil_interpolation = degradation.startswith("pil_")\n\n            if self.pil_interpolation:\n                self.degradation_process = partial(TF.resize, size=self.LR_size, interpolation=interpolation_fn)\n\n            else:\n                self.degradation_process = albumentations.SmallestMaxSize(max_size=self.LR_size,\n                                                                          interpolation=interpolation_fn)\n\n    def __len__(self):\n        return len(self.base)\n\n    def __getitem__(self, i):\n        example = self.base[i]\n        image = Image.open(example["file_path_"])\n\n        if not image.mode == "RGB":\n            image = image.convert("RGB")\n\n        image = np.array(image).astype(np.uint8)\n\n        min_side_len = min(image.shape[:2])\n        crop_side_len = min_side_len * np.random.uniform(self.min_crop_f, self.max_crop_f, size=None)\n        crop_side_len = int(crop_side_len)\n\n        if self.center_crop:\n            self.cropper = albumentations.CenterCrop(height=crop_side_len, width=crop_side_len)\n\n        else:\n            self.cropper = albumentations.RandomCrop(height=crop_side_len, width=crop_side_len)\n\n        image = self.cropper(image=image)["image"]\n        image = self.image_rescaler(image=image)["image"]\n\n        if self.pil_interpolation:\n            image_pil = PIL.Image.fromarray(image)\n            LR_image = self.degradation_process(image_pil)\n            LR_image = np.array(LR_image).astype(np.uint8)\n\n        else:\n            LR_image = self.degradation_process(image=image)["image"]\n\n        example["image"] = (image/127.5 - 1.0).astype(np.float32)\n        example["LR_image"] = (LR_image/127.5 - 1.0).astype(np.float32)\n\n        return example\n\n\nclass ImageNetSRTrain(ImageNetSR):\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n\n    def get_base(self):\n        with open("data/imagenet_train_hr_indices.p", "rb") as f:\n            indices = pickle.load(f)\n        dset = ImageNetTrain(process_images=False,)\n        return Subset(dset, indices)\n\n\nclass ImageNetSRValidation(ImageNetSR):\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n\n    def get_base(self):\n        with open("data/imagenet_val_hr_indices.p", "rb") as f:\n            indices = pickle.load(f)\n        dset = ImageNetValidation(process_images=False,)\n        return Subset(dset, indices)\n',
    'model.ldm.data.lsun': 'import os\nimport numpy as np\nimport PIL\nfrom PIL import Image\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\n\n\nclass LSUNBase(Dataset):\n    def __init__(self,\n                 txt_file,\n                 data_root,\n                 size=None,\n                 interpolation="bicubic",\n                 flip_p=0.5\n                 ):\n        self.data_paths = txt_file\n        self.data_root = data_root\n        with open(self.data_paths, "r") as f:\n            self.image_paths = f.read().splitlines()\n        self._length = len(self.image_paths)\n        self.labels = {\n            "relative_file_path_": [l for l in self.image_paths],\n            "file_path_": [os.path.join(self.data_root, l)\n                           for l in self.image_paths],\n        }\n\n        self.size = size\n        self.interpolation = {"linear": PIL.Image.LINEAR,\n                              "bilinear": PIL.Image.BILINEAR,\n                              "bicubic": PIL.Image.BICUBIC,\n                              "lanczos": PIL.Image.LANCZOS,\n                              }[interpolation]\n        self.flip = transforms.RandomHorizontalFlip(p=flip_p)\n\n    def __len__(self):\n        return self._length\n\n    def __getitem__(self, i):\n        example = dict((k, self.labels[k][i]) for k in self.labels)\n        image = Image.open(example["file_path_"])\n        if not image.mode == "RGB":\n            image = image.convert("RGB")\n\n        # default to score-sde preprocessing\n        img = np.array(image).astype(np.uint8)\n        crop = min(img.shape[0], img.shape[1])\n        h, w, = img.shape[0], img.shape[1]\n        img = img[(h - crop) // 2:(h + crop) // 2,\n              (w - crop) // 2:(w + crop) // 2]\n\n        image = Image.fromarray(img)\n        if self.size is not None:\n            image = image.resize((self.size, self.size), resample=self.interpolation)\n\n        image = self.flip(image)\n        image = np.array(image).astype(np.uint8)\n        example["image"] = (image / 127.5 - 1.0).astype(np.float32)\n        return example\n\n\nclass LSUNChurchesTrain(LSUNBase):\n    def __init__(self, **kwargs):\n        super().__init__(txt_file="data/lsun/church_outdoor_train.txt", data_root="data/lsun/churches", **kwargs)\n\n\nclass LSUNChurchesValidation(LSUNBase):\n    def __init__(self, flip_p=0., **kwargs):\n        super().__init__(txt_file="data/lsun/church_outdoor_val.txt", data_root="data/lsun/churches",\n                         flip_p=flip_p, **kwargs)\n\n\nclass LSUNBedroomsTrain(LSUNBase):\n    def __init__(self, **kwargs):\n        super().__init__(txt_file="data/lsun/bedrooms_train.txt", data_root="data/lsun/bedrooms", **kwargs)\n\n\nclass LSUNBedroomsValidation(LSUNBase):\n    def __init__(self, flip_p=0.0, **kwargs):\n        super().__init__(txt_file="data/lsun/bedrooms_val.txt", data_root="data/lsun/bedrooms",\n                         flip_p=flip_p, **kwargs)\n\n\nclass LSUNCatsTrain(LSUNBase):\n    def __init__(self, **kwargs):\n        super().__init__(txt_file="data/lsun/cat_train.txt", data_root="data/lsun/cats", **kwargs)\n\n\nclass LSUNCatsValidation(LSUNBase):\n    def __init__(self, flip_p=0., **kwargs):\n        super().__init__(txt_file="data/lsun/cat_val.txt", data_root="data/lsun/cats",\n                         flip_p=flip_p, **kwargs)\n',
    'model.ldm.lr_scheduler': 'import numpy as np\n\n\nclass LambdaWarmUpCosineScheduler:\n    """\n    note: use with a base_lr of 1.0\n    """\n    def __init__(self, warm_up_steps, lr_min, lr_max, lr_start, max_decay_steps, verbosity_interval=0):\n        self.lr_warm_up_steps = warm_up_steps\n        self.lr_start = lr_start\n        self.lr_min = lr_min\n        self.lr_max = lr_max\n        self.lr_max_decay_steps = max_decay_steps\n        self.last_lr = 0.\n        self.verbosity_interval = verbosity_interval\n\n    def schedule(self, n, **kwargs):\n        if self.verbosity_interval > 0:\n            if n % self.verbosity_interval == 0: print(f"current step: {n}, recent lr-multiplier: {self.last_lr}")\n        if n < self.lr_warm_up_steps:\n            lr = (self.lr_max - self.lr_start) / self.lr_warm_up_steps * n + self.lr_start\n            self.last_lr = lr\n            return lr\n        else:\n            t = (n - self.lr_warm_up_steps) / (self.lr_max_decay_steps - self.lr_warm_up_steps)\n            t = min(t, 1.0)\n            lr = self.lr_min + 0.5 * (self.lr_max - self.lr_min) * (\n                    1 + np.cos(t * np.pi))\n            self.last_lr = lr\n            return lr\n\n    def __call__(self, n, **kwargs):\n        return self.schedule(n,**kwargs)\n\n\nclass LambdaWarmUpCosineScheduler2:\n    """\n    supports repeated iterations, configurable via lists\n    note: use with a base_lr of 1.0.\n    """\n    def __init__(self, warm_up_steps, f_min, f_max, f_start, cycle_lengths, verbosity_interval=0):\n        assert len(warm_up_steps) == len(f_min) == len(f_max) == len(f_start) == len(cycle_lengths)\n        self.lr_warm_up_steps = warm_up_steps\n        self.f_start = f_start\n        self.f_min = f_min\n        self.f_max = f_max\n        self.cycle_lengths = cycle_lengths\n        self.cum_cycles = np.cumsum([0] + list(self.cycle_lengths))\n        self.last_f = 0.\n        self.verbosity_interval = verbosity_interval\n\n    def find_in_interval(self, n):\n        interval = 0\n        for cl in self.cum_cycles[1:]:\n            if n <= cl:\n                return interval\n            interval += 1\n\n    def schedule(self, n, **kwargs):\n        cycle = self.find_in_interval(n)\n        n = n - self.cum_cycles[cycle]\n        if self.verbosity_interval > 0:\n            if n % self.verbosity_interval == 0: print(f"current step: {n}, recent lr-multiplier: {self.last_f}, "\n                                                       f"current cycle {cycle}")\n        if n < self.lr_warm_up_steps[cycle]:\n            f = (self.f_max[cycle] - self.f_start[cycle]) / self.lr_warm_up_steps[cycle] * n + self.f_start[cycle]\n            self.last_f = f\n            return f\n        else:\n            t = (n - self.lr_warm_up_steps[cycle]) / (self.cycle_lengths[cycle] - self.lr_warm_up_steps[cycle])\n            t = min(t, 1.0)\n            f = self.f_min[cycle] + 0.5 * (self.f_max[cycle] - self.f_min[cycle]) * (\n                    1 + np.cos(t * np.pi))\n            self.last_f = f\n            return f\n\n    def __call__(self, n, **kwargs):\n        return self.schedule(n, **kwargs)\n\n\nclass LambdaLinearScheduler(LambdaWarmUpCosineScheduler2):\n\n    def schedule(self, n, **kwargs):\n        cycle = self.find_in_interval(n)\n        n = n - self.cum_cycles[cycle]\n        if self.verbosity_interval > 0:\n            if n % self.verbosity_interval == 0: print(f"current step: {n}, recent lr-multiplier: {self.last_f}, "\n                                                       f"current cycle {cycle}")\n\n        if n < self.lr_warm_up_steps[cycle]:\n            f = (self.f_max[cycle] - self.f_start[cycle]) / self.lr_warm_up_steps[cycle] * n + self.f_start[cycle]\n            self.last_f = f\n            return f\n        else:\n            f = self.f_min[cycle] + (self.f_max[cycle] - self.f_min[cycle]) * (self.cycle_lengths[cycle] - n) / (self.cycle_lengths[cycle])\n            self.last_f = f\n            return f\n\n',
    'model.ldm.models': '',
    'model.ldm.models.autoencoder': 'import torch\nimport pytorch_lightning as pl\nimport torch.nn.functional as F\nfrom contextlib import contextmanager\n\nfrom model.ldm.modules.diffusionmodules.model import Encoder, Decoder\nfrom model.ldm.modules.distributions.distributions import DiagonalGaussianDistribution\n\nfrom model.ldm.util import instantiate_from_config\n\nimport torch.nn as nn\nfrom einops import rearrange\n\nclass VectorQuantizer(nn.Module):\n    """\n    Improved version over VectorQuantizer, can be used as a drop-in replacement. Mostly\n    avoids costly matrix multiplications and allows for post-hoc remapping of indices.\n    """\n    # NOTE: due to a bug the beta term was applied to the wrong term. for\n    # backwards compatibility we use the buggy version by default, but you can\n    # specify legacy=False to fix it.\n    def __init__(self, n_e, e_dim, beta, remap=None, unknown_index="random",\n                 sane_index_shape=False, legacy=True):\n        super().__init__()\n        self.n_e = n_e\n        self.e_dim = e_dim\n        self.beta = beta\n        self.legacy = legacy\n\n        self.embedding = nn.Embedding(self.n_e, self.e_dim)\n        self.embedding.weight.data.uniform_(-1.0 / self.n_e, 1.0 / self.n_e)\n\n        self.remap = remap\n        if self.remap is not None:\n            self.register_buffer("used", torch.tensor(np.load(self.remap)))\n            self.re_embed = self.used.shape[0]\n            self.unknown_index = unknown_index # "random" or "extra" or integer\n            if self.unknown_index == "extra":\n                self.unknown_index = self.re_embed\n                self.re_embed = self.re_embed+1\n            print(f"Remapping {self.n_e} indices to {self.re_embed} indices. "\n                  f"Using {self.unknown_index} for unknown indices.")\n        else:\n            self.re_embed = n_e\n\n        self.sane_index_shape = sane_index_shape\n\n    def remap_to_used(self, inds):\n        ishape = inds.shape\n        assert len(ishape)>1\n        inds = inds.reshape(ishape[0],-1)\n        used = self.used.to(inds)\n        match = (inds[:,:,None]==used[None,None,...]).long()\n        new = match.argmax(-1)\n        unknown = match.sum(2)<1\n        if self.unknown_index == "random":\n            new[unknown]=torch.randint(0,self.re_embed,size=new[unknown].shape).to(device=new.device)\n        else:\n            new[unknown] = self.unknown_index\n        return new.reshape(ishape)\n\n    def unmap_to_all(self, inds):\n        ishape = inds.shape\n        assert len(ishape)>1\n        inds = inds.reshape(ishape[0],-1)\n        used = self.used.to(inds)\n        if self.re_embed > self.used.shape[0]: # extra token\n            inds[inds>=self.used.shape[0]] = 0 # simply set to zero\n        back=torch.gather(used[None,:][inds.shape[0]*[0],:], 1, inds)\n        return back.reshape(ishape)\n\n    def forward(self, z, temp=None, rescale_logits=False, return_logits=False):\n        assert temp is None or temp==1.0, "Only for interface compatible with Gumbel"\n        assert rescale_logits==False, "Only for interface compatible with Gumbel"\n        assert return_logits==False, "Only for interface compatible with Gumbel"\n        # reshape z -> (batch, height, width, channel) and flatten\n        z = rearrange(z, \'b c h w -> b h w c\').contiguous()\n        z_flattened = z.view(-1, self.e_dim)\n        # distances from z to embeddings e_j (z - e)^2 = z^2 + e^2 - 2 e * z\n\n        d = torch.sum(z_flattened ** 2, dim=1, keepdim=True) + \\\n            torch.sum(self.embedding.weight**2, dim=1) - 2 * \\\n            torch.einsum(\'bd,dn->bn\', z_flattened, rearrange(self.embedding.weight, \'n d -> d n\'))\n\n        min_encoding_indices = torch.argmin(d, dim=1)\n        z_q = self.embedding(min_encoding_indices).view(z.shape)\n        perplexity = None\n        min_encodings = None\n\n        # compute loss for embedding\n        if not self.legacy:\n            loss = self.beta * torch.mean((z_q.detach()-z)**2) + \\\n                   torch.mean((z_q - z.detach()) ** 2)\n        else:\n            loss = torch.mean((z_q.detach()-z)**2) + self.beta * \\\n                   torch.mean((z_q - z.detach()) ** 2)\n\n        # preserve gradients\n        z_q = z + (z_q - z).detach()\n\n        # reshape back to match original input shape\n        z_q = rearrange(z_q, \'b h w c -> b c h w\').contiguous()\n\n        if self.remap is not None:\n            min_encoding_indices = min_encoding_indices.reshape(z.shape[0],-1) # add batch axis\n            min_encoding_indices = self.remap_to_used(min_encoding_indices)\n            min_encoding_indices = min_encoding_indices.reshape(-1,1) # flatten\n\n        if self.sane_index_shape:\n            min_encoding_indices = min_encoding_indices.reshape(\n                z_q.shape[0], z_q.shape[2], z_q.shape[3])\n\n        return z_q, loss, (perplexity, min_encodings, min_encoding_indices)\n\n    def get_codebook_entry(self, indices, shape):\n        # shape specifying (batch, height, width, channel)\n        if self.remap is not None:\n            indices = indices.reshape(shape[0],-1) # add batch axis\n            indices = self.unmap_to_all(indices)\n            indices = indices.reshape(-1) # flatten again\n\n        # get quantized latent vectors\n        z_q = self.embedding(indices)\n\n        if shape is not None:\n            z_q = z_q.view(shape)\n            # reshape back to match original input shape\n            z_q = z_q.permute(0, 3, 1, 2).contiguous()\n\n        return z_q\n\n\nclass VQModel(pl.LightningModule):\n    def __init__(self,\n                 ddconfig,\n                 lossconfig,\n                 n_embed,\n                 embed_dim,\n                 ckpt_path=None,\n                 ignore_keys=[],\n                 image_key="image",\n                 colorize_nlabels=None,\n                 monitor=None,\n                 batch_resize_range=None,\n                 scheduler_config=None,\n                 lr_g_factor=1.0,\n                 remap=None,\n                 sane_index_shape=False, # tell vector quantizer to return indices as bhw\n                 use_ema=False\n                 ):\n        super().__init__()\n        self.embed_dim = embed_dim\n        self.n_embed = n_embed\n        self.image_key = image_key\n        self.encoder = Encoder(**ddconfig)\n        self.decoder = Decoder(**ddconfig)\n        self.loss = instantiate_from_config(lossconfig)\n        self.quantize = VectorQuantizer(n_embed, embed_dim, beta=0.25,\n                                        remap=remap,\n                                        sane_index_shape=sane_index_shape)\n        self.quant_conv = torch.nn.Conv2d(ddconfig["z_channels"], embed_dim, 1)\n        self.post_quant_conv = torch.nn.Conv2d(embed_dim, ddconfig["z_channels"], 1)\n        if colorize_nlabels is not None:\n            assert type(colorize_nlabels)==int\n            self.register_buffer("colorize", torch.randn(3, colorize_nlabels, 1, 1))\n        if monitor is not None:\n            self.monitor = monitor\n        self.batch_resize_range = batch_resize_range\n        if self.batch_resize_range is not None:\n            print(f"{self.__class__.__name__}: Using per-batch resizing in range {batch_resize_range}.")\n\n        self.use_ema = use_ema\n        if self.use_ema:\n            self.model_ema = LitEma(self)\n            print(f"Keeping EMAs of {len(list(self.model_ema.buffers()))}.")\n\n        if ckpt_path is not None:\n            self.init_from_ckpt(ckpt_path, ignore_keys=ignore_keys)\n        self.scheduler_config = scheduler_config\n        self.lr_g_factor = lr_g_factor\n\n    @contextmanager\n    def ema_scope(self, context=None):\n        if self.use_ema:\n            self.model_ema.store(self.parameters())\n            self.model_ema.copy_to(self)\n            if context is not None:\n                print(f"{context}: Switched to EMA weights")\n        try:\n            yield None\n        finally:\n            if self.use_ema:\n                self.model_ema.restore(self.parameters())\n                if context is not None:\n                    print(f"{context}: Restored training weights")\n\n    def init_from_ckpt(self, path, ignore_keys=list()):\n        sd = torch.load(path, map_location="cpu")["state_dict"]\n        keys = list(sd.keys())\n        for k in keys:\n            for ik in ignore_keys:\n                if k.startswith(ik):\n                    print("Deleting key {} from state_dict.".format(k))\n                    del sd[k]\n        missing, unexpected = self.load_state_dict(sd, strict=False)\n        print(f"Restored from {path} with {len(missing)} missing and {len(unexpected)} unexpected keys")\n        if len(missing) > 0:\n            print(f"Missing Keys: {missing}")\n            print(f"Unexpected Keys: {unexpected}")\n\n    def on_train_batch_end(self, *args, **kwargs):\n        if self.use_ema:\n            self.model_ema(self)\n\n    def encode(self, x):\n        h = self.encoder(x)\n        h = self.quant_conv(h)\n        quant, emb_loss, info = self.quantize(h)\n        return quant, emb_loss, info\n\n    def encode_to_prequant(self, x):\n        h = self.encoder(x)\n        h = self.quant_conv(h)\n        return h\n\n    def decode(self, quant):\n        quant = self.post_quant_conv(quant)\n        dec = self.decoder(quant)\n        return dec\n\n    def decode_code(self, code_b):\n        quant_b = self.quantize.embed_code(code_b)\n        dec = self.decode(quant_b)\n        return dec\n\n    def forward(self, input, return_pred_indices=False):\n        quant, diff, (_,_,ind) = self.encode(input)\n        dec = self.decode(quant)\n        if return_pred_indices:\n            return dec, diff, ind\n        return dec, diff\n\n    def get_input(self, batch, k):\n        x = batch[k]\n        if len(x.shape) == 3:\n            x = x[..., None]\n        x = x.permute(0, 3, 1, 2).to(memory_format=torch.contiguous_format).float()\n        if self.batch_resize_range is not None:\n            lower_size = self.batch_resize_range[0]\n            upper_size = self.batch_resize_range[1]\n            if self.global_step <= 4:\n                # do the first few batches with max size to avoid later oom\n                new_resize = upper_size\n            else:\n                new_resize = np.random.choice(np.arange(lower_size, upper_size+16, 16))\n            if new_resize != x.shape[2]:\n                x = F.interpolate(x, size=new_resize, mode="bicubic")\n            x = x.detach()\n        return x\n\n    def training_step(self, batch, batch_idx, optimizer_idx):\n        # https://github.com/pytorch/pytorch/issues/37142\n        # try not to fool the heuristics\n        x = self.get_input(batch, self.image_key)\n        xrec, qloss, ind = self(x, return_pred_indices=True)\n\n        if optimizer_idx == 0:\n            # autoencode\n            aeloss, log_dict_ae = self.loss(qloss, x, xrec, optimizer_idx, self.global_step,\n                                            last_layer=self.get_last_layer(), split="train",\n                                            predicted_indices=ind)\n\n            self.log_dict(log_dict_ae, prog_bar=False, logger=True, on_step=True, on_epoch=True)\n            return aeloss\n\n        if optimizer_idx == 1:\n            # discriminator\n            discloss, log_dict_disc = self.loss(qloss, x, xrec, optimizer_idx, self.global_step,\n                                            last_layer=self.get_last_layer(), split="train")\n            self.log_dict(log_dict_disc, prog_bar=False, logger=True, on_step=True, on_epoch=True)\n            return discloss\n\n    def validation_step(self, batch, batch_idx):\n        log_dict = self._validation_step(batch, batch_idx)\n        with self.ema_scope():\n            log_dict_ema = self._validation_step(batch, batch_idx, suffix="_ema")\n        return log_dict\n\n    def _validation_step(self, batch, batch_idx, suffix=""):\n        x = self.get_input(batch, self.image_key)\n        xrec, qloss, ind = self(x, return_pred_indices=True)\n        aeloss, log_dict_ae = self.loss(qloss, x, xrec, 0,\n                                        self.global_step,\n                                        last_layer=self.get_last_layer(),\n                                        split="val"+suffix,\n                                        predicted_indices=ind\n                                        )\n\n        discloss, log_dict_disc = self.loss(qloss, x, xrec, 1,\n                                            self.global_step,\n                                            last_layer=self.get_last_layer(),\n                                            split="val"+suffix,\n                                            predicted_indices=ind\n                                            )\n        rec_loss = log_dict_ae[f"val{suffix}/rec_loss"]\n        self.log(f"val{suffix}/rec_loss", rec_loss,\n                   prog_bar=True, logger=True, on_step=False, on_epoch=True, sync_dist=True)\n        self.log(f"val{suffix}/aeloss", aeloss,\n                   prog_bar=True, logger=True, on_step=False, on_epoch=True, sync_dist=True)\n        if version.parse(pl.__version__) >= version.parse(\'1.4.0\'):\n            del log_dict_ae[f"val{suffix}/rec_loss"]\n        self.log_dict(log_dict_ae)\n        self.log_dict(log_dict_disc)\n        return self.log_dict\n\n    def configure_optimizers(self):\n        lr_d = self.learning_rate\n        lr_g = self.lr_g_factor*self.learning_rate\n        print("lr_d", lr_d)\n        print("lr_g", lr_g)\n        opt_ae = torch.optim.Adam(list(self.encoder.parameters())+\n                                  list(self.decoder.parameters())+\n                                  list(self.quantize.parameters())+\n                                  list(self.quant_conv.parameters())+\n                                  list(self.post_quant_conv.parameters()),\n                                  lr=lr_g, betas=(0.5, 0.9))\n        opt_disc = torch.optim.Adam(self.loss.discriminator.parameters(),\n                                    lr=lr_d, betas=(0.5, 0.9))\n\n        if self.scheduler_config is not None:\n            scheduler = instantiate_from_config(self.scheduler_config)\n\n            print("Setting up LambdaLR scheduler...")\n            scheduler = [\n                {\n                    \'scheduler\': LambdaLR(opt_ae, lr_lambda=scheduler.schedule),\n                    \'interval\': \'step\',\n                    \'frequency\': 1\n                },\n                {\n                    \'scheduler\': LambdaLR(opt_disc, lr_lambda=scheduler.schedule),\n                    \'interval\': \'step\',\n                    \'frequency\': 1\n                },\n            ]\n            return [opt_ae, opt_disc], scheduler\n        return [opt_ae, opt_disc], []\n\n    def get_last_layer(self):\n        return self.decoder.conv_out.weight\n\n    def log_images(self, batch, only_inputs=False, plot_ema=False, **kwargs):\n        log = dict()\n        x = self.get_input(batch, self.image_key)\n        x = x.to(self.device)\n        if only_inputs:\n            log["inputs"] = x\n            return log\n        xrec, _ = self(x)\n        if x.shape[1] > 3:\n            # colorize with random projection\n            assert xrec.shape[1] > 3\n            x = self.to_rgb(x)\n            xrec = self.to_rgb(xrec)\n        log["inputs"] = x\n        log["reconstructions"] = xrec\n        if plot_ema:\n            with self.ema_scope():\n                xrec_ema, _ = self(x)\n                if x.shape[1] > 3: xrec_ema = self.to_rgb(xrec_ema)\n                log["reconstructions_ema"] = xrec_ema\n        return log\n\n    def to_rgb(self, x):\n        assert self.image_key == "segmentation"\n        if not hasattr(self, "colorize"):\n            self.register_buffer("colorize", torch.randn(3, x.shape[1], 1, 1).to(x))\n        x = F.conv2d(x, weight=self.colorize)\n        x = 2.*(x-x.min())/(x.max()-x.min()) - 1.\n        return x\n\n\nclass VQModelInterface(VQModel):\n    def __init__(self, embed_dim, *args, **kwargs):\n        super().__init__(embed_dim=embed_dim, *args, **kwargs)\n        self.embed_dim = embed_dim\n\n    def encode(self, x):\n        h = self.encoder(x)\n        h = self.quant_conv(h)\n        return h\n\n    def decode(self, h, force_not_quantize=False):\n        # also go through quantization layer\n        if not force_not_quantize:\n            quant, emb_loss, info = self.quantize(h)\n        else:\n            quant = h\n        quant = self.post_quant_conv(quant)\n        dec = self.decoder(quant)\n        return dec\n\n\nclass AutoencoderKL(pl.LightningModule):\n    def __init__(self,\n                 ddconfig,\n                 lossconfig,\n                 embed_dim,\n                 ckpt_path=None,\n                 ignore_keys=[],\n                 image_key="image",\n                 colorize_nlabels=None,\n                 monitor=None,\n                 ):\n        super().__init__()\n        self.image_key = image_key\n        self.encoder = Encoder(**ddconfig)\n        self.decoder = Decoder(**ddconfig)\n        self.loss = instantiate_from_config(lossconfig)\n        assert ddconfig["double_z"]\n        self.quant_conv = torch.nn.Conv2d(2*ddconfig["z_channels"], 2*embed_dim, 1)\n        self.post_quant_conv = torch.nn.Conv2d(embed_dim, ddconfig["z_channels"], 1)\n        self.embed_dim = embed_dim\n        if colorize_nlabels is not None:\n            assert type(colorize_nlabels)==int\n            self.register_buffer("colorize", torch.randn(3, colorize_nlabels, 1, 1))\n        if monitor is not None:\n            self.monitor = monitor\n        if ckpt_path is not None:\n            self.init_from_ckpt(ckpt_path, ignore_keys=ignore_keys)\n\n    def init_from_ckpt(self, path, ignore_keys=list()):\n        sd = torch.load(path, map_location="cpu")["state_dict"]\n        keys = list(sd.keys())\n        for k in keys:\n            for ik in ignore_keys:\n                if k.startswith(ik):\n                    print("Deleting key {} from state_dict.".format(k))\n                    del sd[k]\n        self.load_state_dict(sd, strict=False)\n        print(f"Restored from {path}")\n\n    def encode(self, x):\n        h = self.encoder(x)\n        moments = self.quant_conv(h)\n        posterior = DiagonalGaussianDistribution(moments)\n        return posterior\n\n    def decode(self, z):\n        z = self.post_quant_conv(z)\n        dec = self.decoder(z)\n        return dec\n\n    def forward(self, input, sample_posterior=True):\n        posterior = self.encode(input)\n        if sample_posterior:\n            z = posterior.sample()\n        else:\n            z = posterior.mode()\n        dec = self.decode(z)\n        return dec, posterior\n\n    def get_input(self, batch, k):\n        x = batch[k]\n        if len(x.shape) == 3:\n            x = x[..., None]\n        x = x.permute(0, 3, 1, 2).to(memory_format=torch.contiguous_format).float()\n        return x\n\n    def training_step(self, batch, batch_idx, optimizer_idx):\n        inputs = self.get_input(batch, self.image_key)\n        reconstructions, posterior = self(inputs)\n\n        if optimizer_idx == 0:\n            # train encoder+decoder+logvar\n            aeloss, log_dict_ae = self.loss(inputs, reconstructions, posterior, optimizer_idx, self.global_step,\n                                            last_layer=self.get_last_layer(), split="train")\n            self.log("aeloss", aeloss, prog_bar=True, logger=True, on_step=True, on_epoch=True)\n            self.log_dict(log_dict_ae, prog_bar=False, logger=True, on_step=True, on_epoch=False)\n            return aeloss\n\n        if optimizer_idx == 1:\n            # train the discriminator\n            discloss, log_dict_disc = self.loss(inputs, reconstructions, posterior, optimizer_idx, self.global_step,\n                                                last_layer=self.get_last_layer(), split="train")\n\n            self.log("discloss", discloss, prog_bar=True, logger=True, on_step=True, on_epoch=True)\n            self.log_dict(log_dict_disc, prog_bar=False, logger=True, on_step=True, on_epoch=False)\n            return discloss\n\n    def validation_step(self, batch, batch_idx):\n        inputs = self.get_input(batch, self.image_key)\n        reconstructions, posterior = self(inputs)\n        aeloss, log_dict_ae = self.loss(inputs, reconstructions, posterior, 0, self.global_step,\n                                        last_layer=self.get_last_layer(), split="val")\n\n        discloss, log_dict_disc = self.loss(inputs, reconstructions, posterior, 1, self.global_step,\n                                            last_layer=self.get_last_layer(), split="val")\n\n        self.log("val/rec_loss", log_dict_ae["val/rec_loss"])\n        self.log_dict(log_dict_ae)\n        self.log_dict(log_dict_disc)\n        return self.log_dict\n\n    def configure_optimizers(self):\n        lr = self.learning_rate\n        opt_ae = torch.optim.Adam(list(self.encoder.parameters())+\n                                  list(self.decoder.parameters())+\n                                  list(self.quant_conv.parameters())+\n                                  list(self.post_quant_conv.parameters()),\n                                  lr=lr, betas=(0.5, 0.9))\n        opt_disc = torch.optim.Adam(self.loss.discriminator.parameters(),\n                                    lr=lr, betas=(0.5, 0.9))\n        return [opt_ae, opt_disc], []\n\n    def get_last_layer(self):\n        return self.decoder.conv_out.weight\n\n    @torch.no_grad()\n    def log_images(self, batch, only_inputs=False, **kwargs):\n        log = dict()\n        x = self.get_input(batch, self.image_key)\n        x = x.to(self.device)\n        if not only_inputs:\n            xrec, posterior = self(x)\n            if x.shape[1] > 3:\n                # colorize with random projection\n                assert xrec.shape[1] > 3\n                x = self.to_rgb(x)\n                xrec = self.to_rgb(xrec)\n            log["samples"] = self.decode(torch.randn_like(posterior.sample()))\n            log["reconstructions"] = xrec\n        log["inputs"] = x\n        return log\n\n    def to_rgb(self, x):\n        assert self.image_key == "segmentation"\n        if not hasattr(self, "colorize"):\n            self.register_buffer("colorize", torch.randn(3, x.shape[1], 1, 1).to(x))\n        x = F.conv2d(x, weight=self.colorize)\n        x = 2.*(x-x.min())/(x.max()-x.min()) - 1.\n        return x\n\n\nclass IdentityFirstStage(torch.nn.Module):\n    def __init__(self, *args, vq_interface=False, **kwargs):\n        self.vq_interface = vq_interface  # TODO: Should be true by default but check to not break older stuff\n        super().__init__()\n\n    def encode(self, x, *args, **kwargs):\n        return x\n\n    def decode(self, x, *args, **kwargs):\n        return x\n\n    def quantize(self, x, *args, **kwargs):\n        if self.vq_interface:\n            return x, None, [None, None, None]\n        return x\n\n    def forward(self, x, *args, **kwargs):\n        return x\n',
    'model.ldm.models.diffusion': '',
    'model.ldm.models.diffusion.classifier': 'import os\nimport torch\nimport pytorch_lightning as pl\nfrom omegaconf import OmegaConf\nfrom torch.nn import functional as F\nfrom torch.optim import AdamW\nfrom torch.optim.lr_scheduler import LambdaLR\nfrom copy import deepcopy\nfrom einops import rearrange\nfrom glob import glob\nfrom natsort import natsorted\n\nfrom model.ldm.modules.diffusionmodules.openaimodel import EncoderUNetModel, UNetModel\nfrom model.ldm.util import log_txt_as_img, default, ismap, instantiate_from_config\n\n__models__ = {\n    \'class_label\': EncoderUNetModel,\n    \'segmentation\': UNetModel\n}\n\n\ndef disabled_train(self, mode=True):\n    """Overwrite model.train with this function to make sure train/eval mode\n    does not change anymore."""\n    return self\n\n\nclass NoisyLatentImageClassifier(pl.LightningModule):\n\n    def __init__(self,\n                 diffusion_path,\n                 num_classes,\n                 ckpt_path=None,\n                 pool=\'attention\',\n                 label_key=None,\n                 diffusion_ckpt_path=None,\n                 scheduler_config=None,\n                 weight_decay=1.e-2,\n                 log_steps=10,\n                 monitor=\'val/loss\',\n                 *args,\n                 **kwargs):\n        super().__init__(*args, **kwargs)\n        self.num_classes = num_classes\n        # get latest config of diffusion model\n        diffusion_config = natsorted(glob(os.path.join(diffusion_path, \'configs\', \'*-project.yaml\')))[-1]\n        self.diffusion_config = OmegaConf.load(diffusion_config).model\n        self.diffusion_config.params.ckpt_path = diffusion_ckpt_path\n        self.load_diffusion()\n\n        self.monitor = monitor\n        self.numd = self.diffusion_model.first_stage_model.encoder.num_resolutions - 1\n        self.log_time_interval = self.diffusion_model.num_timesteps // log_steps\n        self.log_steps = log_steps\n\n        self.label_key = label_key if not hasattr(self.diffusion_model, \'cond_stage_key\') \\\n            else self.diffusion_model.cond_stage_key\n\n        assert self.label_key is not None, \'label_key neither in diffusion model nor in model.params\'\n\n        if self.label_key not in __models__:\n            raise NotImplementedError()\n\n        self.load_classifier(ckpt_path, pool)\n\n        self.scheduler_config = scheduler_config\n        self.use_scheduler = self.scheduler_config is not None\n        self.weight_decay = weight_decay\n\n    def init_from_ckpt(self, path, ignore_keys=list(), only_model=False):\n        sd = torch.load(path, map_location="cpu")\n        if "state_dict" in list(sd.keys()):\n            sd = sd["state_dict"]\n        keys = list(sd.keys())\n        for k in keys:\n            for ik in ignore_keys:\n                if k.startswith(ik):\n                    print("Deleting key {} from state_dict.".format(k))\n                    del sd[k]\n        missing, unexpected = self.load_state_dict(sd, strict=False) if not only_model else self.model.load_state_dict(\n            sd, strict=False)\n        print(f"Restored from {path} with {len(missing)} missing and {len(unexpected)} unexpected keys")\n        if len(missing) > 0:\n            print(f"Missing Keys: {missing}")\n        if len(unexpected) > 0:\n            print(f"Unexpected Keys: {unexpected}")\n\n    def load_diffusion(self):\n        model = instantiate_from_config(self.diffusion_config)\n        self.diffusion_model = model.eval()\n        self.diffusion_model.train = disabled_train\n        for param in self.diffusion_model.parameters():\n            param.requires_grad = False\n\n    def load_classifier(self, ckpt_path, pool):\n        model_config = deepcopy(self.diffusion_config.params.unet_config.params)\n        model_config.in_channels = self.diffusion_config.params.unet_config.params.out_channels\n        model_config.out_channels = self.num_classes\n        if self.label_key == \'class_label\':\n            model_config.pool = pool\n\n        self.model = __models__[self.label_key](**model_config)\n        if ckpt_path is not None:\n            print(\'#####################################################################\')\n            print(f\'load from ckpt "{ckpt_path}"\')\n            print(\'#####################################################################\')\n            self.init_from_ckpt(ckpt_path)\n\n    @torch.no_grad()\n    def get_x_noisy(self, x, t, noise=None):\n        noise = default(noise, lambda: torch.randn_like(x))\n        continuous_sqrt_alpha_cumprod = None\n        if self.diffusion_model.use_continuous_noise:\n            continuous_sqrt_alpha_cumprod = self.diffusion_model.sample_continuous_noise_level(x.shape[0], t + 1)\n            # todo: make sure t+1 is correct here\n\n        return self.diffusion_model.q_sample(x_start=x, t=t, noise=noise,\n                                             continuous_sqrt_alpha_cumprod=continuous_sqrt_alpha_cumprod)\n\n    def forward(self, x_noisy, t, *args, **kwargs):\n        return self.model(x_noisy, t)\n\n    @torch.no_grad()\n    def get_input(self, batch, k):\n        x = batch[k]\n        if len(x.shape) == 3:\n            x = x[..., None]\n        x = rearrange(x, \'b h w c -> b c h w\')\n        x = x.to(memory_format=torch.contiguous_format).float()\n        return x\n\n    @torch.no_grad()\n    def get_conditioning(self, batch, k=None):\n        if k is None:\n            k = self.label_key\n        assert k is not None, \'Needs to provide label key\'\n\n        targets = batch[k].to(self.device)\n\n        if self.label_key == \'segmentation\':\n            targets = rearrange(targets, \'b h w c -> b c h w\')\n            for down in range(self.numd):\n                h, w = targets.shape[-2:]\n                targets = F.interpolate(targets, size=(h // 2, w // 2), mode=\'nearest\')\n\n            # targets = rearrange(targets,\'b c h w -> b h w c\')\n\n        return targets\n\n    def compute_top_k(self, logits, labels, k, reduction="mean"):\n        _, top_ks = torch.topk(logits, k, dim=1)\n        if reduction == "mean":\n            return (top_ks == labels[:, None]).float().sum(dim=-1).mean().item()\n        elif reduction == "none":\n            return (top_ks == labels[:, None]).float().sum(dim=-1)\n\n    def on_train_epoch_start(self):\n        # save some memory\n        self.diffusion_model.model.to(\'cpu\')\n\n    @torch.no_grad()\n    def write_logs(self, loss, logits, targets):\n        log_prefix = \'train\' if self.training else \'val\'\n        log = {}\n        log[f"{log_prefix}/loss"] = loss.mean()\n        log[f"{log_prefix}/acc@1"] = self.compute_top_k(\n            logits, targets, k=1, reduction="mean"\n        )\n        log[f"{log_prefix}/acc@5"] = self.compute_top_k(\n            logits, targets, k=5, reduction="mean"\n        )\n\n        self.log_dict(log, prog_bar=False, logger=True, on_step=self.training, on_epoch=True)\n        self.log(\'loss\', log[f"{log_prefix}/loss"], prog_bar=True, logger=False)\n        self.log(\'global_step\', self.global_step, logger=False, on_epoch=False, prog_bar=True)\n        lr = self.optimizers().param_groups[0][\'lr\']\n        self.log(\'lr_abs\', lr, on_step=True, logger=True, on_epoch=False, prog_bar=True)\n\n    def shared_step(self, batch, t=None):\n        x, *_ = self.diffusion_model.get_input(batch, k=self.diffusion_model.first_stage_key)\n        targets = self.get_conditioning(batch)\n        if targets.dim() == 4:\n            targets = targets.argmax(dim=1)\n        if t is None:\n            t = torch.randint(0, self.diffusion_model.num_timesteps, (x.shape[0],), device=self.device).long()\n        else:\n            t = torch.full(size=(x.shape[0],), fill_value=t, device=self.device).long()\n        x_noisy = self.get_x_noisy(x, t)\n        logits = self(x_noisy, t)\n\n        loss = F.cross_entropy(logits, targets, reduction=\'none\')\n\n        self.write_logs(loss.detach(), logits.detach(), targets.detach())\n\n        loss = loss.mean()\n        return loss, logits, x_noisy, targets\n\n    def training_step(self, batch, batch_idx):\n        loss, *_ = self.shared_step(batch)\n        return loss\n\n    def reset_noise_accs(self):\n        self.noisy_acc = {t: {\'acc@1\': [], \'acc@5\': []} for t in\n                          range(0, self.diffusion_model.num_timesteps, self.diffusion_model.log_every_t)}\n\n    def on_validation_start(self):\n        self.reset_noise_accs()\n\n    @torch.no_grad()\n    def validation_step(self, batch, batch_idx):\n        loss, *_ = self.shared_step(batch)\n\n        for t in self.noisy_acc:\n            _, logits, _, targets = self.shared_step(batch, t)\n            self.noisy_acc[t][\'acc@1\'].append(self.compute_top_k(logits, targets, k=1, reduction=\'mean\'))\n            self.noisy_acc[t][\'acc@5\'].append(self.compute_top_k(logits, targets, k=5, reduction=\'mean\'))\n\n        return loss\n\n    def configure_optimizers(self):\n        optimizer = AdamW(self.model.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)\n\n        if self.use_scheduler:\n            scheduler = instantiate_from_config(self.scheduler_config)\n\n            print("Setting up LambdaLR scheduler...")\n            scheduler = [\n                {\n                    \'scheduler\': LambdaLR(optimizer, lr_lambda=scheduler.schedule),\n                    \'interval\': \'step\',\n                    \'frequency\': 1\n                }]\n            return [optimizer], scheduler\n\n        return optimizer\n\n    @torch.no_grad()\n    def log_images(self, batch, N=8, *args, **kwargs):\n        log = dict()\n        x = self.get_input(batch, self.diffusion_model.first_stage_key)\n        log[\'inputs\'] = x\n\n        y = self.get_conditioning(batch)\n\n        if self.label_key == \'class_label\':\n            y = log_txt_as_img((x.shape[2], x.shape[3]), batch["human_label"])\n            log[\'labels\'] = y\n\n        if ismap(y):\n            log[\'labels\'] = self.diffusion_model.to_rgb(y)\n\n            for step in range(self.log_steps):\n                current_time = step * self.log_time_interval\n\n                _, logits, x_noisy, _ = self.shared_step(batch, t=current_time)\n\n                log[f\'inputs@t{current_time}\'] = x_noisy\n\n                pred = F.one_hot(logits.argmax(dim=1), num_classes=self.num_classes)\n                pred = rearrange(pred, \'b h w c -> b c h w\')\n\n                log[f\'pred@t{current_time}\'] = self.diffusion_model.to_rgb(pred)\n\n        for key in log:\n            log[key] = log[key][:N]\n\n        return log\n',
    'model.ldm.models.diffusion.ddim': '"""SAMPLING ONLY."""\n\nimport torch\nimport numpy as np\nfrom tqdm import tqdm\nfrom functools import partial\n\nfrom model.ldm.modules.diffusionmodules.util import make_ddim_sampling_parameters, make_ddim_timesteps, noise_like\n\n\nclass DDIMSampler(object):\n    def __init__(self, model, schedule="linear", **kwargs):\n        super().__init__()\n        self.model = model\n        self.ddpm_num_timesteps = model.num_timesteps\n        self.schedule = schedule\n\n    def register_buffer(self, name, attr):\n        if type(attr) == torch.Tensor:\n            if attr.device != torch.device("cuda"):\n                attr = attr.to(torch.device("cuda"))\n        setattr(self, name, attr)\n\n    def make_schedule(self, ddim_num_steps, ddim_discretize="uniform", ddim_eta=0., verbose=True):\n        self.ddim_timesteps = make_ddim_timesteps(ddim_discr_method=ddim_discretize, num_ddim_timesteps=ddim_num_steps,\n                                                  num_ddpm_timesteps=self.ddpm_num_timesteps,verbose=verbose)\n        alphas_cumprod = self.model.alphas_cumprod\n        assert alphas_cumprod.shape[0] == self.ddpm_num_timesteps, \'alphas have to be defined for each timestep\'\n        to_torch = lambda x: x.clone().detach().to(torch.float32).to(self.model.device)\n\n        self.register_buffer(\'betas\', to_torch(self.model.betas))\n        self.register_buffer(\'alphas_cumprod\', to_torch(alphas_cumprod))\n        self.register_buffer(\'alphas_cumprod_prev\', to_torch(self.model.alphas_cumprod_prev))\n\n        # calculations for diffusion q(x_t | x_{t-1}) and others\n        self.register_buffer(\'sqrt_alphas_cumprod\', to_torch(np.sqrt(alphas_cumprod.cpu())))\n        self.register_buffer(\'sqrt_one_minus_alphas_cumprod\', to_torch(np.sqrt(1. - alphas_cumprod.cpu())))\n        self.register_buffer(\'log_one_minus_alphas_cumprod\', to_torch(np.log(1. - alphas_cumprod.cpu())))\n        self.register_buffer(\'sqrt_recip_alphas_cumprod\', to_torch(np.sqrt(1. / alphas_cumprod.cpu())))\n        self.register_buffer(\'sqrt_recipm1_alphas_cumprod\', to_torch(np.sqrt(1. / alphas_cumprod.cpu() - 1)))\n\n        # ddim sampling parameters\n        ddim_sigmas, ddim_alphas, ddim_alphas_prev = make_ddim_sampling_parameters(alphacums=alphas_cumprod.cpu(),\n                                                                                   ddim_timesteps=self.ddim_timesteps,\n                                                                                   eta=ddim_eta,verbose=verbose)\n        self.register_buffer(\'ddim_sigmas\', ddim_sigmas)\n        self.register_buffer(\'ddim_alphas\', ddim_alphas)\n        self.register_buffer(\'ddim_alphas_prev\', ddim_alphas_prev)\n        self.register_buffer(\'ddim_sqrt_one_minus_alphas\', np.sqrt(1. - ddim_alphas))\n        sigmas_for_original_sampling_steps = ddim_eta * torch.sqrt(\n            (1 - self.alphas_cumprod_prev) / (1 - self.alphas_cumprod) * (\n                        1 - self.alphas_cumprod / self.alphas_cumprod_prev))\n        self.register_buffer(\'ddim_sigmas_for_original_num_steps\', sigmas_for_original_sampling_steps)\n\n    @torch.no_grad()\n    def sample(self,\n               S,\n               batch_size,\n               shape,\n               conditioning=None,\n               callback=None,\n               normals_sequence=None,\n               img_callback=None,\n               quantize_x0=False,\n               eta=0.,\n               mask=None,\n               x0=None,\n               temperature=1.,\n               noise_dropout=0.,\n               score_corrector=None,\n               corrector_kwargs=None,\n               verbose=True,\n               x_T=None,\n               log_every_t=100,\n               unconditional_guidance_scale=1.,\n               unconditional_conditioning=None,\n               # this has to come in the same format as the conditioning, # e.g. as encoded tokens, ...\n               **kwargs\n               ):\n        if conditioning is not None:\n            if isinstance(conditioning, dict):\n                cbs = conditioning[list(conditioning.keys())[0]].shape[0]\n                if cbs != batch_size:\n                    print(f"Warning: Got {cbs} conditionings but batch-size is {batch_size}")\n            else:\n                if conditioning.shape[0] != batch_size:\n                    print(f"Warning: Got {conditioning.shape[0]} conditionings but batch-size is {batch_size}")\n\n        self.make_schedule(ddim_num_steps=S, ddim_eta=eta, verbose=verbose)\n        # sampling\n        C, H, W = shape\n        size = (batch_size, C, H, W)\n        print(f\'Data shape for DDIM sampling is {size}, eta {eta}\')\n\n        samples, intermediates = self.ddim_sampling(conditioning, size,\n                                                    callback=callback,\n                                                    img_callback=img_callback,\n                                                    quantize_denoised=quantize_x0,\n                                                    mask=mask, x0=x0,\n                                                    ddim_use_original_steps=False,\n                                                    noise_dropout=noise_dropout,\n                                                    temperature=temperature,\n                                                    score_corrector=score_corrector,\n                                                    corrector_kwargs=corrector_kwargs,\n                                                    x_T=x_T,\n                                                    log_every_t=log_every_t,\n                                                    unconditional_guidance_scale=unconditional_guidance_scale,\n                                                    unconditional_conditioning=unconditional_conditioning,\n                                                    )\n        return samples, intermediates\n\n    @torch.no_grad()\n    def ddim_sampling(self, cond, shape,\n                      x_T=None, ddim_use_original_steps=False,\n                      callback=None, timesteps=None, quantize_denoised=False,\n                      mask=None, x0=None, img_callback=None, log_every_t=100,\n                      temperature=1., noise_dropout=0., score_corrector=None, corrector_kwargs=None,\n                      unconditional_guidance_scale=1., unconditional_conditioning=None,):\n        device = self.model.betas.device\n        b = shape[0]\n        if x_T is None:\n            img = torch.randn(shape, device=device)\n        else:\n            img = x_T\n\n        if timesteps is None:\n            timesteps = self.ddpm_num_timesteps if ddim_use_original_steps else self.ddim_timesteps\n        elif timesteps is not None and not ddim_use_original_steps:\n            subset_end = int(min(timesteps / self.ddim_timesteps.shape[0], 1) * self.ddim_timesteps.shape[0]) - 1\n            timesteps = self.ddim_timesteps[:subset_end]\n\n        intermediates = {\'x_inter\': [img], \'pred_x0\': [img]}\n        time_range = reversed(range(0,timesteps)) if ddim_use_original_steps else np.flip(timesteps)\n        total_steps = timesteps if ddim_use_original_steps else timesteps.shape[0]\n        print(f"Running DDIM Sampling with {total_steps} timesteps")\n\n        iterator = tqdm(time_range, desc=\'DDIM Sampler\', total=total_steps)\n\n        for i, step in enumerate(iterator):\n            index = total_steps - i - 1\n            ts = torch.full((b,), step, device=device, dtype=torch.long)\n\n            if mask is not None:\n                assert x0 is not None\n                img_orig = self.model.q_sample(x0, ts)  # TODO: deterministic forward pass?\n                img = img_orig * mask + (1. - mask) * img\n\n            outs = self.p_sample_ddim(img, cond, ts, index=index, use_original_steps=ddim_use_original_steps,\n                                      quantize_denoised=quantize_denoised, temperature=temperature,\n                                      noise_dropout=noise_dropout, score_corrector=score_corrector,\n                                      corrector_kwargs=corrector_kwargs,\n                                      unconditional_guidance_scale=unconditional_guidance_scale,\n                                      unconditional_conditioning=unconditional_conditioning)\n            img, pred_x0 = outs\n            if callback: callback(i)\n            if img_callback: img_callback(pred_x0, i)\n\n            if index % log_every_t == 0 or index == total_steps - 1:\n                intermediates[\'x_inter\'].append(img)\n                intermediates[\'pred_x0\'].append(pred_x0)\n\n        return img, intermediates\n\n    @torch.no_grad()\n    def p_sample_ddim(self, x, c, t, index, repeat_noise=False, use_original_steps=False, quantize_denoised=False,\n                      temperature=1., noise_dropout=0., score_corrector=None, corrector_kwargs=None,\n                      unconditional_guidance_scale=1., unconditional_conditioning=None):\n        b, *_, device = *x.shape, x.device\n\n        if unconditional_conditioning is None or unconditional_guidance_scale == 1.:\n            e_t = self.model.apply_model(x, t, c)\n        else:\n            x_in = torch.cat([x] * 2)\n            t_in = torch.cat([t] * 2)\n            c_in = torch.cat([unconditional_conditioning, c])\n            e_t_uncond, e_t = self.model.apply_model(x_in, t_in, c_in).chunk(2)\n            e_t = e_t_uncond + unconditional_guidance_scale * (e_t - e_t_uncond)\n\n        if score_corrector is not None:\n            assert self.model.parameterization == "eps"\n            e_t = score_corrector.modify_score(self.model, e_t, x, t, c, **corrector_kwargs)\n\n        alphas = self.model.alphas_cumprod if use_original_steps else self.ddim_alphas\n        alphas_prev = self.model.alphas_cumprod_prev if use_original_steps else self.ddim_alphas_prev\n        sqrt_one_minus_alphas = self.model.sqrt_one_minus_alphas_cumprod if use_original_steps else self.ddim_sqrt_one_minus_alphas\n        sigmas = self.model.ddim_sigmas_for_original_num_steps if use_original_steps else self.ddim_sigmas\n        # select parameters corresponding to the currently considered timestep\n        a_t = torch.full((b, 1, 1, 1), alphas[index], device=device)\n        a_prev = torch.full((b, 1, 1, 1), alphas_prev[index], device=device)\n        sigma_t = torch.full((b, 1, 1, 1), sigmas[index], device=device)\n        sqrt_one_minus_at = torch.full((b, 1, 1, 1), sqrt_one_minus_alphas[index],device=device)\n\n        # current prediction for x_0\n        pred_x0 = (x - sqrt_one_minus_at * e_t) / a_t.sqrt()\n        if quantize_denoised:\n            pred_x0, _, *_ = self.model.first_stage_model.quantize(pred_x0)\n        # direction pointing to x_t\n        dir_xt = (1. - a_prev - sigma_t**2).sqrt() * e_t\n        noise = sigma_t * noise_like(x.shape, device, repeat_noise) * temperature\n        if noise_dropout > 0.:\n            noise = torch.nn.functional.dropout(noise, p=noise_dropout)\n        x_prev = a_prev.sqrt() * pred_x0 + dir_xt + noise\n        return x_prev, pred_x0\n',
    'model.ldm.models.diffusion.ddpm': '"""\nwild mixture of\nhttps://github.com/lucidrains/denoising-diffusion-pytorch/blob/7706bdfc6f527f58d33f84b7b522e61e6e3164b3/denoising_diffusion_pytorch/denoising_diffusion_pytorch.py\nhttps://github.com/openai/improved-diffusion/blob/e94489283bb876ac1477d5dd7709bbbd2d9902ce/improved_diffusion/gaussian_diffusion.py\nhttps://github.com/CompVis/taming-transformers\n-- merci\n"""\n\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport pytorch_lightning as pl\nfrom torch.optim.lr_scheduler import LambdaLR\nfrom einops import rearrange, repeat\nfrom contextlib import contextmanager\nfrom functools import partial\nfrom tqdm import tqdm\nfrom torchvision.utils import make_grid\nfrom pytorch_lightning.utilities.distributed import rank_zero_only\n\nfrom model.ldm.util import log_txt_as_img, exists, default, ismap, isimage, mean_flat, count_params, instantiate_from_config\nfrom model.ldm.modules.ema import LitEma\nfrom model.ldm.modules.distributions.distributions import normal_kl, DiagonalGaussianDistribution\nfrom model.ldm.models.autoencoder import VQModelInterface, IdentityFirstStage, AutoencoderKL\nfrom model.ldm.modules.diffusionmodules.util import make_beta_schedule, extract_into_tensor, noise_like\nfrom model.ldm.models.diffusion.ddim import DDIMSampler\n\n\n__conditioning_keys__ = {\'concat\': \'c_concat\',\n                         \'crossattn\': \'c_crossattn\',\n                         \'adm\': \'y\'}\n\n\ndef disabled_train(self, mode=True):\n    """Overwrite model.train with this function to make sure train/eval mode\n    does not change anymore."""\n    return self\n\n\ndef uniform_on_device(r1, r2, shape, device):\n    return (r1 - r2) * torch.rand(*shape, device=device) + r2\n\n\nclass DDPM(pl.LightningModule):\n    # classic DDPM with Gaussian diffusion, in image space\n    def __init__(self,\n                 unet_config,\n                 timesteps=1000,\n                 beta_schedule="linear",\n                 loss_type="l2",\n                 ckpt_path=None,\n                 ignore_keys=[],\n                 load_only_unet=False,\n                 monitor="val/loss",\n                 use_ema=True,\n                 first_stage_key="image",\n                 image_size=256,\n                 channels=3,\n                 log_every_t=100,\n                 clip_denoised=True,\n                 linear_start=1e-4,\n                 linear_end=2e-2,\n                 cosine_s=8e-3,\n                 given_betas=None,\n                 original_elbo_weight=0.,\n                 v_posterior=0.,  # weight for choosing posterior variance as sigma = (1-v) * beta_tilde + v * beta\n                 l_simple_weight=1.,\n                 conditioning_key=None,\n                 parameterization="eps",  # all assuming fixed variance schedules\n                 scheduler_config=None,\n                 use_positional_encodings=False,\n                 learn_logvar=False,\n                 logvar_init=0.,\n                 ):\n        super().__init__()\n        assert parameterization in ["eps", "x0"], \'currently only supporting "eps" and "x0"\'\n        self.parameterization = parameterization\n        print(f"{self.__class__.__name__}: Running in {self.parameterization}-prediction mode")\n        self.cond_stage_model = None\n        self.clip_denoised = clip_denoised\n        self.log_every_t = log_every_t\n        self.first_stage_key = first_stage_key\n        self.image_size = image_size  # try conv?\n        self.channels = channels\n        self.use_positional_encodings = use_positional_encodings\n        self.model = DiffusionWrapper(unet_config, conditioning_key)\n        count_params(self.model, verbose=True)\n        self.use_ema = use_ema\n        if self.use_ema:\n            self.model_ema = LitEma(self.model)\n            print(f"Keeping EMAs of {len(list(self.model_ema.buffers()))}.")\n\n        self.use_scheduler = scheduler_config is not None\n        if self.use_scheduler:\n            self.scheduler_config = scheduler_config\n\n        self.v_posterior = v_posterior\n        self.original_elbo_weight = original_elbo_weight\n        self.l_simple_weight = l_simple_weight\n\n        if monitor is not None:\n            self.monitor = monitor\n        if ckpt_path is not None:\n            self.init_from_ckpt(ckpt_path, ignore_keys=ignore_keys, only_model=load_only_unet)\n\n        self.register_schedule(given_betas=given_betas, beta_schedule=beta_schedule, timesteps=timesteps,\n                               linear_start=linear_start, linear_end=linear_end, cosine_s=cosine_s)\n\n        self.loss_type = loss_type\n\n        self.learn_logvar = learn_logvar\n        self.logvar = torch.full(fill_value=logvar_init, size=(self.num_timesteps,))\n        if self.learn_logvar:\n            self.logvar = nn.Parameter(self.logvar, requires_grad=True)\n\n\n    def register_schedule(self, given_betas=None, beta_schedule="linear", timesteps=1000,\n                          linear_start=1e-4, linear_end=2e-2, cosine_s=8e-3):\n        if exists(given_betas):\n            betas = given_betas\n        else:\n            betas = make_beta_schedule(beta_schedule, timesteps, linear_start=linear_start, linear_end=linear_end,\n                                       cosine_s=cosine_s)\n        alphas = 1. - betas\n        alphas_cumprod = np.cumprod(alphas, axis=0)\n        alphas_cumprod_prev = np.append(1., alphas_cumprod[:-1])\n\n        timesteps, = betas.shape\n        self.num_timesteps = int(timesteps)\n        self.linear_start = linear_start\n        self.linear_end = linear_end\n        assert alphas_cumprod.shape[0] == self.num_timesteps, \'alphas have to be defined for each timestep\'\n\n        to_torch = partial(torch.tensor, dtype=torch.float32)\n\n        self.register_buffer(\'betas\', to_torch(betas))\n        self.register_buffer(\'alphas_cumprod\', to_torch(alphas_cumprod))\n        self.register_buffer(\'alphas_cumprod_prev\', to_torch(alphas_cumprod_prev))\n\n        # calculations for diffusion q(x_t | x_{t-1}) and others\n        self.register_buffer(\'sqrt_alphas_cumprod\', to_torch(np.sqrt(alphas_cumprod)))\n        self.register_buffer(\'sqrt_one_minus_alphas_cumprod\', to_torch(np.sqrt(1. - alphas_cumprod)))\n        self.register_buffer(\'log_one_minus_alphas_cumprod\', to_torch(np.log(1. - alphas_cumprod)))\n        self.register_buffer(\'sqrt_recip_alphas_cumprod\', to_torch(np.sqrt(1. / alphas_cumprod)))\n        self.register_buffer(\'sqrt_recipm1_alphas_cumprod\', to_torch(np.sqrt(1. / alphas_cumprod - 1)))\n\n        # calculations for posterior q(x_{t-1} | x_t, x_0)\n        posterior_variance = (1 - self.v_posterior) * betas * (1. - alphas_cumprod_prev) / (\n                    1. - alphas_cumprod) + self.v_posterior * betas\n        # above: equal to 1. / (1. / (1. - alpha_cumprod_tm1) + alpha_t / beta_t)\n        self.register_buffer(\'posterior_variance\', to_torch(posterior_variance))\n        # below: log calculation clipped because the posterior variance is 0 at the beginning of the diffusion chain\n        self.register_buffer(\'posterior_log_variance_clipped\', to_torch(np.log(np.maximum(posterior_variance, 1e-20))))\n        self.register_buffer(\'posterior_mean_coef1\', to_torch(\n            betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod)))\n        self.register_buffer(\'posterior_mean_coef2\', to_torch(\n            (1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod)))\n\n        if self.parameterization == "eps":\n            lvlb_weights = self.betas ** 2 / (\n                        2 * self.posterior_variance * to_torch(alphas) * (1 - self.alphas_cumprod))\n        elif self.parameterization == "x0":\n            lvlb_weights = 0.5 * np.sqrt(torch.Tensor(alphas_cumprod)) / (2. * 1 - torch.Tensor(alphas_cumprod))\n        else:\n            raise NotImplementedError("mu not supported")\n        # TODO how to choose this term\n        lvlb_weights[0] = lvlb_weights[1]\n        self.register_buffer(\'lvlb_weights\', lvlb_weights, persistent=False)\n        assert not torch.isnan(self.lvlb_weights).all()\n\n    @contextmanager\n    def ema_scope(self, context=None):\n        if self.use_ema:\n            self.model_ema.store(self.model.parameters())\n            self.model_ema.copy_to(self.model)\n            if context is not None:\n                print(f"{context}: Switched to EMA weights")\n        try:\n            yield None\n        finally:\n            if self.use_ema:\n                self.model_ema.restore(self.model.parameters())\n                if context is not None:\n                    print(f"{context}: Restored training weights")\n\n    def init_from_ckpt(self, path, ignore_keys=list(), only_model=False):\n        sd = torch.load(path, map_location="cpu")\n        if "state_dict" in list(sd.keys()):\n            sd = sd["state_dict"]\n        keys = list(sd.keys())\n        for k in keys:\n            for ik in ignore_keys:\n                if k.startswith(ik):\n                    print("Deleting key {} from state_dict.".format(k))\n                    del sd[k]\n        missing, unexpected = self.load_state_dict(sd, strict=False) if not only_model else self.model.load_state_dict(\n            sd, strict=False)\n        print(f"Restored from {path} with {len(missing)} missing and {len(unexpected)} unexpected keys")\n        if len(missing) > 0:\n            print(f"Missing Keys: {missing}")\n        if len(unexpected) > 0:\n            print(f"Unexpected Keys: {unexpected}")\n\n    def q_mean_variance(self, x_start, t):\n        """\n        Get the distribution q(x_t | x_0).\n        :param x_start: the [N x C x ...] tensor of noiseless inputs.\n        :param t: the number of diffusion steps (minus 1). Here, 0 means one step.\n        :return: A tuple (mean, variance, log_variance), all of x_start\'s shape.\n        """\n        mean = (extract_into_tensor(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start)\n        variance = extract_into_tensor(1.0 - self.alphas_cumprod, t, x_start.shape)\n        log_variance = extract_into_tensor(self.log_one_minus_alphas_cumprod, t, x_start.shape)\n        return mean, variance, log_variance\n\n    def predict_start_from_noise(self, x_t, t, noise):\n        return (\n                extract_into_tensor(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -\n                extract_into_tensor(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise\n        )\n\n    def q_posterior(self, x_start, x_t, t):\n        posterior_mean = (\n                extract_into_tensor(self.posterior_mean_coef1, t, x_t.shape) * x_start +\n                extract_into_tensor(self.posterior_mean_coef2, t, x_t.shape) * x_t\n        )\n        posterior_variance = extract_into_tensor(self.posterior_variance, t, x_t.shape)\n        posterior_log_variance_clipped = extract_into_tensor(self.posterior_log_variance_clipped, t, x_t.shape)\n        return posterior_mean, posterior_variance, posterior_log_variance_clipped\n\n    def p_mean_variance(self, x, t, clip_denoised: bool):\n        model_out = self.model(x, t)\n        if self.parameterization == "eps":\n            x_recon = self.predict_start_from_noise(x, t=t, noise=model_out)\n        elif self.parameterization == "x0":\n            x_recon = model_out\n        if clip_denoised:\n            x_recon.clamp_(-1., 1.)\n\n        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(x_start=x_recon, x_t=x, t=t)\n        return model_mean, posterior_variance, posterior_log_variance\n\n    @torch.no_grad()\n    def p_sample(self, x, t, clip_denoised=True, repeat_noise=False):\n        b, *_, device = *x.shape, x.device\n        model_mean, _, model_log_variance = self.p_mean_variance(x=x, t=t, clip_denoised=clip_denoised)\n        noise = noise_like(x.shape, device, repeat_noise)\n        # no noise when t == 0\n        nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))\n        return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise\n\n    @torch.no_grad()\n    def p_sample_loop(self, shape, return_intermediates=False):\n        device = self.betas.device\n        b = shape[0]\n        img = torch.randn(shape, device=device)\n        intermediates = [img]\n        for i in tqdm(reversed(range(0, self.num_timesteps)), desc=\'Sampling t\', total=self.num_timesteps):\n            img = self.p_sample(img, torch.full((b,), i, device=device, dtype=torch.long),\n                                clip_denoised=self.clip_denoised)\n            if i % self.log_every_t == 0 or i == self.num_timesteps - 1:\n                intermediates.append(img)\n        if return_intermediates:\n            return img, intermediates\n        return img\n\n    @torch.no_grad()\n    def sample(self, batch_size=16, return_intermediates=False):\n        image_size = self.image_size\n        channels = self.channels\n        return self.p_sample_loop((batch_size, channels, image_size, image_size),\n                                  return_intermediates=return_intermediates)\n\n    def q_sample(self, x_start, t, noise=None):\n        noise = default(noise, lambda: torch.randn_like(x_start))\n        return (extract_into_tensor(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +\n                extract_into_tensor(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise)\n\n    def get_loss(self, pred, target, mean=True):\n        if self.loss_type == \'l1\':\n            loss = (target - pred).abs()\n            if mean:\n                loss = loss.mean()\n        elif self.loss_type == \'l2\':\n            if mean:\n                loss = torch.nn.functional.mse_loss(target, pred)\n            else:\n                loss = torch.nn.functional.mse_loss(target, pred, reduction=\'none\')\n        else:\n            raise NotImplementedError("unknown loss type \'{loss_type}\'")\n\n        return loss\n\n    def p_losses(self, x_start, t, noise=None):\n        noise = default(noise, lambda: torch.randn_like(x_start))\n        x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)\n        model_out = self.model(x_noisy, t)\n\n        loss_dict = {}\n        if self.parameterization == "eps":\n            target = noise\n        elif self.parameterization == "x0":\n            target = x_start\n        else:\n            raise NotImplementedError(f"Paramterization {self.parameterization} not yet supported")\n\n        loss = self.get_loss(model_out, target, mean=False).mean(dim=[1, 2, 3])\n\n        log_prefix = \'train\' if self.training else \'val\'\n\n        loss_dict.update({f\'{log_prefix}/loss_simple\': loss.mean()})\n        loss_simple = loss.mean() * self.l_simple_weight\n\n        loss_vlb = (self.lvlb_weights[t] * loss).mean()\n        loss_dict.update({f\'{log_prefix}/loss_vlb\': loss_vlb})\n\n        loss = loss_simple + self.original_elbo_weight * loss_vlb\n\n        loss_dict.update({f\'{log_prefix}/loss\': loss})\n\n        return loss, loss_dict\n\n    def forward(self, x, *args, **kwargs):\n        # b, c, h, w, device, img_size, = *x.shape, x.device, self.image_size\n        # assert h == img_size and w == img_size, f\'height and width of image must be {img_size}\'\n        t = torch.randint(0, self.num_timesteps, (x.shape[0],), device=self.device).long()\n        return self.p_losses(x, t, *args, **kwargs)\n\n    def get_input(self, batch, k):\n        x = batch[k]\n        if len(x.shape) == 3:\n            x = x[..., None]\n        x = rearrange(x, \'b h w c -> b c h w\')\n        x = x.to(memory_format=torch.contiguous_format).float()\n        return x\n\n    def shared_step(self, batch):\n        x = self.get_input(batch, self.first_stage_key)\n        loss, loss_dict = self(x)\n        return loss, loss_dict\n\n    def training_step(self, batch, batch_idx):\n        loss, loss_dict = self.shared_step(batch)\n\n        self.log_dict(loss_dict, prog_bar=True,\n                      logger=True, on_step=True, on_epoch=True)\n\n        self.log("global_step", self.global_step,\n                 prog_bar=True, logger=True, on_step=True, on_epoch=False)\n\n        if self.use_scheduler:\n            lr = self.optimizers().param_groups[0][\'lr\']\n            self.log(\'lr_abs\', lr, prog_bar=True, logger=True, on_step=True, on_epoch=False)\n\n        return loss\n\n    @torch.no_grad()\n    def validation_step(self, batch, batch_idx):\n        _, loss_dict_no_ema = self.shared_step(batch)\n        with self.ema_scope():\n            _, loss_dict_ema = self.shared_step(batch)\n            loss_dict_ema = {key + \'_ema\': loss_dict_ema[key] for key in loss_dict_ema}\n        self.log_dict(loss_dict_no_ema, prog_bar=False, logger=True, on_step=False, on_epoch=True)\n        self.log_dict(loss_dict_ema, prog_bar=False, logger=True, on_step=False, on_epoch=True)\n\n    def on_train_batch_end(self, *args, **kwargs):\n        if self.use_ema:\n            self.model_ema(self.model)\n\n    def _get_rows_from_list(self, samples):\n        n_imgs_per_row = len(samples)\n        denoise_grid = rearrange(samples, \'n b c h w -> b n c h w\')\n        denoise_grid = rearrange(denoise_grid, \'b n c h w -> (b n) c h w\')\n        denoise_grid = make_grid(denoise_grid, nrow=n_imgs_per_row)\n        return denoise_grid\n\n    @torch.no_grad()\n    def log_images(self, batch, N=8, n_row=2, sample=True, return_keys=None, **kwargs):\n        log = dict()\n        x = self.get_input(batch, self.first_stage_key)\n        N = min(x.shape[0], N)\n        n_row = min(x.shape[0], n_row)\n        x = x.to(self.device)[:N]\n        log["inputs"] = x\n\n        # get diffusion row\n        diffusion_row = list()\n        x_start = x[:n_row]\n\n        for t in range(self.num_timesteps):\n            if t % self.log_every_t == 0 or t == self.num_timesteps - 1:\n                t = repeat(torch.tensor([t]), \'1 -> b\', b=n_row)\n                t = t.to(self.device).long()\n                noise = torch.randn_like(x_start)\n                x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)\n                diffusion_row.append(x_noisy)\n\n        log["diffusion_row"] = self._get_rows_from_list(diffusion_row)\n\n        if sample:\n            # get denoise row\n            with self.ema_scope("Plotting"):\n                samples, denoise_row = self.sample(batch_size=N, return_intermediates=True)\n\n            log["samples"] = samples\n            log["denoise_row"] = self._get_rows_from_list(denoise_row)\n\n        if return_keys:\n            if np.intersect1d(list(log.keys()), return_keys).shape[0] == 0:\n                return log\n            else:\n                return {key: log[key] for key in return_keys}\n        return log\n\n    def configure_optimizers(self):\n        lr = self.learning_rate\n        params = list(self.model.parameters())\n        if self.learn_logvar:\n            params = params + [self.logvar]\n        opt = torch.optim.AdamW(params, lr=lr)\n        return opt\n\n\nclass LatentDiffusion(DDPM):\n    """main class"""\n    def __init__(self,\n                 first_stage_config,\n                 cond_stage_config,\n                 num_timesteps_cond=None,\n                 cond_stage_key="image",\n                 cond_stage_trainable=False,\n                 concat_mode=True,\n                 cond_stage_forward=None,\n                 conditioning_key=None,\n                 scale_factor=1.0,\n                 scale_by_std=False,\n                 *args, **kwargs):\n        self.num_timesteps_cond = default(num_timesteps_cond, 1)\n        self.scale_by_std = scale_by_std\n        assert self.num_timesteps_cond <= kwargs[\'timesteps\']\n        # for backwards compatibility after implementation of DiffusionWrapper\n        if conditioning_key is None:\n            conditioning_key = \'concat\' if concat_mode else \'crossattn\'\n        if cond_stage_config == \'__is_unconditional__\':\n            conditioning_key = None\n        ckpt_path = kwargs.pop("ckpt_path", None)\n        ignore_keys = kwargs.pop("ignore_keys", [])\n        super().__init__(conditioning_key=conditioning_key, *args, **kwargs)\n        self.concat_mode = concat_mode\n        self.cond_stage_trainable = cond_stage_trainable\n        self.cond_stage_key = cond_stage_key\n        try:\n            self.num_downs = len(first_stage_config.params.ddconfig.ch_mult) - 1\n        except:\n            self.num_downs = 0\n        if not scale_by_std:\n            self.scale_factor = scale_factor\n        else:\n            self.register_buffer(\'scale_factor\', torch.tensor(scale_factor))\n        self.instantiate_first_stage(first_stage_config)\n        self.instantiate_cond_stage(cond_stage_config)\n        self.cond_stage_forward = cond_stage_forward\n        self.clip_denoised = False\n        self.bbox_tokenizer = None  \n\n        self.restarted_from_ckpt = False\n        if ckpt_path is not None:\n            self.init_from_ckpt(ckpt_path, ignore_keys)\n            self.restarted_from_ckpt = True\n\n    def make_cond_schedule(self, ):\n        self.cond_ids = torch.full(size=(self.num_timesteps,), fill_value=self.num_timesteps - 1, dtype=torch.long)\n        ids = torch.round(torch.linspace(0, self.num_timesteps - 1, self.num_timesteps_cond)).long()\n        self.cond_ids[:self.num_timesteps_cond] = ids\n\n    @rank_zero_only\n    @torch.no_grad()\n    def on_train_batch_start(self, batch, batch_idx, dataloader_idx):\n        # only for very first batch\n        if self.scale_by_std and self.current_epoch == 0 and self.global_step == 0 and batch_idx == 0 and not self.restarted_from_ckpt:\n            assert self.scale_factor == 1., \'rather not use custom rescaling and std-rescaling simultaneously\'\n            # set rescale weight to 1./std of encodings\n            print("### USING STD-RESCALING ###")\n            x = super().get_input(batch, self.first_stage_key)\n            x = x.to(self.device)\n            encoder_posterior = self.encode_first_stage(x)\n            z = self.get_first_stage_encoding(encoder_posterior).detach()\n            del self.scale_factor\n            self.register_buffer(\'scale_factor\', 1. / z.flatten().std())\n            print(f"setting self.scale_factor to {self.scale_factor}")\n            print("### USING STD-RESCALING ###")\n\n    def register_schedule(self,\n                          given_betas=None, beta_schedule="linear", timesteps=1000,\n                          linear_start=1e-4, linear_end=2e-2, cosine_s=8e-3):\n        super().register_schedule(given_betas, beta_schedule, timesteps, linear_start, linear_end, cosine_s)\n\n        self.shorten_cond_schedule = self.num_timesteps_cond > 1\n        if self.shorten_cond_schedule:\n            self.make_cond_schedule()\n\n    def instantiate_first_stage(self, config):\n        model = instantiate_from_config(config)\n        self.first_stage_model = model.eval()\n        self.first_stage_model.train = disabled_train\n        for param in self.first_stage_model.parameters():\n            param.requires_grad = False\n\n    def instantiate_cond_stage(self, config):\n        if not self.cond_stage_trainable:\n            if config == "__is_first_stage__":\n                print("Using first stage also as cond stage.")\n                self.cond_stage_model = self.first_stage_model\n            elif config == "__is_unconditional__":\n                print(f"Training {self.__class__.__name__} as an unconditional model.")\n                self.cond_stage_model = None\n                # self.be_unconditional = True\n            else:\n                model = instantiate_from_config(config)\n                self.cond_stage_model = model.eval()\n                self.cond_stage_model.train = disabled_train\n                for param in self.cond_stage_model.parameters():\n                    param.requires_grad = False\n        else:\n            assert config != \'__is_first_stage__\'\n            assert config != \'__is_unconditional__\'\n            model = instantiate_from_config(config)\n            self.cond_stage_model = model\n\n    def _get_denoise_row_from_list(self, samples, desc=\'\', force_no_decoder_quantization=False):\n        denoise_row = []\n        for zd in tqdm(samples, desc=desc):\n            denoise_row.append(self.decode_first_stage(zd.to(self.device),\n                                                            force_not_quantize=force_no_decoder_quantization))\n        n_imgs_per_row = len(denoise_row)\n        denoise_row = torch.stack(denoise_row)  # n_log_step, n_row, C, H, W\n        denoise_grid = rearrange(denoise_row, \'n b c h w -> b n c h w\')\n        denoise_grid = rearrange(denoise_grid, \'b n c h w -> (b n) c h w\')\n        denoise_grid = make_grid(denoise_grid, nrow=n_imgs_per_row)\n        return denoise_grid\n\n    def get_first_stage_encoding(self, encoder_posterior):\n        if isinstance(encoder_posterior, DiagonalGaussianDistribution):\n            z = encoder_posterior.sample()\n        elif isinstance(encoder_posterior, torch.Tensor):\n            z = encoder_posterior\n        else:\n            raise NotImplementedError(f"encoder_posterior of type \'{type(encoder_posterior)}\' not yet implemented")\n        return self.scale_factor * z\n\n    def get_learned_conditioning(self, c):\n        if self.cond_stage_forward is None:\n            if hasattr(self.cond_stage_model, \'encode\') and callable(self.cond_stage_model.encode):\n                c = self.cond_stage_model.encode(c)\n                if isinstance(c, DiagonalGaussianDistribution):\n                    c = c.mode()\n            else:\n                c = self.cond_stage_model(c)\n        else:\n            assert hasattr(self.cond_stage_model, self.cond_stage_forward)\n            c = getattr(self.cond_stage_model, self.cond_stage_forward)(c)\n        return c\n\n    def meshgrid(self, h, w):\n        y = torch.arange(0, h).view(h, 1, 1).repeat(1, w, 1)\n        x = torch.arange(0, w).view(1, w, 1).repeat(h, 1, 1)\n\n        arr = torch.cat([y, x], dim=-1)\n        return arr\n\n    def delta_border(self, h, w):\n        """\n        :param h: height\n        :param w: width\n        :return: normalized distance to image border,\n         wtith min distance = 0 at border and max dist = 0.5 at image center\n        """\n        lower_right_corner = torch.tensor([h - 1, w - 1]).view(1, 1, 2)\n        arr = self.meshgrid(h, w) / lower_right_corner\n        dist_left_up = torch.min(arr, dim=-1, keepdims=True)[0]\n        dist_right_down = torch.min(1 - arr, dim=-1, keepdims=True)[0]\n        edge_dist = torch.min(torch.cat([dist_left_up, dist_right_down], dim=-1), dim=-1)[0]\n        return edge_dist\n\n    def get_weighting(self, h, w, Ly, Lx, device):\n        weighting = self.delta_border(h, w)\n        weighting = torch.clip(weighting, self.split_input_params["clip_min_weight"],\n                               self.split_input_params["clip_max_weight"], )\n        weighting = weighting.view(1, h * w, 1).repeat(1, 1, Ly * Lx).to(device)\n\n        if self.split_input_params["tie_braker"]:\n            L_weighting = self.delta_border(Ly, Lx)\n            L_weighting = torch.clip(L_weighting,\n                                     self.split_input_params["clip_min_tie_weight"],\n                                     self.split_input_params["clip_max_tie_weight"])\n\n            L_weighting = L_weighting.view(1, 1, Ly * Lx).to(device)\n            weighting = weighting * L_weighting\n        return weighting\n\n    def get_fold_unfold(self, x, kernel_size, stride, uf=1, df=1):  # todo load once not every time, shorten code\n        """\n        :param x: img of size (bs, c, h, w)\n        :return: n img crops of size (n, bs, c, kernel_size[0], kernel_size[1])\n        """\n        bs, nc, h, w = x.shape\n\n        # number of crops in image\n        Ly = (h - kernel_size[0]) // stride[0] + 1\n        Lx = (w - kernel_size[1]) // stride[1] + 1\n\n        if uf == 1 and df == 1:\n            fold_params = dict(kernel_size=kernel_size, dilation=1, padding=0, stride=stride)\n            unfold = torch.nn.Unfold(**fold_params)\n\n            fold = torch.nn.Fold(output_size=x.shape[2:], **fold_params)\n\n            weighting = self.get_weighting(kernel_size[0], kernel_size[1], Ly, Lx, x.device).to(x.dtype)\n            normalization = fold(weighting).view(1, 1, h, w)  # normalizes the overlap\n            weighting = weighting.view((1, 1, kernel_size[0], kernel_size[1], Ly * Lx))\n\n        elif uf > 1 and df == 1:\n            fold_params = dict(kernel_size=kernel_size, dilation=1, padding=0, stride=stride)\n            unfold = torch.nn.Unfold(**fold_params)\n\n            fold_params2 = dict(kernel_size=(kernel_size[0] * uf, kernel_size[0] * uf),\n                                dilation=1, padding=0,\n                                stride=(stride[0] * uf, stride[1] * uf))\n            fold = torch.nn.Fold(output_size=(x.shape[2] * uf, x.shape[3] * uf), **fold_params2)\n\n            weighting = self.get_weighting(kernel_size[0] * uf, kernel_size[1] * uf, Ly, Lx, x.device).to(x.dtype)\n            normalization = fold(weighting).view(1, 1, h * uf, w * uf)  # normalizes the overlap\n            weighting = weighting.view((1, 1, kernel_size[0] * uf, kernel_size[1] * uf, Ly * Lx))\n\n        elif df > 1 and uf == 1:\n            fold_params = dict(kernel_size=kernel_size, dilation=1, padding=0, stride=stride)\n            unfold = torch.nn.Unfold(**fold_params)\n\n            fold_params2 = dict(kernel_size=(kernel_size[0] // df, kernel_size[0] // df),\n                                dilation=1, padding=0,\n                                stride=(stride[0] // df, stride[1] // df))\n            fold = torch.nn.Fold(output_size=(x.shape[2] // df, x.shape[3] // df), **fold_params2)\n\n            weighting = self.get_weighting(kernel_size[0] // df, kernel_size[1] // df, Ly, Lx, x.device).to(x.dtype)\n            normalization = fold(weighting).view(1, 1, h // df, w // df)  # normalizes the overlap\n            weighting = weighting.view((1, 1, kernel_size[0] // df, kernel_size[1] // df, Ly * Lx))\n\n        else:\n            raise NotImplementedError\n\n        return fold, unfold, normalization, weighting\n\n    @torch.no_grad()\n    def get_input(self, batch, k, return_first_stage_outputs=False, force_c_encode=False,\n                  cond_key=None, return_original_cond=False, bs=None):\n        x = super().get_input(batch, k)\n        if bs is not None:\n            x = x[:bs]\n        x = x.to(self.device)\n        encoder_posterior = self.encode_first_stage(x)\n        z = self.get_first_stage_encoding(encoder_posterior).detach()\n\n        if self.model.conditioning_key is not None:\n            if cond_key is None:\n                cond_key = self.cond_stage_key\n            if cond_key != self.first_stage_key:\n                if cond_key in [\'caption\', \'coordinates_bbox\']:\n                    xc = batch[cond_key]\n                elif cond_key == \'class_label\':\n                    xc = batch\n                else:\n                    xc = super().get_input(batch, cond_key).to(self.device)\n            else:\n                xc = x\n            if not self.cond_stage_trainable or force_c_encode:\n                if isinstance(xc, dict) or isinstance(xc, list):\n                    # import pudb; pudb.set_trace()\n                    c = self.get_learned_conditioning(xc)\n                else:\n                    c = self.get_learned_conditioning(xc.to(self.device))\n            else:\n                c = xc\n            if bs is not None:\n                c = c[:bs]\n\n            if self.use_positional_encodings:\n                pos_x, pos_y = self.compute_latent_shifts(batch)\n                ckey = __conditioning_keys__[self.model.conditioning_key]\n                c = {ckey: c, \'pos_x\': pos_x, \'pos_y\': pos_y}\n\n        else:\n            c = None\n            xc = None\n            if self.use_positional_encodings:\n                pos_x, pos_y = self.compute_latent_shifts(batch)\n                c = {\'pos_x\': pos_x, \'pos_y\': pos_y}\n        out = [z, c]\n        if return_first_stage_outputs:\n            xrec = self.decode_first_stage(z)\n            out.extend([x, xrec])\n        if return_original_cond:\n            out.append(xc)\n        return out\n\n    @torch.no_grad()\n    def decode_first_stage(self, z, predict_cids=False, force_not_quantize=False):\n        if predict_cids:\n            if z.dim() == 4:\n                z = torch.argmax(z.exp(), dim=1).long()\n            z = self.first_stage_model.quantize.get_codebook_entry(z, shape=None)\n            z = rearrange(z, \'b h w c -> b c h w\').contiguous()\n\n        z = 1. / self.scale_factor * z\n\n        if hasattr(self, "split_input_params"):\n            if self.split_input_params["patch_distributed_vq"]:\n                ks = self.split_input_params["ks"]  # eg. (128, 128)\n                stride = self.split_input_params["stride"]  # eg. (64, 64)\n                uf = self.split_input_params["vqf"]\n                bs, nc, h, w = z.shape\n                if ks[0] > h or ks[1] > w:\n                    ks = (min(ks[0], h), min(ks[1], w))\n                    print("reducing Kernel")\n\n                if stride[0] > h or stride[1] > w:\n                    stride = (min(stride[0], h), min(stride[1], w))\n                    print("reducing stride")\n\n                fold, unfold, normalization, weighting = self.get_fold_unfold(z, ks, stride, uf=uf)\n\n                z = unfold(z)  # (bn, nc * prod(**ks), L)\n                # 1. Reshape to img shape\n                z = z.view((z.shape[0], -1, ks[0], ks[1], z.shape[-1]))  # (bn, nc, ks[0], ks[1], L )\n\n                # 2. apply model loop over last dim\n                if isinstance(self.first_stage_model, VQModelInterface):\n                    output_list = [self.first_stage_model.decode(z[:, :, :, :, i],\n                                                                 force_not_quantize=predict_cids or force_not_quantize)\n                                   for i in range(z.shape[-1])]\n                else:\n\n                    output_list = [self.first_stage_model.decode(z[:, :, :, :, i])\n                                   for i in range(z.shape[-1])]\n\n                o = torch.stack(output_list, axis=-1)  # # (bn, nc, ks[0], ks[1], L)\n                o = o * weighting\n                # Reverse 1. reshape to img shape\n                o = o.view((o.shape[0], -1, o.shape[-1]))  # (bn, nc * ks[0] * ks[1], L)\n                # stitch crops together\n                decoded = fold(o)\n                decoded = decoded / normalization  # norm is shape (1, 1, h, w)\n                return decoded\n            else:\n                if isinstance(self.first_stage_model, VQModelInterface):\n                    return self.first_stage_model.decode(z, force_not_quantize=predict_cids or force_not_quantize)\n                else:\n                    return self.first_stage_model.decode(z)\n\n        else:\n            if isinstance(self.first_stage_model, VQModelInterface):\n                return self.first_stage_model.decode(z, force_not_quantize=predict_cids or force_not_quantize)\n            else:\n                return self.first_stage_model.decode(z)\n\n    # same as above but without decorator\n    def differentiable_decode_first_stage(self, z, predict_cids=False, force_not_quantize=False):\n        if predict_cids:\n            if z.dim() == 4:\n                z = torch.argmax(z.exp(), dim=1).long()\n            z = self.first_stage_model.quantize.get_codebook_entry(z, shape=None)\n            z = rearrange(z, \'b h w c -> b c h w\').contiguous()\n\n        z = 1. / self.scale_factor * z\n\n        if hasattr(self, "split_input_params"):\n            if self.split_input_params["patch_distributed_vq"]:\n                ks = self.split_input_params["ks"]  # eg. (128, 128)\n                stride = self.split_input_params["stride"]  # eg. (64, 64)\n                uf = self.split_input_params["vqf"]\n                bs, nc, h, w = z.shape\n                if ks[0] > h or ks[1] > w:\n                    ks = (min(ks[0], h), min(ks[1], w))\n                    print("reducing Kernel")\n\n                if stride[0] > h or stride[1] > w:\n                    stride = (min(stride[0], h), min(stride[1], w))\n                    print("reducing stride")\n\n                fold, unfold, normalization, weighting = self.get_fold_unfold(z, ks, stride, uf=uf)\n\n                z = unfold(z)  # (bn, nc * prod(**ks), L)\n                # 1. Reshape to img shape\n                z = z.view((z.shape[0], -1, ks[0], ks[1], z.shape[-1]))  # (bn, nc, ks[0], ks[1], L )\n\n                # 2. apply model loop over last dim\n                if isinstance(self.first_stage_model, VQModelInterface):  \n                    output_list = [self.first_stage_model.decode(z[:, :, :, :, i],\n                                                                 force_not_quantize=predict_cids or force_not_quantize)\n                                   for i in range(z.shape[-1])]\n                else:\n\n                    output_list = [self.first_stage_model.decode(z[:, :, :, :, i])\n                                   for i in range(z.shape[-1])]\n\n                o = torch.stack(output_list, axis=-1)  # # (bn, nc, ks[0], ks[1], L)\n                o = o * weighting\n                # Reverse 1. reshape to img shape\n                o = o.view((o.shape[0], -1, o.shape[-1]))  # (bn, nc * ks[0] * ks[1], L)\n                # stitch crops together\n                decoded = fold(o)\n                decoded = decoded / normalization  # norm is shape (1, 1, h, w)\n                return decoded\n            else:\n                if isinstance(self.first_stage_model, VQModelInterface):\n                    return self.first_stage_model.decode(z, force_not_quantize=predict_cids or force_not_quantize)\n                else:\n                    return self.first_stage_model.decode(z)\n\n        else:\n            if isinstance(self.first_stage_model, VQModelInterface):\n                return self.first_stage_model.decode(z, force_not_quantize=predict_cids or force_not_quantize)\n            else:\n                return self.first_stage_model.decode(z)\n\n    @torch.no_grad()\n    def encode_first_stage(self, x):\n        if hasattr(self, "split_input_params"):\n            if self.split_input_params["patch_distributed_vq"]:\n                ks = self.split_input_params["ks"]  # eg. (128, 128)\n                stride = self.split_input_params["stride"]  # eg. (64, 64)\n                df = self.split_input_params["vqf"]\n                self.split_input_params[\'original_image_size\'] = x.shape[-2:]\n                bs, nc, h, w = x.shape\n                if ks[0] > h or ks[1] > w:\n                    ks = (min(ks[0], h), min(ks[1], w))\n                    print("reducing Kernel")\n\n                if stride[0] > h or stride[1] > w:\n                    stride = (min(stride[0], h), min(stride[1], w))\n                    print("reducing stride")\n\n                fold, unfold, normalization, weighting = self.get_fold_unfold(x, ks, stride, df=df)\n                z = unfold(x)  # (bn, nc * prod(**ks), L)\n                # Reshape to img shape\n                z = z.view((z.shape[0], -1, ks[0], ks[1], z.shape[-1]))  # (bn, nc, ks[0], ks[1], L )\n\n                output_list = [self.first_stage_model.encode(z[:, :, :, :, i])\n                               for i in range(z.shape[-1])]\n\n                o = torch.stack(output_list, axis=-1)\n                o = o * weighting\n\n                # Reverse reshape to img shape\n                o = o.view((o.shape[0], -1, o.shape[-1]))  # (bn, nc * ks[0] * ks[1], L)\n                # stitch crops together\n                decoded = fold(o)\n                decoded = decoded / normalization\n                return decoded\n\n            else:\n                return self.first_stage_model.encode(x)\n        else:\n            return self.first_stage_model.encode(x)\n\n    def shared_step(self, batch, **kwargs):\n        x, c = self.get_input(batch, self.first_stage_key)\n        loss = self(x, c)\n        return loss\n\n    def forward(self, x, c, *args, **kwargs):\n        t = torch.randint(0, self.num_timesteps, (x.shape[0],), device=self.device).long()\n        if self.model.conditioning_key is not None:\n            assert c is not None\n            if self.cond_stage_trainable:\n                c = self.get_learned_conditioning(c)\n            if self.shorten_cond_schedule:  # TODO: drop this option\n                tc = self.cond_ids[t].to(self.device)\n                c = self.q_sample(x_start=c, t=tc, noise=torch.randn_like(c.float()))\n        return self.p_losses(x, c, t, *args, **kwargs)\n\n    def _rescale_annotations(self, bboxes, crop_coordinates):  # TODO: move to dataset\n        def rescale_bbox(bbox):\n            x0 = clamp((bbox[0] - crop_coordinates[0]) / crop_coordinates[2])\n            y0 = clamp((bbox[1] - crop_coordinates[1]) / crop_coordinates[3])\n            w = min(bbox[2] / crop_coordinates[2], 1 - x0)\n            h = min(bbox[3] / crop_coordinates[3], 1 - y0)\n            return x0, y0, w, h\n\n        return [rescale_bbox(b) for b in bboxes]\n\n    def apply_model(self, x_noisy, t, cond, return_ids=False):\n\n        if isinstance(cond, dict):\n            # hybrid case, cond is exptected to be a dict\n            pass\n        else:\n            if not isinstance(cond, list):\n                cond = [cond]\n            key = \'c_concat\' if self.model.conditioning_key == \'concat\' else \'c_crossattn\'\n            cond = {key: cond}\n\n        if hasattr(self, "split_input_params"):\n            assert len(cond) == 1  # todo can only deal with one conditioning atm\n            assert not return_ids  \n            ks = self.split_input_params["ks"]  # eg. (128, 128)\n            stride = self.split_input_params["stride"]  # eg. (64, 64)\n\n            h, w = x_noisy.shape[-2:]\n\n            fold, unfold, normalization, weighting = self.get_fold_unfold(x_noisy, ks, stride)\n\n            z = unfold(x_noisy)  # (bn, nc * prod(**ks), L)\n            # Reshape to img shape\n            z = z.view((z.shape[0], -1, ks[0], ks[1], z.shape[-1]))  # (bn, nc, ks[0], ks[1], L )\n            z_list = [z[:, :, :, :, i] for i in range(z.shape[-1])]\n\n            if self.cond_stage_key in ["image", "LR_image", "segmentation",\n                                       \'bbox_img\'] and self.model.conditioning_key:  # todo check for completeness\n                c_key = next(iter(cond.keys()))  # get key\n                c = next(iter(cond.values()))  # get value\n                assert (len(c) == 1)  # todo extend to list with more than one elem\n                c = c[0]  # get element\n\n                c = unfold(c)\n                c = c.view((c.shape[0], -1, ks[0], ks[1], c.shape[-1]))  # (bn, nc, ks[0], ks[1], L )\n\n                cond_list = [{c_key: [c[:, :, :, :, i]]} for i in range(c.shape[-1])]\n\n            elif self.cond_stage_key == \'coordinates_bbox\':\n                assert \'original_image_size\' in self.split_input_params, \'BoudingBoxRescaling is missing original_image_size\'\n\n                # assuming padding of unfold is always 0 and its dilation is always 1\n                n_patches_per_row = int((w - ks[0]) / stride[0] + 1)\n                full_img_h, full_img_w = self.split_input_params[\'original_image_size\']\n                # as we are operating on latents, we need the factor from the original image size to the\n                # spatial latent size to properly rescale the crops for regenerating the bbox annotations\n                num_downs = self.first_stage_model.encoder.num_resolutions - 1\n                rescale_latent = 2 ** (num_downs)\n\n                # get top left postions of patches as conforming for the bbbox tokenizer, therefore we\n                # need to rescale the tl patch coordinates to be in between (0,1)\n                tl_patch_coordinates = [(rescale_latent * stride[0] * (patch_nr % n_patches_per_row) / full_img_w,\n                                         rescale_latent * stride[1] * (patch_nr // n_patches_per_row) / full_img_h)\n                                        for patch_nr in range(z.shape[-1])]\n\n                # patch_limits are tl_coord, width and height coordinates as (x_tl, y_tl, h, w)\n                patch_limits = [(x_tl, y_tl,\n                                 rescale_latent * ks[0] / full_img_w,\n                                 rescale_latent * ks[1] / full_img_h) for x_tl, y_tl in tl_patch_coordinates]\n                # patch_values = [(np.arange(x_tl,min(x_tl+ks, 1.)),np.arange(y_tl,min(y_tl+ks, 1.))) for x_tl, y_tl in tl_patch_coordinates]\n\n                # tokenize crop coordinates for the bounding boxes of the respective patches\n                patch_limits_tknzd = [torch.LongTensor(self.bbox_tokenizer._crop_encoder(bbox))[None].to(self.device)\n                                      for bbox in patch_limits]  # list of length l with tensors of shape (1, 2)\n                print(patch_limits_tknzd[0].shape)\n                # cut tknzd crop position from conditioning\n                assert isinstance(cond, dict), \'cond must be dict to be fed into model\'\n                cut_cond = cond[\'c_crossattn\'][0][..., :-2].to(self.device)\n                print(cut_cond.shape)\n\n                adapted_cond = torch.stack([torch.cat([cut_cond, p], dim=1) for p in patch_limits_tknzd])\n                adapted_cond = rearrange(adapted_cond, \'l b n -> (l b) n\')\n                print(adapted_cond.shape)\n                adapted_cond = self.get_learned_conditioning(adapted_cond)\n                print(adapted_cond.shape)\n                adapted_cond = rearrange(adapted_cond, \'(l b) n d -> l b n d\', l=z.shape[-1])\n                print(adapted_cond.shape)\n\n                cond_list = [{\'c_crossattn\': [e]} for e in adapted_cond]\n\n            else:\n                cond_list = [cond for i in range(z.shape[-1])]  # Todo make this more efficient\n\n            # apply model by loop over crops\n            output_list = [self.model(z_list[i], t, **cond_list[i]) for i in range(z.shape[-1])]\n            assert not isinstance(output_list[0],\n                                  tuple)  # todo cant deal with multiple model outputs check this never happens\n\n            o = torch.stack(output_list, axis=-1)\n            o = o * weighting\n            # Reverse reshape to img shape\n            o = o.view((o.shape[0], -1, o.shape[-1]))  # (bn, nc * ks[0] * ks[1], L)\n            # stitch crops together\n            x_recon = fold(o) / normalization\n\n        else:\n            x_recon = self.model(x_noisy, t, **cond)\n\n        if isinstance(x_recon, tuple) and not return_ids:\n            return x_recon[0]\n        else:\n            return x_recon\n\n    def _predict_eps_from_xstart(self, x_t, t, pred_xstart):\n        return (extract_into_tensor(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t - pred_xstart) / \\\n               extract_into_tensor(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape)\n\n    def _prior_bpd(self, x_start):\n        """\n        Get the prior KL term for the variational lower-bound, measured in\n        bits-per-dim.\n        This term can\'t be optimized, as it only depends on the encoder.\n        :param x_start: the [N x C x ...] tensor of inputs.\n        :return: a batch of [N] KL values (in bits), one per batch element.\n        """\n        batch_size = x_start.shape[0]\n        t = torch.tensor([self.num_timesteps - 1] * batch_size, device=x_start.device)\n        qt_mean, _, qt_log_variance = self.q_mean_variance(x_start, t)\n        kl_prior = normal_kl(mean1=qt_mean, logvar1=qt_log_variance, mean2=0.0, logvar2=0.0)\n        return mean_flat(kl_prior) / np.log(2.0)\n\n    def p_losses(self, x_start, cond, t, noise=None):\n        noise = default(noise, lambda: torch.randn_like(x_start))\n        x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)\n        model_output = self.apply_model(x_noisy, t, cond)\n\n        loss_dict = {}\n        prefix = \'train\' if self.training else \'val\'\n\n        if self.parameterization == "x0":\n            target = x_start\n        elif self.parameterization == "eps":\n            target = noise\n        else:\n            raise NotImplementedError()\n\n        loss_simple = self.get_loss(model_output, target, mean=False).mean([1, 2, 3])\n        loss_dict.update({f\'{prefix}/loss_simple\': loss_simple.mean()})\n\n        logvar_t = self.logvar[t].to(self.device)\n        loss = loss_simple / torch.exp(logvar_t) + logvar_t\n        # loss = loss_simple / torch.exp(self.logvar) + self.logvar\n        if self.learn_logvar:\n            loss_dict.update({f\'{prefix}/loss_gamma\': loss.mean()})\n            loss_dict.update({\'logvar\': self.logvar.data.mean()})\n\n        loss = self.l_simple_weight * loss.mean()\n\n        loss_vlb = self.get_loss(model_output, target, mean=False).mean(dim=(1, 2, 3))\n        loss_vlb = (self.lvlb_weights[t] * loss_vlb).mean()\n        loss_dict.update({f\'{prefix}/loss_vlb\': loss_vlb})\n        loss += (self.original_elbo_weight * loss_vlb)\n        loss_dict.update({f\'{prefix}/loss\': loss})\n\n        return loss, loss_dict\n\n    def p_mean_variance(self, x, c, t, clip_denoised: bool, return_codebook_ids=False, quantize_denoised=False,\n                        return_x0=False, score_corrector=None, corrector_kwargs=None):\n        t_in = t\n        model_out = self.apply_model(x, t_in, c, return_ids=return_codebook_ids)\n\n        if score_corrector is not None:\n            assert self.parameterization == "eps"\n            model_out = score_corrector.modify_score(self, model_out, x, t, c, **corrector_kwargs)\n\n        if return_codebook_ids:\n            model_out, logits = model_out\n\n        if self.parameterization == "eps":\n            x_recon = self.predict_start_from_noise(x, t=t, noise=model_out)\n        elif self.parameterization == "x0":\n            x_recon = model_out\n        else:\n            raise NotImplementedError()\n\n        if clip_denoised:\n            x_recon.clamp_(-1., 1.)\n        if quantize_denoised:\n            x_recon, _, [_, _, indices] = self.first_stage_model.quantize(x_recon)\n        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(x_start=x_recon, x_t=x, t=t)\n        if return_codebook_ids:\n            return model_mean, posterior_variance, posterior_log_variance, logits\n        elif return_x0:\n            return model_mean, posterior_variance, posterior_log_variance, x_recon\n        else:\n            return model_mean, posterior_variance, posterior_log_variance\n\n    @torch.no_grad()\n    def p_sample(self, x, c, t, clip_denoised=False, repeat_noise=False,\n                 return_codebook_ids=False, quantize_denoised=False, return_x0=False,\n                 temperature=1., noise_dropout=0., score_corrector=None, corrector_kwargs=None):\n        b, *_, device = *x.shape, x.device\n        outputs = self.p_mean_variance(x=x, c=c, t=t, clip_denoised=clip_denoised,\n                                       return_codebook_ids=return_codebook_ids,\n                                       quantize_denoised=quantize_denoised,\n                                       return_x0=return_x0,\n                                       score_corrector=score_corrector, corrector_kwargs=corrector_kwargs)\n        if return_codebook_ids:\n            raise DeprecationWarning("Support dropped.")\n            model_mean, _, model_log_variance, logits = outputs\n        elif return_x0:\n            model_mean, _, model_log_variance, x0 = outputs\n        else:\n            model_mean, _, model_log_variance = outputs\n\n        noise = noise_like(x.shape, device, repeat_noise) * temperature\n        if noise_dropout > 0.:\n            noise = torch.nn.functional.dropout(noise, p=noise_dropout)\n        # no noise when t == 0\n        nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))\n\n        if return_codebook_ids:\n            return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise, logits.argmax(dim=1)\n        if return_x0:\n            return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise, x0\n        else:\n            return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise\n\n    @torch.no_grad()\n    def progressive_denoising(self, cond, shape, verbose=True, callback=None, quantize_denoised=False,\n                              img_callback=None, mask=None, x0=None, temperature=1., noise_dropout=0.,\n                              score_corrector=None, corrector_kwargs=None, batch_size=None, x_T=None, start_T=None,\n                              log_every_t=None):\n        if not log_every_t:\n            log_every_t = self.log_every_t\n        timesteps = self.num_timesteps\n        if batch_size is not None:\n            b = batch_size if batch_size is not None else shape[0]\n            shape = [batch_size] + list(shape)\n        else:\n            b = batch_size = shape[0]\n        if x_T is None:\n            img = torch.randn(shape, device=self.device)\n        else:\n            img = x_T\n        intermediates = []\n        if cond is not None:\n            if isinstance(cond, dict):\n                cond = {key: cond[key][:batch_size] if not isinstance(cond[key], list) else\n                list(map(lambda x: x[:batch_size], cond[key])) for key in cond}\n            else:\n                cond = [c[:batch_size] for c in cond] if isinstance(cond, list) else cond[:batch_size]\n\n        if start_T is not None:\n            timesteps = min(timesteps, start_T)\n        iterator = tqdm(reversed(range(0, timesteps)), desc=\'Progressive Generation\',\n                        total=timesteps) if verbose else reversed(\n            range(0, timesteps))\n        if type(temperature) == float:\n            temperature = [temperature] * timesteps\n\n        for i in iterator:\n            ts = torch.full((b,), i, device=self.device, dtype=torch.long)\n            if self.shorten_cond_schedule:\n                assert self.model.conditioning_key != \'hybrid\'\n                tc = self.cond_ids[ts].to(cond.device)\n                cond = self.q_sample(x_start=cond, t=tc, noise=torch.randn_like(cond))\n\n            img, x0_partial = self.p_sample(img, cond, ts,\n                                            clip_denoised=self.clip_denoised,\n                                            quantize_denoised=quantize_denoised, return_x0=True,\n                                            temperature=temperature[i], noise_dropout=noise_dropout,\n                                            score_corrector=score_corrector, corrector_kwargs=corrector_kwargs)\n            if mask is not None:\n                assert x0 is not None\n                img_orig = self.q_sample(x0, ts)\n                img = img_orig * mask + (1. - mask) * img\n\n            if i % log_every_t == 0 or i == timesteps - 1:\n                intermediates.append(x0_partial)\n            if callback: callback(i)\n            if img_callback: img_callback(img, i)\n        return img, intermediates\n\n    @torch.no_grad()\n    def p_sample_loop(self, cond, shape, return_intermediates=False,\n                      x_T=None, verbose=True, callback=None, timesteps=None, quantize_denoised=False,\n                      mask=None, x0=None, img_callback=None, start_T=None,\n                      log_every_t=None):\n\n        if not log_every_t:\n            log_every_t = self.log_every_t\n        device = self.betas.device\n        b = shape[0]\n        if x_T is None:\n            img = torch.randn(shape, device=device)\n        else:\n            img = x_T\n\n        intermediates = [img]\n        if timesteps is None:\n            timesteps = self.num_timesteps\n\n        if start_T is not None:\n            timesteps = min(timesteps, start_T)\n        iterator = tqdm(reversed(range(0, timesteps)), desc=\'Sampling t\', total=timesteps) if verbose else reversed(\n            range(0, timesteps))\n\n        if mask is not None:\n            assert x0 is not None\n            assert x0.shape[2:3] == mask.shape[2:3]  # spatial size has to match\n\n        for i in iterator:\n            ts = torch.full((b,), i, device=device, dtype=torch.long)\n            if self.shorten_cond_schedule:\n                assert self.model.conditioning_key != \'hybrid\'\n                tc = self.cond_ids[ts].to(cond.device)\n                cond = self.q_sample(x_start=cond, t=tc, noise=torch.randn_like(cond))\n\n            img = self.p_sample(img, cond, ts,\n                                clip_denoised=self.clip_denoised,\n                                quantize_denoised=quantize_denoised)\n            if mask is not None:\n                img_orig = self.q_sample(x0, ts)\n                img = img_orig * mask + (1. - mask) * img\n\n            if i % log_every_t == 0 or i == timesteps - 1:\n                intermediates.append(img)\n            if callback: callback(i)\n            if img_callback: img_callback(img, i)\n\n        if return_intermediates:\n            return img, intermediates\n        return img\n\n    @torch.no_grad()\n    def sample(self, cond, batch_size=16, return_intermediates=False, x_T=None,\n               verbose=True, timesteps=None, quantize_denoised=False,\n               mask=None, x0=None, shape=None,**kwargs):\n        if shape is None:\n            shape = (batch_size, self.channels, self.image_size, self.image_size)\n        if cond is not None:\n            if isinstance(cond, dict):\n                cond = {key: cond[key][:batch_size] if not isinstance(cond[key], list) else\n                list(map(lambda x: x[:batch_size], cond[key])) for key in cond}\n            else:\n                cond = [c[:batch_size] for c in cond] if isinstance(cond, list) else cond[:batch_size]\n        return self.p_sample_loop(cond,\n                                  shape,\n                                  return_intermediates=return_intermediates, x_T=x_T,\n                                  verbose=verbose, timesteps=timesteps, quantize_denoised=quantize_denoised,\n                                  mask=mask, x0=x0)\n\n    @torch.no_grad()\n    def sample_log(self,cond,batch_size,ddim, ddim_steps,**kwargs):\n\n        if ddim:\n            ddim_sampler = DDIMSampler(self)\n            shape = (self.channels, self.image_size, self.image_size)\n            samples, intermediates =ddim_sampler.sample(ddim_steps,batch_size,\n                                                        shape,cond,verbose=False,**kwargs)\n\n        else:\n            samples, intermediates = self.sample(cond=cond, batch_size=batch_size,\n                                                 return_intermediates=True,**kwargs)\n\n        return samples, intermediates\n\n\n    @torch.no_grad()\n    def log_images(self, batch, N=8, n_row=4, sample=True, ddim_steps=200, ddim_eta=1., return_keys=None,\n                   quantize_denoised=True, inpaint=True, plot_denoise_rows=False, plot_progressive_rows=True,\n                   plot_diffusion_rows=True, **kwargs):\n\n        use_ddim = ddim_steps is not None\n\n        log = dict()\n        z, c, x, xrec, xc = self.get_input(batch, self.first_stage_key,\n                                           return_first_stage_outputs=True,\n                                           force_c_encode=True,\n                                           return_original_cond=True,\n                                           bs=N)\n        N = min(x.shape[0], N)\n        n_row = min(x.shape[0], n_row)\n        log["inputs"] = x\n        log["reconstruction"] = xrec\n        if self.model.conditioning_key is not None:\n            if hasattr(self.cond_stage_model, "decode"):\n                xc = self.cond_stage_model.decode(c)\n                log["conditioning"] = xc\n            elif self.cond_stage_key in ["caption"]:\n                xc = log_txt_as_img((x.shape[2], x.shape[3]), batch["caption"])\n                log["conditioning"] = xc\n            elif self.cond_stage_key == \'class_label\':\n                xc = log_txt_as_img((x.shape[2], x.shape[3]), batch["human_label"])\n                log[\'conditioning\'] = xc\n            elif isimage(xc):\n                log["conditioning"] = xc\n            if ismap(xc):\n                log["original_conditioning"] = self.to_rgb(xc)\n\n        if plot_diffusion_rows:\n            # get diffusion row\n            diffusion_row = list()\n            z_start = z[:n_row]\n            for t in range(self.num_timesteps):\n                if t % self.log_every_t == 0 or t == self.num_timesteps - 1:\n                    t = repeat(torch.tensor([t]), \'1 -> b\', b=n_row)\n                    t = t.to(self.device).long()\n                    noise = torch.randn_like(z_start)\n                    z_noisy = self.q_sample(x_start=z_start, t=t, noise=noise)\n                    diffusion_row.append(self.decode_first_stage(z_noisy))\n\n            diffusion_row = torch.stack(diffusion_row)  # n_log_step, n_row, C, H, W\n            diffusion_grid = rearrange(diffusion_row, \'n b c h w -> b n c h w\')\n            diffusion_grid = rearrange(diffusion_grid, \'b n c h w -> (b n) c h w\')\n            diffusion_grid = make_grid(diffusion_grid, nrow=diffusion_row.shape[0])\n            log["diffusion_row"] = diffusion_grid\n\n        if sample:\n            # get denoise row\n            with self.ema_scope("Plotting"):\n                samples, z_denoise_row = self.sample_log(cond=c,batch_size=N,ddim=use_ddim,\n                                                         ddim_steps=ddim_steps,eta=ddim_eta)\n                # samples, z_denoise_row = self.sample(cond=c, batch_size=N, return_intermediates=True)\n            x_samples = self.decode_first_stage(samples)\n            log["samples"] = x_samples\n            if plot_denoise_rows:\n                denoise_grid = self._get_denoise_row_from_list(z_denoise_row)\n                log["denoise_row"] = denoise_grid\n\n            if quantize_denoised and not isinstance(self.first_stage_model, AutoencoderKL) and not isinstance(\n                    self.first_stage_model, IdentityFirstStage):\n                # also display when quantizing x0 while sampling\n                with self.ema_scope("Plotting Quantized Denoised"):\n                    samples, z_denoise_row = self.sample_log(cond=c,batch_size=N,ddim=use_ddim,\n                                                             ddim_steps=ddim_steps,eta=ddim_eta,\n                                                             quantize_denoised=True)\n                    # samples, z_denoise_row = self.sample(cond=c, batch_size=N, return_intermediates=True,\n                    #                                      quantize_denoised=True)\n                x_samples = self.decode_first_stage(samples.to(self.device))\n                log["samples_x0_quantized"] = x_samples\n\n            if inpaint:\n                # make a simple center square\n                b, h, w = z.shape[0], z.shape[2], z.shape[3]\n                mask = torch.ones(N, h, w).to(self.device)\n                # zeros will be filled in\n                mask[:, h // 4:3 * h // 4, w // 4:3 * w // 4] = 0.\n                mask = mask[:, None, ...]\n                with self.ema_scope("Plotting Inpaint"):\n\n                    samples, _ = self.sample_log(cond=c,batch_size=N,ddim=use_ddim, eta=ddim_eta,\n                                                ddim_steps=ddim_steps, x0=z[:N], mask=mask)\n                x_samples = self.decode_first_stage(samples.to(self.device))\n                log["samples_inpainting"] = x_samples\n                log["mask"] = mask\n\n                # outpaint\n                with self.ema_scope("Plotting Outpaint"):\n                    samples, _ = self.sample_log(cond=c, batch_size=N, ddim=use_ddim,eta=ddim_eta,\n                                                ddim_steps=ddim_steps, x0=z[:N], mask=mask)\n                x_samples = self.decode_first_stage(samples.to(self.device))\n                log["samples_outpainting"] = x_samples\n\n        if plot_progressive_rows:\n            with self.ema_scope("Plotting Progressives"):\n                img, progressives = self.progressive_denoising(c,\n                                                               shape=(self.channels, self.image_size, self.image_size),\n                                                               batch_size=N)\n            prog_row = self._get_denoise_row_from_list(progressives, desc="Progressive Generation")\n            log["progressive_row"] = prog_row\n\n        if return_keys:\n            if np.intersect1d(list(log.keys()), return_keys).shape[0] == 0:\n                return log\n            else:\n                return {key: log[key] for key in return_keys}\n        return log\n\n    def configure_optimizers(self):\n        lr = self.learning_rate\n        params = list(self.model.parameters())\n        if self.cond_stage_trainable:\n            print(f"{self.__class__.__name__}: Also optimizing conditioner params!")\n            params = params + list(self.cond_stage_model.parameters())\n        if self.learn_logvar:\n            print(\'Diffusion model optimizing logvar\')\n            params.append(self.logvar)\n        opt = torch.optim.AdamW(params, lr=lr)\n        if self.use_scheduler:\n            assert \'target\' in self.scheduler_config\n            scheduler = instantiate_from_config(self.scheduler_config)\n\n            print("Setting up LambdaLR scheduler...")\n            scheduler = [\n                {\n                    \'scheduler\': LambdaLR(opt, lr_lambda=scheduler.schedule),\n                    \'interval\': \'step\',\n                    \'frequency\': 1\n                }]\n            return [opt], scheduler\n        return opt\n\n    @torch.no_grad()\n    def to_rgb(self, x):\n        x = x.float()\n        if not hasattr(self, "colorize"):\n            self.colorize = torch.randn(3, x.shape[1], 1, 1).to(x)\n        x = nn.functional.conv2d(x, weight=self.colorize)\n        x = 2. * (x - x.min()) / (x.max() - x.min()) - 1.\n        return x\n\n\nclass DiffusionWrapper(pl.LightningModule):\n    def __init__(self, diff_model_config, conditioning_key):\n        super().__init__()\n        self.diffusion_model = instantiate_from_config(diff_model_config)\n        self.conditioning_key = conditioning_key\n        assert self.conditioning_key in [None, \'concat\', \'crossattn\', \'hybrid\', \'adm\']\n\n    def forward(self, x, t, c_concat: list = None, c_crossattn: list = None):\n        if self.conditioning_key is None:\n            out = self.diffusion_model(x, t)\n        elif self.conditioning_key == \'concat\':\n            xc = torch.cat([x] + c_concat, dim=1)\n            out = self.diffusion_model(xc, t)\n        elif self.conditioning_key == \'crossattn\':\n            cc = torch.cat(c_crossattn, 1)\n            out = self.diffusion_model(x, t, context=cc)\n        elif self.conditioning_key == \'hybrid\':\n            xc = torch.cat([x] + c_concat, dim=1)\n            cc = torch.cat(c_crossattn, 1)\n            out = self.diffusion_model(xc, t, context=cc)\n        elif self.conditioning_key == \'adm\':\n            cc = c_crossattn[0]\n            out = self.diffusion_model(x, t, y=cc)\n        else:\n            raise NotImplementedError()\n\n        return out\n\n\nclass Layout2ImgDiffusion(LatentDiffusion):\n    # TODO: move all layout-specific hacks to this class\n    def __init__(self, cond_stage_key, *args, **kwargs):\n        assert cond_stage_key == \'coordinates_bbox\', \'Layout2ImgDiffusion only for cond_stage_key="coordinates_bbox"\'\n        super().__init__(cond_stage_key=cond_stage_key, *args, **kwargs)\n\n    def log_images(self, batch, N=8, *args, **kwargs):\n        logs = super().log_images(batch=batch, N=N, *args, **kwargs)\n\n        key = \'train\' if self.training else \'validation\'\n        dset = self.trainer.datamodule.datasets[key]\n        mapper = dset.conditional_builders[self.cond_stage_key]\n\n        bbox_imgs = []\n        map_fn = lambda catno: dset.get_textual_label(dset.get_category_id(catno))\n        for tknzd_bbox in batch[self.cond_stage_key][:N]:\n            bboximg = mapper.plot(tknzd_bbox.detach().cpu(), map_fn, (256, 256))\n            bbox_imgs.append(bboximg)\n\n        cond_img = torch.stack(bbox_imgs, dim=0)\n        logs[\'bbox_image\'] = cond_img\n        return logs\n',
    'model.ldm.models.diffusion.plms': '"""SAMPLING ONLY."""\n\nimport torch\nimport numpy as np\nfrom tqdm import tqdm\nfrom functools import partial\n\nfrom model.ldm.modules.diffusionmodules.util import make_ddim_sampling_parameters, make_ddim_timesteps, noise_like\n\n\nclass PLMSSampler(object):\n    def __init__(self, model, schedule="linear", **kwargs):\n        super().__init__()\n        self.model = model\n        self.ddpm_num_timesteps = model.num_timesteps\n        self.schedule = schedule\n\n    def register_buffer(self, name, attr):\n        if type(attr) == torch.Tensor:\n            if attr.device != torch.device("cuda"):\n                attr = attr.to(torch.device("cuda"))\n        setattr(self, name, attr)\n\n    def make_schedule(self, ddim_num_steps, ddim_discretize="uniform", ddim_eta=0., verbose=True):\n        if ddim_eta != 0:\n            raise ValueError(\'ddim_eta must be 0 for PLMS\')\n        self.ddim_timesteps = make_ddim_timesteps(ddim_discr_method=ddim_discretize, num_ddim_timesteps=ddim_num_steps,\n                                                  num_ddpm_timesteps=self.ddpm_num_timesteps,verbose=verbose)\n        alphas_cumprod = self.model.alphas_cumprod\n        assert alphas_cumprod.shape[0] == self.ddpm_num_timesteps, \'alphas have to be defined for each timestep\'\n        to_torch = lambda x: x.clone().detach().to(torch.float32).to(self.model.device)\n\n        self.register_buffer(\'betas\', to_torch(self.model.betas))\n        self.register_buffer(\'alphas_cumprod\', to_torch(alphas_cumprod))\n        self.register_buffer(\'alphas_cumprod_prev\', to_torch(self.model.alphas_cumprod_prev))\n\n        # calculations for diffusion q(x_t | x_{t-1}) and others\n        self.register_buffer(\'sqrt_alphas_cumprod\', to_torch(np.sqrt(alphas_cumprod.cpu())))\n        self.register_buffer(\'sqrt_one_minus_alphas_cumprod\', to_torch(np.sqrt(1. - alphas_cumprod.cpu())))\n        self.register_buffer(\'log_one_minus_alphas_cumprod\', to_torch(np.log(1. - alphas_cumprod.cpu())))\n        self.register_buffer(\'sqrt_recip_alphas_cumprod\', to_torch(np.sqrt(1. / alphas_cumprod.cpu())))\n        self.register_buffer(\'sqrt_recipm1_alphas_cumprod\', to_torch(np.sqrt(1. / alphas_cumprod.cpu() - 1)))\n\n        # ddim sampling parameters\n        ddim_sigmas, ddim_alphas, ddim_alphas_prev = make_ddim_sampling_parameters(alphacums=alphas_cumprod.cpu(),\n                                                                                   ddim_timesteps=self.ddim_timesteps,\n                                                                                   eta=ddim_eta,verbose=verbose)\n        self.register_buffer(\'ddim_sigmas\', ddim_sigmas)\n        self.register_buffer(\'ddim_alphas\', ddim_alphas)\n        self.register_buffer(\'ddim_alphas_prev\', ddim_alphas_prev)\n        self.register_buffer(\'ddim_sqrt_one_minus_alphas\', np.sqrt(1. - ddim_alphas))\n        sigmas_for_original_sampling_steps = ddim_eta * torch.sqrt(\n            (1 - self.alphas_cumprod_prev) / (1 - self.alphas_cumprod) * (\n                        1 - self.alphas_cumprod / self.alphas_cumprod_prev))\n        self.register_buffer(\'ddim_sigmas_for_original_num_steps\', sigmas_for_original_sampling_steps)\n\n    @torch.no_grad()\n    def sample(self,\n               S,\n               batch_size,\n               shape,\n               conditioning=None,\n               callback=None,\n               normals_sequence=None,\n               img_callback=None,\n               quantize_x0=False,\n               eta=0.,\n               mask=None,\n               x0=None,\n               temperature=1.,\n               noise_dropout=0.,\n               score_corrector=None,\n               corrector_kwargs=None,\n               verbose=True,\n               x_T=None,\n               log_every_t=100,\n               unconditional_guidance_scale=1.,\n               unconditional_conditioning=None,\n               # this has to come in the same format as the conditioning, # e.g. as encoded tokens, ...\n               **kwargs\n               ):\n        if conditioning is not None:\n            if isinstance(conditioning, dict):\n                cbs = conditioning[list(conditioning.keys())[0]].shape[0]\n                if cbs != batch_size:\n                    print(f"Warning: Got {cbs} conditionings but batch-size is {batch_size}")\n            else:\n                if conditioning.shape[0] != batch_size:\n                    print(f"Warning: Got {conditioning.shape[0]} conditionings but batch-size is {batch_size}")\n\n        self.make_schedule(ddim_num_steps=S, ddim_eta=eta, verbose=verbose)\n        # sampling\n        C, H, W = shape\n        size = (batch_size, C, H, W)\n        print(f\'Data shape for PLMS sampling is {size}\')\n\n        samples, intermediates = self.plms_sampling(conditioning, size,\n                                                    callback=callback,\n                                                    img_callback=img_callback,\n                                                    quantize_denoised=quantize_x0,\n                                                    mask=mask, x0=x0,\n                                                    ddim_use_original_steps=False,\n                                                    noise_dropout=noise_dropout,\n                                                    temperature=temperature,\n                                                    score_corrector=score_corrector,\n                                                    corrector_kwargs=corrector_kwargs,\n                                                    x_T=x_T,\n                                                    log_every_t=log_every_t,\n                                                    unconditional_guidance_scale=unconditional_guidance_scale,\n                                                    unconditional_conditioning=unconditional_conditioning,\n                                                    )\n        return samples, intermediates\n\n    @torch.no_grad()\n    def plms_sampling(self, cond, shape,\n                      x_T=None, ddim_use_original_steps=False,\n                      callback=None, timesteps=None, quantize_denoised=False,\n                      mask=None, x0=None, img_callback=None, log_every_t=100,\n                      temperature=1., noise_dropout=0., score_corrector=None, corrector_kwargs=None,\n                      unconditional_guidance_scale=1., unconditional_conditioning=None,):\n        device = self.model.betas.device\n        b = shape[0]\n        if x_T is None:\n            img = torch.randn(shape, device=device)\n        else:\n            img = x_T\n\n        if timesteps is None:\n            timesteps = self.ddpm_num_timesteps if ddim_use_original_steps else self.ddim_timesteps\n        elif timesteps is not None and not ddim_use_original_steps:\n            subset_end = int(min(timesteps / self.ddim_timesteps.shape[0], 1) * self.ddim_timesteps.shape[0]) - 1\n            timesteps = self.ddim_timesteps[:subset_end]\n\n        intermediates = {\'x_inter\': [img], \'pred_x0\': [img]}\n        time_range = list(reversed(range(0,timesteps))) if ddim_use_original_steps else np.flip(timesteps)\n        total_steps = timesteps if ddim_use_original_steps else timesteps.shape[0]\n        print(f"Running PLMS Sampling with {total_steps} timesteps")\n\n        iterator = tqdm(time_range, desc=\'PLMS Sampler\', total=total_steps)\n        old_eps = []\n\n        for i, step in enumerate(iterator):\n            index = total_steps - i - 1\n            ts = torch.full((b,), step, device=device, dtype=torch.long)\n            ts_next = torch.full((b,), time_range[min(i + 1, len(time_range) - 1)], device=device, dtype=torch.long)\n\n            if mask is not None:\n                assert x0 is not None\n                img_orig = self.model.q_sample(x0, ts)  # TODO: deterministic forward pass?\n                img = img_orig * mask + (1. - mask) * img\n\n            outs = self.p_sample_plms(img, cond, ts, index=index, use_original_steps=ddim_use_original_steps,\n                                      quantize_denoised=quantize_denoised, temperature=temperature,\n                                      noise_dropout=noise_dropout, score_corrector=score_corrector,\n                                      corrector_kwargs=corrector_kwargs,\n                                      unconditional_guidance_scale=unconditional_guidance_scale,\n                                      unconditional_conditioning=unconditional_conditioning,\n                                      old_eps=old_eps, t_next=ts_next)\n            img, pred_x0, e_t = outs\n            old_eps.append(e_t)\n            if len(old_eps) >= 4:\n                old_eps.pop(0)\n            if callback: callback(i)\n            if img_callback: img_callback(pred_x0, i)\n\n            if index % log_every_t == 0 or index == total_steps - 1:\n                intermediates[\'x_inter\'].append(img)\n                intermediates[\'pred_x0\'].append(pred_x0)\n\n        return img, intermediates\n\n    @torch.no_grad()\n    def p_sample_plms(self, x, c, t, index, repeat_noise=False, use_original_steps=False, quantize_denoised=False,\n                      temperature=1., noise_dropout=0., score_corrector=None, corrector_kwargs=None,\n                      unconditional_guidance_scale=1., unconditional_conditioning=None, old_eps=None, t_next=None):\n        b, *_, device = *x.shape, x.device\n\n        def get_model_output(x, t):\n            if unconditional_conditioning is None or unconditional_guidance_scale == 1.:\n                e_t = self.model.apply_model(x, t, c)\n            else:\n                x_in = torch.cat([x] * 2)\n                t_in = torch.cat([t] * 2)\n                c_in = torch.cat([unconditional_conditioning, c])\n                e_t_uncond, e_t = self.model.apply_model(x_in, t_in, c_in).chunk(2)\n                e_t = e_t_uncond + unconditional_guidance_scale * (e_t - e_t_uncond)\n\n            if score_corrector is not None:\n                assert self.model.parameterization == "eps"\n                e_t = score_corrector.modify_score(self.model, e_t, x, t, c, **corrector_kwargs)\n\n            return e_t\n\n        alphas = self.model.alphas_cumprod if use_original_steps else self.ddim_alphas\n        alphas_prev = self.model.alphas_cumprod_prev if use_original_steps else self.ddim_alphas_prev\n        sqrt_one_minus_alphas = self.model.sqrt_one_minus_alphas_cumprod if use_original_steps else self.ddim_sqrt_one_minus_alphas\n        sigmas = self.model.ddim_sigmas_for_original_num_steps if use_original_steps else self.ddim_sigmas\n\n        def get_x_prev_and_pred_x0(e_t, index):\n            # select parameters corresponding to the currently considered timestep\n            a_t = torch.full((b, 1, 1, 1), alphas[index], device=device)\n            a_prev = torch.full((b, 1, 1, 1), alphas_prev[index], device=device)\n            sigma_t = torch.full((b, 1, 1, 1), sigmas[index], device=device)\n            sqrt_one_minus_at = torch.full((b, 1, 1, 1), sqrt_one_minus_alphas[index],device=device)\n\n            # current prediction for x_0\n            pred_x0 = (x - sqrt_one_minus_at * e_t) / a_t.sqrt()\n            if quantize_denoised:\n                pred_x0, _, *_ = self.model.first_stage_model.quantize(pred_x0)\n            # direction pointing to x_t\n            dir_xt = (1. - a_prev - sigma_t**2).sqrt() * e_t\n            noise = sigma_t * noise_like(x.shape, device, repeat_noise) * temperature\n            if noise_dropout > 0.:\n                noise = torch.nn.functional.dropout(noise, p=noise_dropout)\n            x_prev = a_prev.sqrt() * pred_x0 + dir_xt + noise\n            return x_prev, pred_x0\n\n        e_t = get_model_output(x, t)\n        if len(old_eps) == 0:\n            # Pseudo Improved Euler (2nd order)\n            x_prev, pred_x0 = get_x_prev_and_pred_x0(e_t, index)\n            e_t_next = get_model_output(x_prev, t_next)\n            e_t_prime = (e_t + e_t_next) / 2\n        elif len(old_eps) == 1:\n            # 2nd order Pseudo Linear Multistep (Adams-Bashforth)\n            e_t_prime = (3 * e_t - old_eps[-1]) / 2\n        elif len(old_eps) == 2:\n            # 3nd order Pseudo Linear Multistep (Adams-Bashforth)\n            e_t_prime = (23 * e_t - 16 * old_eps[-1] + 5 * old_eps[-2]) / 12\n        elif len(old_eps) >= 3:\n            # 4nd order Pseudo Linear Multistep (Adams-Bashforth)\n            e_t_prime = (55 * e_t - 59 * old_eps[-1] + 37 * old_eps[-2] - 9 * old_eps[-3]) / 24\n\n        x_prev, pred_x0 = get_x_prev_and_pred_x0(e_t_prime, index)\n\n        return x_prev, pred_x0, e_t\n',
    'model.ldm.modules': '',
    'model.ldm.modules.attention': 'from inspect import isfunction\nimport math\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn, einsum\nfrom einops import rearrange, repeat\n\nfrom model.ldm.modules.diffusionmodules.util import checkpoint\n\n\ndef exists(val):\n    return val is not None\n\n\ndef uniq(arr):\n    return{el: True for el in arr}.keys()\n\n\ndef default(val, d):\n    if exists(val):\n        return val\n    return d() if isfunction(d) else d\n\n\ndef max_neg_value(t):\n    return -torch.finfo(t.dtype).max\n\n\ndef init_(tensor):\n    dim = tensor.shape[-1]\n    std = 1 / math.sqrt(dim)\n    tensor.uniform_(-std, std)\n    return tensor\n\n\n# feedforward\nclass GEGLU(nn.Module):\n    def __init__(self, dim_in, dim_out):\n        super().__init__()\n        self.proj = nn.Linear(dim_in, dim_out * 2)\n\n    def forward(self, x):\n        x, gate = self.proj(x).chunk(2, dim=-1)\n        return x * F.gelu(gate)\n\n\nclass FeedForward(nn.Module):\n    def __init__(self, dim, dim_out=None, mult=4, glu=False, dropout=0.):\n        super().__init__()\n        inner_dim = int(dim * mult)\n        dim_out = default(dim_out, dim)\n        project_in = nn.Sequential(\n            nn.Linear(dim, inner_dim),\n            nn.GELU()\n        ) if not glu else GEGLU(dim, inner_dim)\n\n        self.net = nn.Sequential(\n            project_in,\n            nn.Dropout(dropout),\n            nn.Linear(inner_dim, dim_out)\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\n\ndef zero_module(module):\n    """\n    Zero out the parameters of a module and return it.\n    """\n    for p in module.parameters():\n        p.detach().zero_()\n    return module\n\n\ndef Normalize(in_channels):\n    return torch.nn.GroupNorm(num_groups=32, num_channels=in_channels, eps=1e-6, affine=True)\n\n\nclass LinearAttention(nn.Module):\n    def __init__(self, dim, heads=4, dim_head=32):\n        super().__init__()\n        self.heads = heads\n        hidden_dim = dim_head * heads\n        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)\n        self.to_out = nn.Conv2d(hidden_dim, dim, 1)\n\n    def forward(self, x):\n        b, c, h, w = x.shape\n        qkv = self.to_qkv(x)\n        q, k, v = rearrange(qkv, \'b (qkv heads c) h w -> qkv b heads c (h w)\', heads = self.heads, qkv=3)\n        k = k.softmax(dim=-1)  \n        context = torch.einsum(\'bhdn,bhen->bhde\', k, v)\n        out = torch.einsum(\'bhde,bhdn->bhen\', context, q)\n        out = rearrange(out, \'b heads c (h w) -> b (heads c) h w\', heads=self.heads, h=h, w=w)\n        return self.to_out(out)\n\n\nclass SpatialSelfAttention(nn.Module):\n    def __init__(self, in_channels):\n        super().__init__()\n        self.in_channels = in_channels\n\n        self.norm = Normalize(in_channels)\n        self.q = torch.nn.Conv2d(in_channels,\n                                 in_channels,\n                                 kernel_size=1,\n                                 stride=1,\n                                 padding=0)\n        self.k = torch.nn.Conv2d(in_channels,\n                                 in_channels,\n                                 kernel_size=1,\n                                 stride=1,\n                                 padding=0)\n        self.v = torch.nn.Conv2d(in_channels,\n                                 in_channels,\n                                 kernel_size=1,\n                                 stride=1,\n                                 padding=0)\n        self.proj_out = torch.nn.Conv2d(in_channels,\n                                        in_channels,\n                                        kernel_size=1,\n                                        stride=1,\n                                        padding=0)\n\n    def forward(self, x):\n        h_ = x\n        h_ = self.norm(h_)\n        q = self.q(h_)\n        k = self.k(h_)\n        v = self.v(h_)\n\n        # compute attention\n        b,c,h,w = q.shape\n        q = rearrange(q, \'b c h w -> b (h w) c\')\n        k = rearrange(k, \'b c h w -> b c (h w)\')\n        w_ = torch.einsum(\'bij,bjk->bik\', q, k)\n\n        w_ = w_ * (int(c)**(-0.5))\n        w_ = torch.nn.functional.softmax(w_, dim=2)\n\n        # attend to values\n        v = rearrange(v, \'b c h w -> b c (h w)\')\n        w_ = rearrange(w_, \'b i j -> b j i\')\n        h_ = torch.einsum(\'bij,bjk->bik\', v, w_)\n        h_ = rearrange(h_, \'b c (h w) -> b c h w\', h=h)\n        h_ = self.proj_out(h_)\n\n        return x+h_\n\n\nclass CrossAttention(nn.Module):\n    def __init__(self, query_dim, context_dim=None, heads=8, dim_head=64, dropout=0.):\n        super().__init__()\n        inner_dim = dim_head * heads\n        context_dim = default(context_dim, query_dim)\n\n        self.scale = dim_head ** -0.5\n        self.heads = heads\n\n        self.to_q = nn.Linear(query_dim, inner_dim, bias=False)\n        self.to_k = nn.Linear(context_dim, inner_dim, bias=False)\n        self.to_v = nn.Linear(context_dim, inner_dim, bias=False)\n\n        self.to_out = nn.Sequential(\n            nn.Linear(inner_dim, query_dim),\n            nn.Dropout(dropout)\n        )\n\n    def forward(self, x, context=None, mask=None):\n        h = self.heads\n\n        q = self.to_q(x)\n        context = default(context, x)\n        k = self.to_k(context)\n        v = self.to_v(context)\n\n        q, k, v = map(lambda t: rearrange(t, \'b n (h d) -> (b h) n d\', h=h), (q, k, v))\n\n        sim = einsum(\'b i d, b j d -> b i j\', q, k) * self.scale\n\n        if exists(mask):\n            mask = rearrange(mask, \'b ... -> b (...)\')\n            max_neg_value = -torch.finfo(sim.dtype).max\n            mask = repeat(mask, \'b j -> (b h) () j\', h=h)\n            sim.masked_fill_(~mask, max_neg_value)\n\n        # attention, what we cannot get enough of\n        attn = sim.softmax(dim=-1)\n\n        out = einsum(\'b i j, b j d -> b i d\', attn, v)\n        out = rearrange(out, \'(b h) n d -> b n (h d)\', h=h)\n        return self.to_out(out)\n\n\nclass BasicTransformerBlock(nn.Module):\n    def __init__(self, dim, n_heads, d_head, dropout=0., context_dim=None, gated_ff=True, checkpoint=True):\n        super().__init__()\n        self.attn1 = CrossAttention(query_dim=dim, heads=n_heads, dim_head=d_head, dropout=dropout)  # is a self-attention\n        self.ff = FeedForward(dim, dropout=dropout, glu=gated_ff)\n        self.attn2 = CrossAttention(query_dim=dim, context_dim=context_dim,\n                                    heads=n_heads, dim_head=d_head, dropout=dropout)  # is self-attn if context is none\n        self.norm1 = nn.LayerNorm(dim)\n        self.norm2 = nn.LayerNorm(dim)\n        self.norm3 = nn.LayerNorm(dim)\n        self.checkpoint = checkpoint\n\n    def forward(self, x, context=None):\n        return checkpoint(self._forward, (x, context), self.parameters(), self.checkpoint)\n\n    def _forward(self, x, context=None):\n        x = self.attn1(self.norm1(x)) + x\n        x = self.attn2(self.norm2(x), context=context) + x\n        x = self.ff(self.norm3(x)) + x\n        return x\n\n\nclass SpatialTransformer(nn.Module):\n    """\n    Transformer block for image-like data.\n    First, project the input (aka embedding)\n    and reshape to b, t, d.\n    Then apply standard transformer action.\n    Finally, reshape to image\n    """\n    def __init__(self, in_channels, n_heads, d_head,\n                 depth=1, dropout=0., context_dim=None):\n        super().__init__()\n        self.in_channels = in_channels\n        inner_dim = n_heads * d_head\n        self.norm = Normalize(in_channels)\n\n        self.proj_in = nn.Conv2d(in_channels,\n                                 inner_dim,\n                                 kernel_size=1,\n                                 stride=1,\n                                 padding=0)\n\n        self.transformer_blocks = nn.ModuleList(\n            [BasicTransformerBlock(inner_dim, n_heads, d_head, dropout=dropout, context_dim=context_dim)\n                for d in range(depth)]\n        )\n\n        self.proj_out = zero_module(nn.Conv2d(inner_dim,\n                                              in_channels,\n                                              kernel_size=1,\n                                              stride=1,\n                                              padding=0))\n\n    def forward(self, x, context=None):\n        # note: if no context is given, cross-attention defaults to self-attention\n        b, c, h, w = x.shape\n        x_in = x\n        x = self.norm(x)\n        x = self.proj_in(x)\n        x = rearrange(x, \'b c h w -> b (h w) c\')\n        for block in self.transformer_blocks:\n            x = block(x, context=context)\n        x = rearrange(x, \'b (h w) c -> b c h w\', h=h, w=w)\n        x = self.proj_out(x)\n        return x + x_in',
    'model.ldm.modules.diffusionmodules': '',
    'model.ldm.modules.diffusionmodules.model': '# pytorch_diffusion + derived encoder decoder\nimport math\nimport torch\nimport torch.nn as nn\nimport numpy as np\nfrom einops import rearrange\n\nfrom model.ldm.util import instantiate_from_config\nfrom model.ldm.modules.attention import LinearAttention\n\n\ndef get_timestep_embedding(timesteps, embedding_dim):\n    """\n    This matches the implementation in Denoising Diffusion Probabilistic Models:\n    From Fairseq.\n    Build sinusoidal embeddings.\n    This matches the implementation in tensor2tensor, but differs slightly\n    from the description in Section 3.5 of "Attention Is All You Need".\n    """\n    assert len(timesteps.shape) == 1\n\n    half_dim = embedding_dim // 2\n    emb = math.log(10000) / (half_dim - 1)\n    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32) * -emb)\n    emb = emb.to(device=timesteps.device)\n    emb = timesteps.float()[:, None] * emb[None, :]\n    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n    if embedding_dim % 2 == 1:  # zero pad\n        emb = torch.nn.functional.pad(emb, (0,1,0,0))\n    return emb\n\n\ndef nonlinearity(x):\n    # swish\n    return x*torch.sigmoid(x)\n\n\ndef Normalize(in_channels, num_groups=32):\n    return torch.nn.GroupNorm(num_groups=num_groups, num_channels=in_channels, eps=1e-6, affine=True)\n\n\nclass Upsample(nn.Module):\n    def __init__(self, in_channels, with_conv):\n        super().__init__()\n        self.with_conv = with_conv\n        if self.with_conv:\n            self.conv = torch.nn.Conv2d(in_channels,\n                                        in_channels,\n                                        kernel_size=3,\n                                        stride=1,\n                                        padding=1)\n\n    def forward(self, x):\n        x = torch.nn.functional.interpolate(x, scale_factor=2.0, mode="nearest")\n        if self.with_conv:\n            x = self.conv(x)\n        return x\n\n\nclass Downsample(nn.Module):\n    def __init__(self, in_channels, with_conv):\n        super().__init__()\n        self.with_conv = with_conv\n        if self.with_conv:\n            # no asymmetric padding in torch conv, must do it ourselves\n            self.conv = torch.nn.Conv2d(in_channels,\n                                        in_channels,\n                                        kernel_size=3,\n                                        stride=2,\n                                        padding=0)\n\n    def forward(self, x):\n        if self.with_conv:\n            pad = (0,1,0,1)\n            x = torch.nn.functional.pad(x, pad, mode="constant", value=0)\n            x = self.conv(x)\n        else:\n            x = torch.nn.functional.avg_pool2d(x, kernel_size=2, stride=2)\n        return x\n\n\nclass ResnetBlock(nn.Module):\n    def __init__(self, *, in_channels, out_channels=None, conv_shortcut=False,\n                 dropout, temb_channels=512):\n        super().__init__()\n        self.in_channels = in_channels\n        out_channels = in_channels if out_channels is None else out_channels\n        self.out_channels = out_channels\n        self.use_conv_shortcut = conv_shortcut\n\n        self.norm1 = Normalize(in_channels)\n        self.conv1 = torch.nn.Conv2d(in_channels,\n                                     out_channels,\n                                     kernel_size=3,\n                                     stride=1,\n                                     padding=1)\n        if temb_channels > 0:\n            self.temb_proj = torch.nn.Linear(temb_channels,\n                                             out_channels)\n        self.norm2 = Normalize(out_channels)\n        self.dropout = torch.nn.Dropout(dropout)\n        self.conv2 = torch.nn.Conv2d(out_channels,\n                                     out_channels,\n                                     kernel_size=3,\n                                     stride=1,\n                                     padding=1)\n        if self.in_channels != self.out_channels:\n            if self.use_conv_shortcut:\n                self.conv_shortcut = torch.nn.Conv2d(in_channels,\n                                                     out_channels,\n                                                     kernel_size=3,\n                                                     stride=1,\n                                                     padding=1)\n            else:\n                self.nin_shortcut = torch.nn.Conv2d(in_channels,\n                                                    out_channels,\n                                                    kernel_size=1,\n                                                    stride=1,\n                                                    padding=0)\n\n    def forward(self, x, temb):\n        h = x\n        h = self.norm1(h)\n        h = nonlinearity(h)\n        h = self.conv1(h)\n\n        if temb is not None:\n            h = h + self.temb_proj(nonlinearity(temb))[:,:,None,None]\n\n        h = self.norm2(h)\n        h = nonlinearity(h)\n        h = self.dropout(h)\n        h = self.conv2(h)\n\n        if self.in_channels != self.out_channels:\n            if self.use_conv_shortcut:\n                x = self.conv_shortcut(x)\n            else:\n                x = self.nin_shortcut(x)\n\n        return x+h\n\n\nclass LinAttnBlock(LinearAttention):\n    """to match AttnBlock usage"""\n    def __init__(self, in_channels):\n        super().__init__(dim=in_channels, heads=1, dim_head=in_channels)\n\n\nclass AttnBlock(nn.Module):\n    def __init__(self, in_channels):\n        super().__init__()\n        self.in_channels = in_channels\n\n        self.norm = Normalize(in_channels)\n        self.q = torch.nn.Conv2d(in_channels,\n                                 in_channels,\n                                 kernel_size=1,\n                                 stride=1,\n                                 padding=0)\n        self.k = torch.nn.Conv2d(in_channels,\n                                 in_channels,\n                                 kernel_size=1,\n                                 stride=1,\n                                 padding=0)\n        self.v = torch.nn.Conv2d(in_channels,\n                                 in_channels,\n                                 kernel_size=1,\n                                 stride=1,\n                                 padding=0)\n        self.proj_out = torch.nn.Conv2d(in_channels,\n                                        in_channels,\n                                        kernel_size=1,\n                                        stride=1,\n                                        padding=0)\n\n\n    def forward(self, x):\n        h_ = x\n        h_ = self.norm(h_)\n        q = self.q(h_)\n        k = self.k(h_)\n        v = self.v(h_)\n\n        # compute attention\n        b,c,h,w = q.shape\n        q = q.reshape(b,c,h*w)\n        q = q.permute(0,2,1)   # b,hw,c\n        k = k.reshape(b,c,h*w) # b,c,hw\n        w_ = torch.bmm(q,k)     # b,hw,hw    w[b,i,j]=sum_c q[b,i,c]k[b,c,j]\n        w_ = w_ * (int(c)**(-0.5))\n        w_ = torch.nn.functional.softmax(w_, dim=2)\n\n        # attend to values\n        v = v.reshape(b,c,h*w)\n        w_ = w_.permute(0,2,1)   # b,hw,hw (first hw of k, second of q)\n        h_ = torch.bmm(v,w_)     # b, c,hw (hw of q) h_[b,c,j] = sum_i v[b,c,i] w_[b,i,j]\n        h_ = h_.reshape(b,c,h,w)\n\n        h_ = self.proj_out(h_)\n\n        return x+h_\n\n\ndef make_attn(in_channels, attn_type="vanilla"):\n    assert attn_type in ["vanilla", "linear", "none"], f\'attn_type {attn_type} unknown\'\n    print(f"making attention of type \'{attn_type}\' with {in_channels} in_channels")\n    if attn_type == "vanilla":\n        return AttnBlock(in_channels)\n    elif attn_type == "none":\n        return nn.Identity(in_channels)\n    else:\n        return LinAttnBlock(in_channels)\n\n\nclass Model(nn.Module):\n    def __init__(self, *, ch, out_ch, ch_mult=(1,2,4,8), num_res_blocks,\n                 attn_resolutions, dropout=0.0, resamp_with_conv=True, in_channels,\n                 resolution, use_timestep=True, use_linear_attn=False, attn_type="vanilla"):\n        super().__init__()\n        if use_linear_attn: attn_type = "linear"\n        self.ch = ch\n        self.temb_ch = self.ch*4\n        self.num_resolutions = len(ch_mult)\n        self.num_res_blocks = num_res_blocks\n        self.resolution = resolution\n        self.in_channels = in_channels\n\n        self.use_timestep = use_timestep\n        if self.use_timestep:\n            # timestep embedding\n            self.temb = nn.Module()\n            self.temb.dense = nn.ModuleList([\n                torch.nn.Linear(self.ch,\n                                self.temb_ch),\n                torch.nn.Linear(self.temb_ch,\n                                self.temb_ch),\n            ])\n\n        # downsampling\n        self.conv_in = torch.nn.Conv2d(in_channels,\n                                       self.ch,\n                                       kernel_size=3,\n                                       stride=1,\n                                       padding=1)\n\n        curr_res = resolution\n        in_ch_mult = (1,)+tuple(ch_mult)\n        self.down = nn.ModuleList()\n        for i_level in range(self.num_resolutions):\n            block = nn.ModuleList()\n            attn = nn.ModuleList()\n            block_in = ch*in_ch_mult[i_level]\n            block_out = ch*ch_mult[i_level]\n            for i_block in range(self.num_res_blocks):\n                block.append(ResnetBlock(in_channels=block_in,\n                                         out_channels=block_out,\n                                         temb_channels=self.temb_ch,\n                                         dropout=dropout))\n                block_in = block_out\n                if curr_res in attn_resolutions:\n                    attn.append(make_attn(block_in, attn_type=attn_type))\n            down = nn.Module()\n            down.block = block\n            down.attn = attn\n            if i_level != self.num_resolutions-1:\n                down.downsample = Downsample(block_in, resamp_with_conv)\n                curr_res = curr_res // 2\n            self.down.append(down)\n\n        # middle\n        self.mid = nn.Module()\n        self.mid.block_1 = ResnetBlock(in_channels=block_in,\n                                       out_channels=block_in,\n                                       temb_channels=self.temb_ch,\n                                       dropout=dropout)\n        self.mid.attn_1 = make_attn(block_in, attn_type=attn_type)\n        self.mid.block_2 = ResnetBlock(in_channels=block_in,\n                                       out_channels=block_in,\n                                       temb_channels=self.temb_ch,\n                                       dropout=dropout)\n\n        # upsampling\n        self.up = nn.ModuleList()\n        for i_level in reversed(range(self.num_resolutions)):\n            block = nn.ModuleList()\n            attn = nn.ModuleList()\n            block_out = ch*ch_mult[i_level]\n            skip_in = ch*ch_mult[i_level]\n            for i_block in range(self.num_res_blocks+1):\n                if i_block == self.num_res_blocks:\n                    skip_in = ch*in_ch_mult[i_level]\n                block.append(ResnetBlock(in_channels=block_in+skip_in,\n                                         out_channels=block_out,\n                                         temb_channels=self.temb_ch,\n                                         dropout=dropout))\n                block_in = block_out\n                if curr_res in attn_resolutions:\n                    attn.append(make_attn(block_in, attn_type=attn_type))\n            up = nn.Module()\n            up.block = block\n            up.attn = attn\n            if i_level != 0:\n                up.upsample = Upsample(block_in, resamp_with_conv)\n                curr_res = curr_res * 2\n            self.up.insert(0, up) # prepend to get consistent order\n\n        # end\n        self.norm_out = Normalize(block_in)\n        self.conv_out = torch.nn.Conv2d(block_in,\n                                        out_ch,\n                                        kernel_size=3,\n                                        stride=1,\n                                        padding=1)\n\n    def forward(self, x, t=None, context=None):\n        #assert x.shape[2] == x.shape[3] == self.resolution\n        if context is not None:\n            # assume aligned context, cat along channel axis\n            x = torch.cat((x, context), dim=1)\n        if self.use_timestep:\n            # timestep embedding\n            assert t is not None\n            temb = get_timestep_embedding(t, self.ch)\n            temb = self.temb.dense[0](temb)\n            temb = nonlinearity(temb)\n            temb = self.temb.dense[1](temb)\n        else:\n            temb = None\n\n        # downsampling\n        hs = [self.conv_in(x)]\n        for i_level in range(self.num_resolutions):\n            for i_block in range(self.num_res_blocks):\n                h = self.down[i_level].block[i_block](hs[-1], temb)\n                if len(self.down[i_level].attn) > 0:\n                    h = self.down[i_level].attn[i_block](h)\n                hs.append(h)\n            if i_level != self.num_resolutions-1:\n                hs.append(self.down[i_level].downsample(hs[-1]))\n\n        # middle\n        h = hs[-1]\n        h = self.mid.block_1(h, temb)\n        h = self.mid.attn_1(h)\n        h = self.mid.block_2(h, temb)\n\n        # upsampling\n        for i_level in reversed(range(self.num_resolutions)):\n            for i_block in range(self.num_res_blocks+1):\n                h = self.up[i_level].block[i_block](\n                    torch.cat([h, hs.pop()], dim=1), temb)\n                if len(self.up[i_level].attn) > 0:\n                    h = self.up[i_level].attn[i_block](h)\n            if i_level != 0:\n                h = self.up[i_level].upsample(h)\n\n        # end\n        h = self.norm_out(h)\n        h = nonlinearity(h)\n        h = self.conv_out(h)\n        return h\n\n    def get_last_layer(self):\n        return self.conv_out.weight\n\n\nclass Encoder(nn.Module):\n    def __init__(self, *, ch, out_ch, ch_mult=(1,2,4,8), num_res_blocks,\n                 attn_resolutions, dropout=0.0, resamp_with_conv=True, in_channels,\n                 resolution, z_channels, double_z=True, use_linear_attn=False, attn_type="vanilla",\n                 **ignore_kwargs):\n        super().__init__()\n        if use_linear_attn: attn_type = "linear"\n        self.ch = ch\n        self.temb_ch = 0\n        self.num_resolutions = len(ch_mult)\n        self.num_res_blocks = num_res_blocks\n        self.resolution = resolution\n        self.in_channels = in_channels\n\n        # downsampling\n        self.conv_in = torch.nn.Conv2d(in_channels,\n                                       self.ch,\n                                       kernel_size=3,\n                                       stride=1,\n                                       padding=1)\n\n        curr_res = resolution\n        in_ch_mult = (1,)+tuple(ch_mult)\n        self.in_ch_mult = in_ch_mult\n        self.down = nn.ModuleList()\n        for i_level in range(self.num_resolutions):\n            block = nn.ModuleList()\n            attn = nn.ModuleList()\n            block_in = ch*in_ch_mult[i_level]\n            block_out = ch*ch_mult[i_level]\n            for i_block in range(self.num_res_blocks):\n                block.append(ResnetBlock(in_channels=block_in,\n                                         out_channels=block_out,\n                                         temb_channels=self.temb_ch,\n                                         dropout=dropout))\n                block_in = block_out\n                if curr_res in attn_resolutions:\n                    attn.append(make_attn(block_in, attn_type=attn_type))\n            down = nn.Module()\n            down.block = block\n            down.attn = attn\n            if i_level != self.num_resolutions-1:\n                down.downsample = Downsample(block_in, resamp_with_conv)\n                curr_res = curr_res // 2\n            self.down.append(down)\n\n        # middle\n        self.mid = nn.Module()\n        self.mid.block_1 = ResnetBlock(in_channels=block_in,\n                                       out_channels=block_in,\n                                       temb_channels=self.temb_ch,\n                                       dropout=dropout)\n        self.mid.attn_1 = make_attn(block_in, attn_type=attn_type)\n        self.mid.block_2 = ResnetBlock(in_channels=block_in,\n                                       out_channels=block_in,\n                                       temb_channels=self.temb_ch,\n                                       dropout=dropout)\n\n        # end\n        self.norm_out = Normalize(block_in)\n        self.conv_out = torch.nn.Conv2d(block_in,\n                                        2*z_channels if double_z else z_channels,\n                                        kernel_size=3,\n                                        stride=1,\n                                        padding=1)\n\n    def forward(self, x):\n        # timestep embedding\n        temb = None\n\n        # downsampling\n        hs = [self.conv_in(x)]\n        for i_level in range(self.num_resolutions):\n            for i_block in range(self.num_res_blocks):\n                h = self.down[i_level].block[i_block](hs[-1], temb)\n                if len(self.down[i_level].attn) > 0:\n                    h = self.down[i_level].attn[i_block](h)\n                hs.append(h)\n            if i_level != self.num_resolutions-1:\n                hs.append(self.down[i_level].downsample(hs[-1]))\n\n        # middle\n        h = hs[-1]\n        h = self.mid.block_1(h, temb)\n        h = self.mid.attn_1(h)\n        h = self.mid.block_2(h, temb)\n\n        # end\n        h = self.norm_out(h)\n        h = nonlinearity(h)\n        h = self.conv_out(h)\n        return h\n\n\nclass Decoder(nn.Module):\n    def __init__(self, *, ch, out_ch, ch_mult=(1,2,4,8), num_res_blocks,\n                 attn_resolutions, dropout=0.0, resamp_with_conv=True, in_channels,\n                 resolution, z_channels, give_pre_end=False, tanh_out=False, use_linear_attn=False,\n                 attn_type="vanilla", **ignorekwargs):\n        super().__init__()\n        if use_linear_attn: attn_type = "linear"\n        self.ch = ch\n        self.temb_ch = 0\n        self.num_resolutions = len(ch_mult)\n        self.num_res_blocks = num_res_blocks\n        self.resolution = resolution\n        self.in_channels = in_channels\n        self.give_pre_end = give_pre_end\n        self.tanh_out = tanh_out\n\n        # compute in_ch_mult, block_in and curr_res at lowest res\n        in_ch_mult = (1,)+tuple(ch_mult)\n        block_in = ch*ch_mult[self.num_resolutions-1]\n        curr_res = resolution // 2**(self.num_resolutions-1)\n        self.z_shape = (1,z_channels,curr_res,curr_res)\n        print("Working with z of shape {} = {} dimensions.".format(\n            self.z_shape, np.prod(self.z_shape)))\n\n        # z to block_in\n        self.conv_in = torch.nn.Conv2d(z_channels,\n                                       block_in,\n                                       kernel_size=3,\n                                       stride=1,\n                                       padding=1)\n\n        # middle\n        self.mid = nn.Module()\n        self.mid.block_1 = ResnetBlock(in_channels=block_in,\n                                       out_channels=block_in,\n                                       temb_channels=self.temb_ch,\n                                       dropout=dropout)\n        self.mid.attn_1 = make_attn(block_in, attn_type=attn_type)\n        self.mid.block_2 = ResnetBlock(in_channels=block_in,\n                                       out_channels=block_in,\n                                       temb_channels=self.temb_ch,\n                                       dropout=dropout)\n\n        # upsampling\n        self.up = nn.ModuleList()\n        for i_level in reversed(range(self.num_resolutions)):\n            block = nn.ModuleList()\n            attn = nn.ModuleList()\n            block_out = ch*ch_mult[i_level]\n            for i_block in range(self.num_res_blocks+1):\n                block.append(ResnetBlock(in_channels=block_in,\n                                         out_channels=block_out,\n                                         temb_channels=self.temb_ch,\n                                         dropout=dropout))\n                block_in = block_out\n                if curr_res in attn_resolutions:\n                    attn.append(make_attn(block_in, attn_type=attn_type))\n            up = nn.Module()\n            up.block = block\n            up.attn = attn\n            if i_level != 0:\n                up.upsample = Upsample(block_in, resamp_with_conv)\n                curr_res = curr_res * 2\n            self.up.insert(0, up) # prepend to get consistent order\n\n        # end\n        self.norm_out = Normalize(block_in)\n        self.conv_out = torch.nn.Conv2d(block_in,\n                                        out_ch,\n                                        kernel_size=3,\n                                        stride=1,\n                                        padding=1)\n\n    def forward(self, z):\n        #assert z.shape[1:] == self.z_shape[1:]\n        self.last_z_shape = z.shape\n\n        # timestep embedding\n        temb = None\n\n        # z to block_in\n        h = self.conv_in(z)\n\n        # middle\n        h = self.mid.block_1(h, temb)\n        h = self.mid.attn_1(h)\n        h = self.mid.block_2(h, temb)\n\n        # upsampling\n        for i_level in reversed(range(self.num_resolutions)):\n            for i_block in range(self.num_res_blocks+1):\n                h = self.up[i_level].block[i_block](h, temb)\n                if len(self.up[i_level].attn) > 0:\n                    h = self.up[i_level].attn[i_block](h)\n            if i_level != 0:\n                h = self.up[i_level].upsample(h)\n\n        # end\n        if self.give_pre_end:\n            return h\n\n        h = self.norm_out(h)\n        h = nonlinearity(h)\n        h = self.conv_out(h)\n        if self.tanh_out:\n            h = torch.tanh(h)\n        return h\n\n\nclass SimpleDecoder(nn.Module):\n    def __init__(self, in_channels, out_channels, *args, **kwargs):\n        super().__init__()\n        self.model = nn.ModuleList([nn.Conv2d(in_channels, in_channels, 1),\n                                     ResnetBlock(in_channels=in_channels,\n                                                 out_channels=2 * in_channels,\n                                                 temb_channels=0, dropout=0.0),\n                                     ResnetBlock(in_channels=2 * in_channels,\n                                                out_channels=4 * in_channels,\n                                                temb_channels=0, dropout=0.0),\n                                     ResnetBlock(in_channels=4 * in_channels,\n                                                out_channels=2 * in_channels,\n                                                temb_channels=0, dropout=0.0),\n                                     nn.Conv2d(2*in_channels, in_channels, 1),\n                                     Upsample(in_channels, with_conv=True)])\n        # end\n        self.norm_out = Normalize(in_channels)\n        self.conv_out = torch.nn.Conv2d(in_channels,\n                                        out_channels,\n                                        kernel_size=3,\n                                        stride=1,\n                                        padding=1)\n\n    def forward(self, x):\n        for i, layer in enumerate(self.model):\n            if i in [1,2,3]:\n                x = layer(x, None)\n            else:\n                x = layer(x)\n\n        h = self.norm_out(x)\n        h = nonlinearity(h)\n        x = self.conv_out(h)\n        return x\n\n\nclass UpsampleDecoder(nn.Module):\n    def __init__(self, in_channels, out_channels, ch, num_res_blocks, resolution,\n                 ch_mult=(2,2), dropout=0.0):\n        super().__init__()\n        # upsampling\n        self.temb_ch = 0\n        self.num_resolutions = len(ch_mult)\n        self.num_res_blocks = num_res_blocks\n        block_in = in_channels\n        curr_res = resolution // 2 ** (self.num_resolutions - 1)\n        self.res_blocks = nn.ModuleList()\n        self.upsample_blocks = nn.ModuleList()\n        for i_level in range(self.num_resolutions):\n            res_block = []\n            block_out = ch * ch_mult[i_level]\n            for i_block in range(self.num_res_blocks + 1):\n                res_block.append(ResnetBlock(in_channels=block_in,\n                                         out_channels=block_out,\n                                         temb_channels=self.temb_ch,\n                                         dropout=dropout))\n                block_in = block_out\n            self.res_blocks.append(nn.ModuleList(res_block))\n            if i_level != self.num_resolutions - 1:\n                self.upsample_blocks.append(Upsample(block_in, True))\n                curr_res = curr_res * 2\n\n        # end\n        self.norm_out = Normalize(block_in)\n        self.conv_out = torch.nn.Conv2d(block_in,\n                                        out_channels,\n                                        kernel_size=3,\n                                        stride=1,\n                                        padding=1)\n\n    def forward(self, x):\n        # upsampling\n        h = x\n        for k, i_level in enumerate(range(self.num_resolutions)):\n            for i_block in range(self.num_res_blocks + 1):\n                h = self.res_blocks[i_level][i_block](h, None)\n            if i_level != self.num_resolutions - 1:\n                h = self.upsample_blocks[k](h)\n        h = self.norm_out(h)\n        h = nonlinearity(h)\n        h = self.conv_out(h)\n        return h\n\n\nclass LatentRescaler(nn.Module):\n    def __init__(self, factor, in_channels, mid_channels, out_channels, depth=2):\n        super().__init__()\n        # residual block, interpolate, residual block\n        self.factor = factor\n        self.conv_in = nn.Conv2d(in_channels,\n                                 mid_channels,\n                                 kernel_size=3,\n                                 stride=1,\n                                 padding=1)\n        self.res_block1 = nn.ModuleList([ResnetBlock(in_channels=mid_channels,\n                                                     out_channels=mid_channels,\n                                                     temb_channels=0,\n                                                     dropout=0.0) for _ in range(depth)])\n        self.attn = AttnBlock(mid_channels)\n        self.res_block2 = nn.ModuleList([ResnetBlock(in_channels=mid_channels,\n                                                     out_channels=mid_channels,\n                                                     temb_channels=0,\n                                                     dropout=0.0) for _ in range(depth)])\n\n        self.conv_out = nn.Conv2d(mid_channels,\n                                  out_channels,\n                                  kernel_size=1,\n                                  )\n\n    def forward(self, x):\n        x = self.conv_in(x)\n        for block in self.res_block1:\n            x = block(x, None)\n        x = torch.nn.functional.interpolate(x, size=(int(round(x.shape[2]*self.factor)), int(round(x.shape[3]*self.factor))))\n        x = self.attn(x)\n        for block in self.res_block2:\n            x = block(x, None)\n        x = self.conv_out(x)\n        return x\n\n\nclass MergedRescaleEncoder(nn.Module):\n    def __init__(self, in_channels, ch, resolution, out_ch, num_res_blocks,\n                 attn_resolutions, dropout=0.0, resamp_with_conv=True,\n                 ch_mult=(1,2,4,8), rescale_factor=1.0, rescale_module_depth=1):\n        super().__init__()\n        intermediate_chn = ch * ch_mult[-1]\n        self.encoder = Encoder(in_channels=in_channels, num_res_blocks=num_res_blocks, ch=ch, ch_mult=ch_mult,\n                               z_channels=intermediate_chn, double_z=False, resolution=resolution,\n                               attn_resolutions=attn_resolutions, dropout=dropout, resamp_with_conv=resamp_with_conv,\n                               out_ch=None)\n        self.rescaler = LatentRescaler(factor=rescale_factor, in_channels=intermediate_chn,\n                                       mid_channels=intermediate_chn, out_channels=out_ch, depth=rescale_module_depth)\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.rescaler(x)\n        return x\n\n\nclass MergedRescaleDecoder(nn.Module):\n    def __init__(self, z_channels, out_ch, resolution, num_res_blocks, attn_resolutions, ch, ch_mult=(1,2,4,8),\n                 dropout=0.0, resamp_with_conv=True, rescale_factor=1.0, rescale_module_depth=1):\n        super().__init__()\n        tmp_chn = z_channels*ch_mult[-1]\n        self.decoder = Decoder(out_ch=out_ch, z_channels=tmp_chn, attn_resolutions=attn_resolutions, dropout=dropout,\n                               resamp_with_conv=resamp_with_conv, in_channels=None, num_res_blocks=num_res_blocks,\n                               ch_mult=ch_mult, resolution=resolution, ch=ch)\n        self.rescaler = LatentRescaler(factor=rescale_factor, in_channels=z_channels, mid_channels=tmp_chn,\n                                       out_channels=tmp_chn, depth=rescale_module_depth)\n\n    def forward(self, x):\n        x = self.rescaler(x)\n        x = self.decoder(x)\n        return x\n\n\nclass Upsampler(nn.Module):\n    def __init__(self, in_size, out_size, in_channels, out_channels, ch_mult=2):\n        super().__init__()\n        assert out_size >= in_size\n        num_blocks = int(np.log2(out_size//in_size))+1\n        factor_up = 1.+ (out_size % in_size)\n        print(f"Building {self.__class__.__name__} with in_size: {in_size} --> out_size {out_size} and factor {factor_up}")\n        self.rescaler = LatentRescaler(factor=factor_up, in_channels=in_channels, mid_channels=2*in_channels,\n                                       out_channels=in_channels)\n        self.decoder = Decoder(out_ch=out_channels, resolution=out_size, z_channels=in_channels, num_res_blocks=2,\n                               attn_resolutions=[], in_channels=None, ch=in_channels,\n                               ch_mult=[ch_mult for _ in range(num_blocks)])\n\n    def forward(self, x):\n        x = self.rescaler(x)\n        x = self.decoder(x)\n        return x\n\n\nclass Resize(nn.Module):\n    def __init__(self, in_channels=None, learned=False, mode="bilinear"):\n        super().__init__()\n        self.with_conv = learned\n        self.mode = mode\n        if self.with_conv:\n            print(f"Note: {self.__class__.__name} uses learned downsampling and will ignore the fixed {mode} mode")\n            raise NotImplementedError()\n            assert in_channels is not None\n            # no asymmetric padding in torch conv, must do it ourselves\n            self.conv = torch.nn.Conv2d(in_channels,\n                                        in_channels,\n                                        kernel_size=4,\n                                        stride=2,\n                                        padding=1)\n\n    def forward(self, x, scale_factor=1.0):\n        if scale_factor==1.0:\n            return x\n        else:\n            x = torch.nn.functional.interpolate(x, mode=self.mode, align_corners=False, scale_factor=scale_factor)\n        return x\n\nclass FirstStagePostProcessor(nn.Module):\n\n    def __init__(self, ch_mult:list, in_channels,\n                 pretrained_model:nn.Module=None,\n                 reshape=False,\n                 n_channels=None,\n                 dropout=0.,\n                 pretrained_config=None):\n        super().__init__()\n        if pretrained_config is None:\n            assert pretrained_model is not None, \'Either "pretrained_model" or "pretrained_config" must not be None\'\n            self.pretrained_model = pretrained_model\n        else:\n            assert pretrained_config is not None, \'Either "pretrained_model" or "pretrained_config" must not be None\'\n            self.instantiate_pretrained(pretrained_config)\n\n        self.do_reshape = reshape\n\n        if n_channels is None:\n            n_channels = self.pretrained_model.encoder.ch\n\n        self.proj_norm = Normalize(in_channels,num_groups=in_channels//2)\n        self.proj = nn.Conv2d(in_channels,n_channels,kernel_size=3,\n                            stride=1,padding=1)\n\n        blocks = []\n        downs = []\n        ch_in = n_channels\n        for m in ch_mult:\n            blocks.append(ResnetBlock(in_channels=ch_in,out_channels=m*n_channels,dropout=dropout))\n            ch_in = m * n_channels\n            downs.append(Downsample(ch_in, with_conv=False))\n\n        self.model = nn.ModuleList(blocks)\n        self.downsampler = nn.ModuleList(downs)\n\n\n    def instantiate_pretrained(self, config):\n        model = instantiate_from_config(config)\n        self.pretrained_model = model.eval()\n        # self.pretrained_model.train = False\n        for param in self.pretrained_model.parameters():\n            param.requires_grad = False\n\n\n    @torch.no_grad()\n    def encode_with_pretrained(self,x):\n        c = self.pretrained_model.encode(x)\n        if isinstance(c, DiagonalGaussianDistribution):\n            c = c.mode()\n        return  c\n\n    def forward(self,x):\n        z_fs = self.encode_with_pretrained(x)\n        z = self.proj_norm(z_fs)\n        z = self.proj(z)\n        z = nonlinearity(z)\n\n        for submodel, downmodel in zip(self.model,self.downsampler):\n            z = submodel(z,temb=None)\n            z = downmodel(z)\n\n        if self.do_reshape:\n            z = rearrange(z,\'b c h w -> b (h w) c\')\n        return z\n\n',
    'model.ldm.modules.diffusionmodules.openaimodel': 'from abc import abstractmethod\nfrom functools import partial\nimport math\nfrom typing import Iterable\n\nimport numpy as np\nimport torch as th\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom model.ldm.modules.diffusionmodules.util import (\n    checkpoint,\n    conv_nd,\n    linear,\n    avg_pool_nd,\n    zero_module,\n    normalization,\n    timestep_embedding,\n)\nfrom model.ldm.modules.attention import SpatialTransformer\n\n\n# dummy replace\ndef convert_module_to_f16(x):\n    pass\n\ndef convert_module_to_f32(x):\n    pass\n\n\n## go\nclass AttentionPool2d(nn.Module):\n    """\n    Adapted from CLIP: https://github.com/openai/CLIP/blob/main/clip/model.py\n    """\n\n    def __init__(\n        self,\n        spacial_dim: int,\n        embed_dim: int,\n        num_heads_channels: int,\n        output_dim: int = None,\n    ):\n        super().__init__()\n        self.positional_embedding = nn.Parameter(th.randn(embed_dim, spacial_dim ** 2 + 1) / embed_dim ** 0.5)\n        self.qkv_proj = conv_nd(1, embed_dim, 3 * embed_dim, 1)\n        self.c_proj = conv_nd(1, embed_dim, output_dim or embed_dim, 1)\n        self.num_heads = embed_dim // num_heads_channels\n        self.attention = QKVAttention(self.num_heads)\n\n    def forward(self, x):\n        b, c, *_spatial = x.shape\n        x = x.reshape(b, c, -1)  # NC(HW)\n        x = th.cat([x.mean(dim=-1, keepdim=True), x], dim=-1)  # NC(HW+1)\n        x = x + self.positional_embedding[None, :, :].to(x.dtype)  # NC(HW+1)\n        x = self.qkv_proj(x)\n        x = self.attention(x)\n        x = self.c_proj(x)\n        return x[:, :, 0]\n\n\nclass TimestepBlock(nn.Module):\n    """\n    Any module where forward() takes timestep embeddings as a second argument.\n    """\n\n    @abstractmethod\n    def forward(self, x, emb):\n        """\n        Apply the module to `x` given `emb` timestep embeddings.\n        """\n\n\nclass TimestepEmbedSequential(nn.Sequential, TimestepBlock):\n    """\n    A sequential module that passes timestep embeddings to the children that\n    support it as an extra input.\n    """\n\n    def forward(self, x, emb, context=None):\n        for layer in self:\n            if isinstance(layer, TimestepBlock):\n                x = layer(x, emb)\n            elif isinstance(layer, SpatialTransformer):\n                x = layer(x, context)\n            else:\n                x = layer(x)\n        return x\n\n\nclass Upsample(nn.Module):\n    """\n    An upsampling layer with an optional convolution.\n    :param channels: channels in the inputs and outputs.\n    :param use_conv: a bool determining if a convolution is applied.\n    :param dims: determines if the signal is 1D, 2D, or 3D. If 3D, then\n                 upsampling occurs in the inner-two dimensions.\n    """\n\n    def __init__(self, channels, use_conv, dims=2, out_channels=None, padding=1):\n        super().__init__()\n        self.channels = channels\n        self.out_channels = out_channels or channels\n        self.use_conv = use_conv\n        self.dims = dims\n        if use_conv:\n            self.conv = conv_nd(dims, self.channels, self.out_channels, 3, padding=padding)\n\n    def forward(self, x):\n        assert x.shape[1] == self.channels\n        if self.dims == 3:\n            x = F.interpolate(\n                x, (x.shape[2], x.shape[3] * 2, x.shape[4] * 2), mode="nearest"\n            )\n        else:\n            x = F.interpolate(x, scale_factor=2, mode="nearest")\n        if self.use_conv:\n            x = self.conv(x)\n        return x\n\nclass TransposedUpsample(nn.Module):\n    \'Learned 2x upsampling without padding\'\n    def __init__(self, channels, out_channels=None, ks=5):\n        super().__init__()\n        self.channels = channels\n        self.out_channels = out_channels or channels\n\n        self.up = nn.ConvTranspose2d(self.channels,self.out_channels,kernel_size=ks,stride=2)\n\n    def forward(self,x):\n        return self.up(x)\n\n\nclass Downsample(nn.Module):\n    """\n    A downsampling layer with an optional convolution.\n    :param channels: channels in the inputs and outputs.\n    :param use_conv: a bool determining if a convolution is applied.\n    :param dims: determines if the signal is 1D, 2D, or 3D. If 3D, then\n                 downsampling occurs in the inner-two dimensions.\n    """\n\n    def __init__(self, channels, use_conv, dims=2, out_channels=None,padding=1):\n        super().__init__()\n        self.channels = channels\n        self.out_channels = out_channels or channels\n        self.use_conv = use_conv\n        self.dims = dims\n        stride = 2 if dims != 3 else (1, 2, 2)\n        if use_conv:\n            self.op = conv_nd(\n                dims, self.channels, self.out_channels, 3, stride=stride, padding=padding\n            )\n        else:\n            assert self.channels == self.out_channels\n            self.op = avg_pool_nd(dims, kernel_size=stride, stride=stride)\n\n    def forward(self, x):\n        assert x.shape[1] == self.channels\n        return self.op(x)\n\n\nclass ResBlock(TimestepBlock):\n    """\n    A residual block that can optionally change the number of channels.\n    :param channels: the number of input channels.\n    :param emb_channels: the number of timestep embedding channels.\n    :param dropout: the rate of dropout.\n    :param out_channels: if specified, the number of out channels.\n    :param use_conv: if True and out_channels is specified, use a spatial\n        convolution instead of a smaller 1x1 convolution to change the\n        channels in the skip connection.\n    :param dims: determines if the signal is 1D, 2D, or 3D.\n    :param use_checkpoint: if True, use gradient checkpointing on this module.\n    :param up: if True, use this block for upsampling.\n    :param down: if True, use this block for downsampling.\n    """\n\n    def __init__(\n        self,\n        channels,\n        emb_channels,\n        dropout,\n        out_channels=None,\n        use_conv=False,\n        use_scale_shift_norm=False,\n        dims=2,\n        use_checkpoint=False,\n        up=False,\n        down=False,\n    ):\n        super().__init__()\n        self.channels = channels\n        self.emb_channels = emb_channels\n        self.dropout = dropout\n        self.out_channels = out_channels or channels\n        self.use_conv = use_conv\n        self.use_checkpoint = use_checkpoint\n        self.use_scale_shift_norm = use_scale_shift_norm\n\n        self.in_layers = nn.Sequential(\n            normalization(channels),\n            nn.SiLU(),\n            conv_nd(dims, channels, self.out_channels, 3, padding=1),\n        )\n\n        self.updown = up or down\n\n        if up:\n            self.h_upd = Upsample(channels, False, dims)\n            self.x_upd = Upsample(channels, False, dims)\n        elif down:\n            self.h_upd = Downsample(channels, False, dims)\n            self.x_upd = Downsample(channels, False, dims)\n        else:\n            self.h_upd = self.x_upd = nn.Identity()\n\n        self.emb_layers = nn.Sequential(\n            nn.SiLU(),\n            linear(\n                emb_channels,\n                2 * self.out_channels if use_scale_shift_norm else self.out_channels,\n            ),\n        )\n        self.out_layers = nn.Sequential(\n            normalization(self.out_channels),\n            nn.SiLU(),\n            nn.Dropout(p=dropout),\n            zero_module(\n                conv_nd(dims, self.out_channels, self.out_channels, 3, padding=1)\n            ),\n        )\n\n        if self.out_channels == channels:\n            self.skip_connection = nn.Identity()\n        elif use_conv:\n            self.skip_connection = conv_nd(\n                dims, channels, self.out_channels, 3, padding=1\n            )\n        else:\n            self.skip_connection = conv_nd(dims, channels, self.out_channels, 1)\n\n    def forward(self, x, emb):\n        """\n        Apply the block to a Tensor, conditioned on a timestep embedding.\n        :param x: an [N x C x ...] Tensor of features.\n        :param emb: an [N x emb_channels] Tensor of timestep embeddings.\n        :return: an [N x C x ...] Tensor of outputs.\n        """\n        return checkpoint(\n            self._forward, (x, emb), self.parameters(), self.use_checkpoint\n        )\n\n\n    def _forward(self, x, emb):\n        if self.updown:\n            in_rest, in_conv = self.in_layers[:-1], self.in_layers[-1]\n            h = in_rest(x)\n            h = self.h_upd(h)\n            x = self.x_upd(x)\n            h = in_conv(h)\n        else:\n            h = self.in_layers(x)\n        emb_out = self.emb_layers(emb).type(h.dtype)\n        while len(emb_out.shape) < len(h.shape):\n            emb_out = emb_out[..., None]\n        if self.use_scale_shift_norm:\n            out_norm, out_rest = self.out_layers[0], self.out_layers[1:]\n            scale, shift = th.chunk(emb_out, 2, dim=1)\n            h = out_norm(h) * (1 + scale) + shift\n            h = out_rest(h)\n        else:\n            h = h + emb_out\n            h = self.out_layers(h)\n        return self.skip_connection(x) + h\n\n\nclass AttentionBlock(nn.Module):\n    """\n    An attention block that allows spatial positions to attend to each other.\n    Originally ported from here, but adapted to the N-d case.\n    https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/models/unet.py#L66.\n    """\n\n    def __init__(\n        self,\n        channels,\n        num_heads=1,\n        num_head_channels=-1,\n        use_checkpoint=False,\n        use_new_attention_order=False,\n    ):\n        super().__init__()\n        self.channels = channels\n        if num_head_channels == -1:\n            self.num_heads = num_heads\n        else:\n            assert (\n                channels % num_head_channels == 0\n            ), f"q,k,v channels {channels} is not divisible by num_head_channels {num_head_channels}"\n            self.num_heads = channels // num_head_channels\n        self.use_checkpoint = use_checkpoint\n        self.norm = normalization(channels)\n        self.qkv = conv_nd(1, channels, channels * 3, 1)\n        if use_new_attention_order:\n            # split qkv before split heads\n            self.attention = QKVAttention(self.num_heads)\n        else:\n            # split heads before split qkv\n            self.attention = QKVAttentionLegacy(self.num_heads)\n\n        self.proj_out = zero_module(conv_nd(1, channels, channels, 1))\n\n    def forward(self, x):\n        return checkpoint(self._forward, (x,), self.parameters(), True)   # TODO: check checkpoint usage, is True # TODO: fix the .half call!!!\n        #return pt_checkpoint(self._forward, x)  # pytorch\n\n    def _forward(self, x):\n        b, c, *spatial = x.shape\n        x = x.reshape(b, c, -1)\n        qkv = self.qkv(self.norm(x))\n        h = self.attention(qkv)\n        h = self.proj_out(h)\n        return (x + h).reshape(b, c, *spatial)\n\n\ndef count_flops_attn(model, _x, y):\n    """\n    A counter for the `thop` package to count the operations in an\n    attention operation.\n    Meant to be used like:\n        macs, params = thop.profile(\n            model,\n            inputs=(inputs, timestamps),\n            custom_ops={QKVAttention: QKVAttention.count_flops},\n        )\n    """\n    b, c, *spatial = y[0].shape\n    num_spatial = int(np.prod(spatial))\n    # We perform two matmuls with the same number of ops.\n    # The first computes the weight matrix, the second computes\n    # the combination of the value vectors.\n    matmul_ops = 2 * b * (num_spatial ** 2) * c\n    model.total_ops += th.DoubleTensor([matmul_ops])\n\n\nclass QKVAttentionLegacy(nn.Module):\n    """\n    A module which performs QKV attention. Matches legacy QKVAttention + input/ouput heads shaping\n    """\n\n    def __init__(self, n_heads):\n        super().__init__()\n        self.n_heads = n_heads\n\n    def forward(self, qkv):\n        """\n        Apply QKV attention.\n        :param qkv: an [N x (H * 3 * C) x T] tensor of Qs, Ks, and Vs.\n        :return: an [N x (H * C) x T] tensor after attention.\n        """\n        bs, width, length = qkv.shape\n        assert width % (3 * self.n_heads) == 0\n        ch = width // (3 * self.n_heads)\n        q, k, v = qkv.reshape(bs * self.n_heads, ch * 3, length).split(ch, dim=1)\n        scale = 1 / math.sqrt(math.sqrt(ch))\n        weight = th.einsum(\n            "bct,bcs->bts", q * scale, k * scale\n        )  # More stable with f16 than dividing afterwards\n        weight = th.softmax(weight.float(), dim=-1).type(weight.dtype)\n        a = th.einsum("bts,bcs->bct", weight, v)\n        return a.reshape(bs, -1, length)\n\n    @staticmethod\n    def count_flops(model, _x, y):\n        return count_flops_attn(model, _x, y)\n\n\nclass QKVAttention(nn.Module):\n    """\n    A module which performs QKV attention and splits in a different order.\n    """\n\n    def __init__(self, n_heads):\n        super().__init__()\n        self.n_heads = n_heads\n\n    def forward(self, qkv):\n        """\n        Apply QKV attention.\n        :param qkv: an [N x (3 * H * C) x T] tensor of Qs, Ks, and Vs.\n        :return: an [N x (H * C) x T] tensor after attention.\n        """\n        bs, width, length = qkv.shape\n        assert width % (3 * self.n_heads) == 0\n        ch = width // (3 * self.n_heads)\n        q, k, v = qkv.chunk(3, dim=1)\n        scale = 1 / math.sqrt(math.sqrt(ch))\n        weight = th.einsum(\n            "bct,bcs->bts",\n            (q * scale).view(bs * self.n_heads, ch, length),\n            (k * scale).view(bs * self.n_heads, ch, length),\n        )  # More stable with f16 than dividing afterwards\n        weight = th.softmax(weight.float(), dim=-1).type(weight.dtype)\n        a = th.einsum("bts,bcs->bct", weight, v.reshape(bs * self.n_heads, ch, length))\n        return a.reshape(bs, -1, length)\n\n    @staticmethod\n    def count_flops(model, _x, y):\n        return count_flops_attn(model, _x, y)\n\n\nclass UNetModel(nn.Module):\n    """\n    The full UNet model with attention and timestep embedding.\n    :param in_channels: channels in the input Tensor.\n    :param model_channels: base channel count for the model.\n    :param out_channels: channels in the output Tensor.\n    :param num_res_blocks: number of residual blocks per downsample.\n    :param attention_resolutions: a collection of downsample rates at which\n        attention will take place. May be a set, list, or tuple.\n        For example, if this contains 4, then at 4x downsampling, attention\n        will be used.\n    :param dropout: the dropout probability.\n    :param channel_mult: channel multiplier for each level of the UNet.\n    :param conv_resample: if True, use learned convolutions for upsampling and\n        downsampling.\n    :param dims: determines if the signal is 1D, 2D, or 3D.\n    :param num_classes: if specified (as an int), then this model will be\n        class-conditional with `num_classes` classes.\n    :param use_checkpoint: use gradient checkpointing to reduce memory usage.\n    :param num_heads: the number of attention heads in each attention layer.\n    :param num_heads_channels: if specified, ignore num_heads and instead use\n                               a fixed channel width per attention head.\n    :param num_heads_upsample: works with num_heads to set a different number\n                               of heads for upsampling. Deprecated.\n    :param use_scale_shift_norm: use a FiLM-like conditioning mechanism.\n    :param resblock_updown: use residual blocks for up/downsampling.\n    :param use_new_attention_order: use a different attention pattern for potentially\n                                    increased efficiency.\n    """\n\n    def __init__(\n        self,\n        image_size,\n        in_channels,\n        model_channels,\n        out_channels,\n        num_res_blocks,\n        attention_resolutions,\n        dropout=0,\n        channel_mult=(1, 2, 4, 8),\n        conv_resample=True,\n        dims=2,\n        num_classes=None,\n        use_checkpoint=False,\n        use_fp16=False,\n        num_heads=-1,\n        num_head_channels=-1,\n        num_heads_upsample=-1,\n        use_scale_shift_norm=False,\n        resblock_updown=False,\n        use_new_attention_order=False,\n        use_spatial_transformer=False,    # custom transformer support\n        transformer_depth=1,              # custom transformer support\n        context_dim=None,                 # custom transformer support\n        n_embed=None,                     # custom support for prediction of discrete ids into codebook of first stage vq model\n        legacy=True,\n    ):\n        super().__init__()\n        if use_spatial_transformer:\n            assert context_dim is not None, \'Fool!! You forgot to include the dimension of your cross-attention conditioning...\'\n\n        if context_dim is not None:\n            assert use_spatial_transformer, \'Fool!! You forgot to use the spatial transformer for your cross-attention conditioning...\'\n            from omegaconf.listconfig import ListConfig\n            if type(context_dim) == ListConfig:\n                context_dim = list(context_dim)\n\n        if num_heads_upsample == -1:\n            num_heads_upsample = num_heads\n\n        if num_heads == -1:\n            assert num_head_channels != -1, \'Either num_heads or num_head_channels has to be set\'\n\n        if num_head_channels == -1:\n            assert num_heads != -1, \'Either num_heads or num_head_channels has to be set\'\n\n        self.image_size = image_size\n        self.in_channels = in_channels\n        self.model_channels = model_channels\n        self.out_channels = out_channels\n        self.num_res_blocks = num_res_blocks\n        self.attention_resolutions = attention_resolutions\n        self.dropout = dropout\n        self.channel_mult = channel_mult\n        self.conv_resample = conv_resample\n        self.num_classes = num_classes\n        self.use_checkpoint = use_checkpoint\n        self.dtype = th.float16 if use_fp16 else th.float32\n        self.num_heads = num_heads\n        self.num_head_channels = num_head_channels\n        self.num_heads_upsample = num_heads_upsample\n        self.predict_codebook_ids = n_embed is not None\n\n        time_embed_dim = model_channels * 4\n        self.time_embed = nn.Sequential(\n            linear(model_channels, time_embed_dim),\n            nn.SiLU(),\n            linear(time_embed_dim, time_embed_dim),\n        )\n\n        if self.num_classes is not None:\n            self.label_emb = nn.Embedding(num_classes, time_embed_dim)\n\n        self.input_blocks = nn.ModuleList(\n            [\n                TimestepEmbedSequential(\n                    conv_nd(dims, in_channels, model_channels, 3, padding=1)\n                )\n            ]\n        )\n        self._feature_size = model_channels\n        input_block_chans = [model_channels]\n        ch = model_channels\n        ds = 1\n        for level, mult in enumerate(channel_mult):\n            for _ in range(num_res_blocks):\n                layers = [\n                    ResBlock(\n                        ch,\n                        time_embed_dim,\n                        dropout,\n                        out_channels=mult * model_channels,\n                        dims=dims,\n                        use_checkpoint=use_checkpoint,\n                        use_scale_shift_norm=use_scale_shift_norm,\n                    )\n                ]\n                ch = mult * model_channels\n                if ds in attention_resolutions:\n                    if num_head_channels == -1:\n                        dim_head = ch // num_heads\n                    else:\n                        num_heads = ch // num_head_channels\n                        dim_head = num_head_channels\n                    if legacy:\n                        #num_heads = 1\n                        dim_head = ch // num_heads if use_spatial_transformer else num_head_channels\n                    layers.append(\n                        AttentionBlock(\n                            ch,\n                            use_checkpoint=use_checkpoint,\n                            num_heads=num_heads,\n                            num_head_channels=dim_head,\n                            use_new_attention_order=use_new_attention_order,\n                        ) if not use_spatial_transformer else SpatialTransformer(\n                            ch, num_heads, dim_head, depth=transformer_depth, context_dim=context_dim\n                        )\n                    )\n                self.input_blocks.append(TimestepEmbedSequential(*layers))\n                self._feature_size += ch\n                input_block_chans.append(ch)\n            if level != len(channel_mult) - 1:\n                out_ch = ch\n                self.input_blocks.append(\n                    TimestepEmbedSequential(\n                        ResBlock(\n                            ch,\n                            time_embed_dim,\n                            dropout,\n                            out_channels=out_ch,\n                            dims=dims,\n                            use_checkpoint=use_checkpoint,\n                            use_scale_shift_norm=use_scale_shift_norm,\n                            down=True,\n                        )\n                        if resblock_updown\n                        else Downsample(\n                            ch, conv_resample, dims=dims, out_channels=out_ch\n                        )\n                    )\n                )\n                ch = out_ch\n                input_block_chans.append(ch)\n                ds *= 2\n                self._feature_size += ch\n\n        if num_head_channels == -1:\n            dim_head = ch // num_heads\n        else:\n            num_heads = ch // num_head_channels\n            dim_head = num_head_channels\n        if legacy:\n            #num_heads = 1\n            dim_head = ch // num_heads if use_spatial_transformer else num_head_channels\n        self.middle_block = TimestepEmbedSequential(\n            ResBlock(\n                ch,\n                time_embed_dim,\n                dropout,\n                dims=dims,\n                use_checkpoint=use_checkpoint,\n                use_scale_shift_norm=use_scale_shift_norm,\n            ),\n            AttentionBlock(\n                ch,\n                use_checkpoint=use_checkpoint,\n                num_heads=num_heads,\n                num_head_channels=dim_head,\n                use_new_attention_order=use_new_attention_order,\n            ) if not use_spatial_transformer else SpatialTransformer(\n                            ch, num_heads, dim_head, depth=transformer_depth, context_dim=context_dim\n                        ),\n            ResBlock(\n                ch,\n                time_embed_dim,\n                dropout,\n                dims=dims,\n                use_checkpoint=use_checkpoint,\n                use_scale_shift_norm=use_scale_shift_norm,\n            ),\n        )\n        self._feature_size += ch\n\n        self.output_blocks = nn.ModuleList([])\n        for level, mult in list(enumerate(channel_mult))[::-1]:\n            for i in range(num_res_blocks + 1):\n                ich = input_block_chans.pop()\n                layers = [\n                    ResBlock(\n                        ch + ich,\n                        time_embed_dim,\n                        dropout,\n                        out_channels=model_channels * mult,\n                        dims=dims,\n                        use_checkpoint=use_checkpoint,\n                        use_scale_shift_norm=use_scale_shift_norm,\n                    )\n                ]\n                ch = model_channels * mult\n                if ds in attention_resolutions:\n                    if num_head_channels == -1:\n                        dim_head = ch // num_heads\n                    else:\n                        num_heads = ch // num_head_channels\n                        dim_head = num_head_channels\n                    if legacy:\n                        #num_heads = 1\n                        dim_head = ch // num_heads if use_spatial_transformer else num_head_channels\n                    layers.append(\n                        AttentionBlock(\n                            ch,\n                            use_checkpoint=use_checkpoint,\n                            num_heads=num_heads_upsample,\n                            num_head_channels=dim_head,\n                            use_new_attention_order=use_new_attention_order,\n                        ) if not use_spatial_transformer else SpatialTransformer(\n                            ch, num_heads, dim_head, depth=transformer_depth, context_dim=context_dim\n                        )\n                    )\n                if level and i == num_res_blocks:\n                    out_ch = ch\n                    layers.append(\n                        ResBlock(\n                            ch,\n                            time_embed_dim,\n                            dropout,\n                            out_channels=out_ch,\n                            dims=dims,\n                            use_checkpoint=use_checkpoint,\n                            use_scale_shift_norm=use_scale_shift_norm,\n                            up=True,\n                        )\n                        if resblock_updown\n                        else Upsample(ch, conv_resample, dims=dims, out_channels=out_ch)\n                    )\n                    ds //= 2\n                self.output_blocks.append(TimestepEmbedSequential(*layers))\n                self._feature_size += ch\n\n        self.out = nn.Sequential(\n            normalization(ch),\n            nn.SiLU(),\n            zero_module(conv_nd(dims, model_channels, out_channels, 3, padding=1)),\n        )\n        if self.predict_codebook_ids:\n            self.id_predictor = nn.Sequential(\n            normalization(ch),\n            conv_nd(dims, model_channels, n_embed, 1),\n            #nn.LogSoftmax(dim=1)  # change to cross_entropy and produce non-normalized logits\n        )\n\n    def convert_to_fp16(self):\n        """\n        Convert the torso of the model to float16.\n        """\n        self.input_blocks.apply(convert_module_to_f16)\n        self.middle_block.apply(convert_module_to_f16)\n        self.output_blocks.apply(convert_module_to_f16)\n\n    def convert_to_fp32(self):\n        """\n        Convert the torso of the model to float32.\n        """\n        self.input_blocks.apply(convert_module_to_f32)\n        self.middle_block.apply(convert_module_to_f32)\n        self.output_blocks.apply(convert_module_to_f32)\n\n    def forward(self, x, timesteps=None, context=None, y=None,**kwargs):\n        """\n        Apply the model to an input batch.\n        :param x: an [N x C x ...] Tensor of inputs.\n        :param timesteps: a 1-D batch of timesteps.\n        :param context: conditioning plugged in via crossattn\n        :param y: an [N] Tensor of labels, if class-conditional.\n        :return: an [N x C x ...] Tensor of outputs.\n        """\n        assert (y is not None) == (\n            self.num_classes is not None\n        ), "must specify y if and only if the model is class-conditional"\n        hs = []\n        t_emb = timestep_embedding(timesteps, self.model_channels, repeat_only=False)\n        emb = self.time_embed(t_emb)\n\n        if self.num_classes is not None:\n            assert y.shape == (x.shape[0],)\n            emb = emb + self.label_emb(y)\n\n        h = x.type(self.dtype)\n        for module in self.input_blocks:\n            h = module(h, emb, context)\n            hs.append(h)\n        h = self.middle_block(h, emb, context)\n        for module in self.output_blocks:\n            h = th.cat([h, hs.pop()], dim=1)\n            h = module(h, emb, context)\n        h = h.type(x.dtype)\n        if self.predict_codebook_ids:\n            return self.id_predictor(h)\n        else:\n            return self.out(h)\n\n\nclass EncoderUNetModel(nn.Module):\n    """\n    The half UNet model with attention and timestep embedding.\n    For usage, see UNet.\n    """\n\n    def __init__(\n        self,\n        image_size,\n        in_channels,\n        model_channels,\n        out_channels,\n        num_res_blocks,\n        attention_resolutions,\n        dropout=0,\n        channel_mult=(1, 2, 4, 8),\n        conv_resample=True,\n        dims=2,\n        use_checkpoint=False,\n        use_fp16=False,\n        num_heads=1,\n        num_head_channels=-1,\n        num_heads_upsample=-1,\n        use_scale_shift_norm=False,\n        resblock_updown=False,\n        use_new_attention_order=False,\n        pool="adaptive",\n        *args,\n        **kwargs\n    ):\n        super().__init__()\n\n        if num_heads_upsample == -1:\n            num_heads_upsample = num_heads\n\n        self.in_channels = in_channels\n        self.model_channels = model_channels\n        self.out_channels = out_channels\n        self.num_res_blocks = num_res_blocks\n        self.attention_resolutions = attention_resolutions\n        self.dropout = dropout\n        self.channel_mult = channel_mult\n        self.conv_resample = conv_resample\n        self.use_checkpoint = use_checkpoint\n        self.dtype = th.float16 if use_fp16 else th.float32\n        self.num_heads = num_heads\n        self.num_head_channels = num_head_channels\n        self.num_heads_upsample = num_heads_upsample\n\n        time_embed_dim = model_channels * 4\n        self.time_embed = nn.Sequential(\n            linear(model_channels, time_embed_dim),\n            nn.SiLU(),\n            linear(time_embed_dim, time_embed_dim),\n        )\n\n        self.input_blocks = nn.ModuleList(\n            [\n                TimestepEmbedSequential(\n                    conv_nd(dims, in_channels, model_channels, 3, padding=1)\n                )\n            ]\n        )\n        self._feature_size = model_channels\n        input_block_chans = [model_channels]\n        ch = model_channels\n        ds = 1\n        for level, mult in enumerate(channel_mult):\n            for _ in range(num_res_blocks):\n                layers = [\n                    ResBlock(\n                        ch,\n                        time_embed_dim,\n                        dropout,\n                        out_channels=mult * model_channels,\n                        dims=dims,\n                        use_checkpoint=use_checkpoint,\n                        use_scale_shift_norm=use_scale_shift_norm,\n                    )\n                ]\n                ch = mult * model_channels\n                if ds in attention_resolutions:\n                    layers.append(\n                        AttentionBlock(\n                            ch,\n                            use_checkpoint=use_checkpoint,\n                            num_heads=num_heads,\n                            num_head_channels=num_head_channels,\n                            use_new_attention_order=use_new_attention_order,\n                        )\n                    )\n                self.input_blocks.append(TimestepEmbedSequential(*layers))\n                self._feature_size += ch\n                input_block_chans.append(ch)\n            if level != len(channel_mult) - 1:\n                out_ch = ch\n                self.input_blocks.append(\n                    TimestepEmbedSequential(\n                        ResBlock(\n                            ch,\n                            time_embed_dim,\n                            dropout,\n                            out_channels=out_ch,\n                            dims=dims,\n                            use_checkpoint=use_checkpoint,\n                            use_scale_shift_norm=use_scale_shift_norm,\n                            down=True,\n                        )\n                        if resblock_updown\n                        else Downsample(\n                            ch, conv_resample, dims=dims, out_channels=out_ch\n                        )\n                    )\n                )\n                ch = out_ch\n                input_block_chans.append(ch)\n                ds *= 2\n                self._feature_size += ch\n\n        self.middle_block = TimestepEmbedSequential(\n            ResBlock(\n                ch,\n                time_embed_dim,\n                dropout,\n                dims=dims,\n                use_checkpoint=use_checkpoint,\n                use_scale_shift_norm=use_scale_shift_norm,\n            ),\n            AttentionBlock(\n                ch,\n                use_checkpoint=use_checkpoint,\n                num_heads=num_heads,\n                num_head_channels=num_head_channels,\n                use_new_attention_order=use_new_attention_order,\n            ),\n            ResBlock(\n                ch,\n                time_embed_dim,\n                dropout,\n                dims=dims,\n                use_checkpoint=use_checkpoint,\n                use_scale_shift_norm=use_scale_shift_norm,\n            ),\n        )\n        self._feature_size += ch\n        self.pool = pool\n        if pool == "adaptive":\n            self.out = nn.Sequential(\n                normalization(ch),\n                nn.SiLU(),\n                nn.AdaptiveAvgPool2d((1, 1)),\n                zero_module(conv_nd(dims, ch, out_channels, 1)),\n                nn.Flatten(),\n            )\n        elif pool == "attention":\n            assert num_head_channels != -1\n            self.out = nn.Sequential(\n                normalization(ch),\n                nn.SiLU(),\n                AttentionPool2d(\n                    (image_size // ds), ch, num_head_channels, out_channels\n                ),\n            )\n        elif pool == "spatial":\n            self.out = nn.Sequential(\n                nn.Linear(self._feature_size, 2048),\n                nn.ReLU(),\n                nn.Linear(2048, self.out_channels),\n            )\n        elif pool == "spatial_v2":\n            self.out = nn.Sequential(\n                nn.Linear(self._feature_size, 2048),\n                normalization(2048),\n                nn.SiLU(),\n                nn.Linear(2048, self.out_channels),\n            )\n        else:\n            raise NotImplementedError(f"Unexpected {pool} pooling")\n\n    def convert_to_fp16(self):\n        """\n        Convert the torso of the model to float16.\n        """\n        self.input_blocks.apply(convert_module_to_f16)\n        self.middle_block.apply(convert_module_to_f16)\n\n    def convert_to_fp32(self):\n        """\n        Convert the torso of the model to float32.\n        """\n        self.input_blocks.apply(convert_module_to_f32)\n        self.middle_block.apply(convert_module_to_f32)\n\n    def forward(self, x, timesteps):\n        """\n        Apply the model to an input batch.\n        :param x: an [N x C x ...] Tensor of inputs.\n        :param timesteps: a 1-D batch of timesteps.\n        :return: an [N x K] Tensor of outputs.\n        """\n        emb = self.time_embed(timestep_embedding(timesteps, self.model_channels))\n\n        results = []\n        h = x.type(self.dtype)\n        for module in self.input_blocks:\n            h = module(h, emb)\n            if self.pool.startswith("spatial"):\n                results.append(h.type(x.dtype).mean(dim=(2, 3)))\n        h = self.middle_block(h, emb)\n        if self.pool.startswith("spatial"):\n            results.append(h.type(x.dtype).mean(dim=(2, 3)))\n            h = th.cat(results, axis=-1)\n            return self.out(h)\n        else:\n            h = h.type(x.dtype)\n            return self.out(h)\n\n',
    'model.ldm.modules.diffusionmodules.util': '# adopted from\n# https://github.com/openai/improved-diffusion/blob/main/improved_diffusion/gaussian_diffusion.py\n# and\n# https://github.com/lucidrains/denoising-diffusion-pytorch/blob/7706bdfc6f527f58d33f84b7b522e61e6e3164b3/denoising_diffusion_pytorch/denoising_diffusion_pytorch.py\n# and\n# https://github.com/openai/guided-diffusion/blob/0ba878e517b276c45d1195eb29f6f5f72659a05b/guided_diffusion/nn.py\n#\n# thanks!\n\n\nimport os\nimport math\nimport torch\nimport torch.nn as nn\nimport numpy as np\nfrom einops import repeat\n\nfrom model.ldm.util import instantiate_from_config\n\n\ndef make_beta_schedule(schedule, n_timestep, linear_start=1e-4, linear_end=2e-2, cosine_s=8e-3):\n    if schedule == "linear":\n        betas = (\n                torch.linspace(linear_start ** 0.5, linear_end ** 0.5, n_timestep, dtype=torch.float64) ** 2\n        )\n\n    elif schedule == "cosine":\n        timesteps = (\n                torch.arange(n_timestep + 1, dtype=torch.float64) / n_timestep + cosine_s\n        )\n        alphas = timesteps / (1 + cosine_s) * np.pi / 2\n        alphas = torch.cos(alphas).pow(2)\n        alphas = alphas / alphas[0]\n        betas = 1 - alphas[1:] / alphas[:-1]\n        betas = np.clip(betas, a_min=0, a_max=0.999)\n\n    elif schedule == "sqrt_linear":\n        betas = torch.linspace(linear_start, linear_end, n_timestep, dtype=torch.float64)\n    elif schedule == "sqrt":\n        betas = torch.linspace(linear_start, linear_end, n_timestep, dtype=torch.float64) ** 0.5\n    else:\n        raise ValueError(f"schedule \'{schedule}\' unknown.")\n    return betas.numpy()\n\n\ndef make_ddim_timesteps(ddim_discr_method, num_ddim_timesteps, num_ddpm_timesteps, verbose=True):\n    if ddim_discr_method == \'uniform\':\n        c = num_ddpm_timesteps // num_ddim_timesteps\n        ddim_timesteps = np.asarray(list(range(0, num_ddpm_timesteps, c)))\n    elif ddim_discr_method == \'quad\':\n        ddim_timesteps = ((np.linspace(0, np.sqrt(num_ddpm_timesteps * .8), num_ddim_timesteps)) ** 2).astype(int)\n    else:\n        raise NotImplementedError(f\'There is no ddim discretization method called "{ddim_discr_method}"\')\n\n    # assert ddim_timesteps.shape[0] == num_ddim_timesteps\n    # add one to get the final alpha values right (the ones from first scale to data during sampling)\n    steps_out = ddim_timesteps + 1\n    if verbose:\n        print(f\'Selected timesteps for ddim sampler: {steps_out}\')\n    return steps_out\n\n\ndef make_ddim_sampling_parameters(alphacums, ddim_timesteps, eta, verbose=True):\n    # select alphas for computing the variance schedule\n    alphas = alphacums[ddim_timesteps]\n    alphas_prev = np.asarray([alphacums[0]] + alphacums[ddim_timesteps[:-1]].tolist())\n\n    # according the the formula provided in https://arxiv.org/abs/2010.02502\n    sigmas = eta * np.sqrt((1 - alphas_prev) / (1 - alphas) * (1 - alphas / alphas_prev))\n    if verbose:\n        print(f\'Selected alphas for ddim sampler: a_t: {alphas}; a_(t-1): {alphas_prev}\')\n        print(f\'For the chosen value of eta, which is {eta}, \'\n              f\'this results in the following sigma_t schedule for ddim sampler {sigmas}\')\n    return sigmas, alphas, alphas_prev\n\n\ndef betas_for_alpha_bar(num_diffusion_timesteps, alpha_bar, max_beta=0.999):\n    """\n    Create a beta schedule that discretizes the given alpha_t_bar function,\n    which defines the cumulative product of (1-beta) over time from t = [0,1].\n    :param num_diffusion_timesteps: the number of betas to produce.\n    :param alpha_bar: a lambda that takes an argument t from 0 to 1 and\n                      produces the cumulative product of (1-beta) up to that\n                      part of the diffusion process.\n    :param max_beta: the maximum beta to use; use values lower than 1 to\n                     prevent singularities.\n    """\n    betas = []\n    for i in range(num_diffusion_timesteps):\n        t1 = i / num_diffusion_timesteps\n        t2 = (i + 1) / num_diffusion_timesteps\n        betas.append(min(1 - alpha_bar(t2) / alpha_bar(t1), max_beta))\n    return np.array(betas)\n\n\ndef extract_into_tensor(a, t, x_shape):\n    b, *_ = t.shape\n    out = a.gather(-1, t)\n    return out.reshape(b, *((1,) * (len(x_shape) - 1)))\n\n\ndef checkpoint(func, inputs, params, flag):\n    """\n    Gradient checkpointing helper.\n\n    NOTE: This repository is arranged for *sampling/inference*. CLAMP/LatentCLAMP\n    rely on torch.func (functorch) transforms (vjp/jvp). Custom autograd.Function\n    checkpoint implementations are not compatible with these transforms unless\n    they implement `setup_context`. The original guided-diffusion checkpoint\n    helper therefore breaks under torch.func.vjp/jvp.\n\n    For simplicity and robustness we DISABLE checkpointing here and always run\n    the function normally. This has no effect on correctness for inference.\n    """\n    return func(*inputs)\n\n\nclass CheckpointFunction(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, run_function, length, *args):\n        ctx.run_function = run_function\n        ctx.input_tensors = list(args[:length])\n        ctx.input_params = list(args[length:])\n\n        with torch.no_grad():\n            output_tensors = ctx.run_function(*ctx.input_tensors)\n        return output_tensors\n\n    @staticmethod\n    def backward(ctx, *output_grads):\n        ctx.input_tensors = [x.detach().requires_grad_(True) for x in ctx.input_tensors]\n        with torch.enable_grad():\n            # Fixes a bug where the first op in run_function modifies the\n            # Tensor storage in place, which is not allowed for detach()\'d\n            # Tensors.\n            shallow_copies = [x.view_as(x) for x in ctx.input_tensors]\n            output_tensors = ctx.run_function(*shallow_copies)\n        input_grads = torch.autograd.grad(\n            output_tensors,\n            ctx.input_tensors + ctx.input_params,\n            output_grads,\n            allow_unused=True,\n        )\n        # NOTE: Do NOT delete ctx.input_tensors/params.\n        # CLAMP/torch.func.vjp may call backward multiple times on a retained graph.\n        return (None, None) + input_grads\n\n\ndef timestep_embedding(timesteps, dim, max_period=10000, repeat_only=False):\n    """\n    Create sinusoidal timestep embeddings.\n    :param timesteps: a 1-D Tensor of N indices, one per batch element.\n                      These may be fractional.\n    :param dim: the dimension of the output.\n    :param max_period: controls the minimum frequency of the embeddings.\n    :return: an [N x dim] Tensor of positional embeddings.\n    """\n    if not repeat_only:\n        half = dim // 2\n        freqs = torch.exp(\n            -math.log(max_period) * torch.arange(start=0, end=half, dtype=torch.float32) / half\n        ).to(device=timesteps.device)\n        args = timesteps[:, None].float() * freqs[None]\n        embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n        if dim % 2:\n            embedding = torch.cat([embedding, torch.zeros_like(embedding[:, :1])], dim=-1)\n    else:\n        embedding = repeat(timesteps, \'b -> b d\', d=dim)\n    return embedding\n\n\ndef zero_module(module):\n    """\n    Zero out the parameters of a module and return it.\n    """\n    for p in module.parameters():\n        p.detach().zero_()\n    return module\n\n\ndef scale_module(module, scale):\n    """\n    Scale the parameters of a module and return it.\n    """\n    for p in module.parameters():\n        p.detach().mul_(scale)\n    return module\n\n\ndef mean_flat(tensor):\n    """\n    Take the mean over all non-batch dimensions.\n    """\n    return tensor.mean(dim=list(range(1, len(tensor.shape))))\n\n\ndef normalization(channels):\n    """\n    Make a standard normalization layer.\n    :param channels: number of input channels.\n    :return: an nn.Module for normalization.\n    """\n    return GroupNorm32(32, channels)\n\n\n# PyTorch 1.7 has SiLU, but we support PyTorch 1.5.\nclass SiLU(nn.Module):\n    def forward(self, x):\n        return x * torch.sigmoid(x)\n\n\nclass GroupNorm32(nn.GroupNorm):\n    def forward(self, x):\n        return super().forward(x.float()).type(x.dtype)\n\ndef conv_nd(dims, *args, **kwargs):\n    """\n    Create a 1D, 2D, or 3D convolution module.\n    """\n    if dims == 1:\n        return nn.Conv1d(*args, **kwargs)\n    elif dims == 2:\n        return nn.Conv2d(*args, **kwargs)\n    elif dims == 3:\n        return nn.Conv3d(*args, **kwargs)\n    raise ValueError(f"unsupported dimensions: {dims}")\n\n\ndef linear(*args, **kwargs):\n    """\n    Create a linear module.\n    """\n    return nn.Linear(*args, **kwargs)\n\n\ndef avg_pool_nd(dims, *args, **kwargs):\n    """\n    Create a 1D, 2D, or 3D average pooling module.\n    """\n    if dims == 1:\n        return nn.AvgPool1d(*args, **kwargs)\n    elif dims == 2:\n        return nn.AvgPool2d(*args, **kwargs)\n    elif dims == 3:\n        return nn.AvgPool3d(*args, **kwargs)\n    raise ValueError(f"unsupported dimensions: {dims}")\n\n\nclass HybridConditioner(nn.Module):\n\n    def __init__(self, c_concat_config, c_crossattn_config):\n        super().__init__()\n        self.concat_conditioner = instantiate_from_config(c_concat_config)\n        self.crossattn_conditioner = instantiate_from_config(c_crossattn_config)\n\n    def forward(self, c_concat, c_crossattn):\n        c_concat = self.concat_conditioner(c_concat)\n        c_crossattn = self.crossattn_conditioner(c_crossattn)\n        return {\'c_concat\': [c_concat], \'c_crossattn\': [c_crossattn]}\n\n\ndef noise_like(shape, device, repeat=False):\n    repeat_noise = lambda: torch.randn((1, *shape[1:]), device=device).repeat(shape[0], *((1,) * (len(shape) - 1)))\n    noise = lambda: torch.randn(shape, device=device)\n    return repeat_noise() if repeat else noise()',
    'model.ldm.modules.distributions': '',
    'model.ldm.modules.distributions.distributions': 'import torch\nimport numpy as np\n\n\nclass AbstractDistribution:\n    def sample(self):\n        raise NotImplementedError()\n\n    def mode(self):\n        raise NotImplementedError()\n\n\nclass DiracDistribution(AbstractDistribution):\n    def __init__(self, value):\n        self.value = value\n\n    def sample(self):\n        return self.value\n\n    def mode(self):\n        return self.value\n\n\nclass DiagonalGaussianDistribution(object):\n    def __init__(self, parameters, deterministic=False):\n        self.parameters = parameters\n        self.mean, self.logvar = torch.chunk(parameters, 2, dim=1)\n        self.logvar = torch.clamp(self.logvar, -30.0, 20.0)\n        self.deterministic = deterministic\n        self.std = torch.exp(0.5 * self.logvar)\n        self.var = torch.exp(self.logvar)\n        if self.deterministic:\n            self.var = self.std = torch.zeros_like(self.mean).to(device=self.parameters.device)\n\n    def sample(self):\n        x = self.mean + self.std * torch.randn(self.mean.shape).to(device=self.parameters.device)\n        return x\n\n    def kl(self, other=None):\n        if self.deterministic:\n            return torch.Tensor([0.])\n        else:\n            if other is None:\n                return 0.5 * torch.sum(torch.pow(self.mean, 2)\n                                       + self.var - 1.0 - self.logvar,\n                                       dim=[1, 2, 3])\n            else:\n                return 0.5 * torch.sum(\n                    torch.pow(self.mean - other.mean, 2) / other.var\n                    + self.var / other.var - 1.0 - self.logvar + other.logvar,\n                    dim=[1, 2, 3])\n\n    def nll(self, sample, dims=[1,2,3]):\n        if self.deterministic:\n            return torch.Tensor([0.])\n        logtwopi = np.log(2.0 * np.pi)\n        return 0.5 * torch.sum(\n            logtwopi + self.logvar + torch.pow(sample - self.mean, 2) / self.var,\n            dim=dims)\n\n    def mode(self):\n        return self.mean\n\n\ndef normal_kl(mean1, logvar1, mean2, logvar2):\n    """\n    source: https://github.com/openai/guided-diffusion/blob/27c20a8fab9cb472df5d6bdd6c8d11c8f430b924/guided_diffusion/losses.py#L12\n    Compute the KL divergence between two gaussians.\n    Shapes are automatically broadcasted, so batches can be compared to\n    scalars, among other use cases.\n    """\n    tensor = None\n    for obj in (mean1, logvar1, mean2, logvar2):\n        if isinstance(obj, torch.Tensor):\n            tensor = obj\n            break\n    assert tensor is not None, "at least one argument must be a Tensor"\n\n    # Force variances to be Tensors. Broadcasting helps convert scalars to\n    # Tensors, but it does not work for torch.exp().\n    logvar1, logvar2 = [\n        x if isinstance(x, torch.Tensor) else torch.tensor(x).to(tensor)\n        for x in (logvar1, logvar2)\n    ]\n\n    return 0.5 * (\n        -1.0\n        + logvar2\n        - logvar1\n        + torch.exp(logvar1 - logvar2)\n        + ((mean1 - mean2) ** 2) * torch.exp(-logvar2)\n    )\n',
    'model.ldm.modules.ema': 'import torch\nfrom torch import nn\n\n\nclass LitEma(nn.Module):\n    def __init__(self, model, decay=0.9999, use_num_upates=True):\n        super().__init__()\n        if decay < 0.0 or decay > 1.0:\n            raise ValueError(\'Decay must be between 0 and 1\')\n\n        self.m_name2s_name = {}\n        self.register_buffer(\'decay\', torch.tensor(decay, dtype=torch.float32))\n        self.register_buffer(\'num_updates\', torch.tensor(0,dtype=torch.int) if use_num_upates\n                             else torch.tensor(-1,dtype=torch.int))\n\n        for name, p in model.named_parameters():\n            if p.requires_grad:\n                #remove as \'.\'-character is not allowed in buffers\n                s_name = name.replace(\'.\',\'\')\n                self.m_name2s_name.update({name:s_name})\n                self.register_buffer(s_name,p.clone().detach().data)\n\n        self.collected_params = []\n\n    def forward(self,model):\n        decay = self.decay\n\n        if self.num_updates >= 0:\n            self.num_updates += 1\n            decay = min(self.decay,(1 + self.num_updates) / (10 + self.num_updates))\n\n        one_minus_decay = 1.0 - decay\n\n        with torch.no_grad():\n            m_param = dict(model.named_parameters())\n            shadow_params = dict(self.named_buffers())\n\n            for key in m_param:\n                if m_param[key].requires_grad:\n                    sname = self.m_name2s_name[key]\n                    shadow_params[sname] = shadow_params[sname].type_as(m_param[key])\n                    shadow_params[sname].sub_(one_minus_decay * (shadow_params[sname] - m_param[key]))\n                else:\n                    assert not key in self.m_name2s_name\n\n    def copy_to(self, model):\n        m_param = dict(model.named_parameters())\n        shadow_params = dict(self.named_buffers())\n        for key in m_param:\n            if m_param[key].requires_grad:\n                m_param[key].data.copy_(shadow_params[self.m_name2s_name[key]].data)\n            else:\n                assert not key in self.m_name2s_name\n\n    def store(self, parameters):\n        """\n        Save the current parameters for restoring later.\n        Args:\n          parameters: Iterable of `torch.nn.Parameter`; the parameters to be\n            temporarily stored.\n        """\n        self.collected_params = [param.clone() for param in parameters]\n\n    def restore(self, parameters):\n        """\n        Restore the parameters stored with the `store` method.\n        Useful to validate the model with EMA parameters without affecting the\n        original optimization process. Store the parameters before the\n        `copy_to` method. After validation (or model saving), use this to\n        restore the former parameters.\n        Args:\n          parameters: Iterable of `torch.nn.Parameter`; the parameters to be\n            updated with the stored parameters.\n        """\n        for c_param, param in zip(self.collected_params, parameters):\n            param.data.copy_(c_param.data)\n',
    'model.ldm.modules.encoders': '',
    'model.ldm.modules.encoders.modules': 'import torch\nimport torch.nn as nn\nfrom functools import partial\nimport clip\nfrom einops import rearrange, repeat\nimport kornia\n\n\nfrom model.ldm.modules.x_transformer import Encoder, TransformerWrapper  # TODO: can we directly rely on lucidrains code and simply add this as a reuirement? --> test\n\n\nclass AbstractEncoder(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n    def encode(self, *args, **kwargs):\n        raise NotImplementedError\n\n\n\nclass ClassEmbedder(nn.Module):\n    def __init__(self, embed_dim, n_classes=1000, key=\'class\'):\n        super().__init__()\n        self.key = key\n        self.embedding = nn.Embedding(n_classes, embed_dim)\n\n    def forward(self, batch, key=None):\n        if key is None:\n            key = self.key\n        # this is for use in crossattn\n        c = batch[key][:, None]\n        c = self.embedding(c)\n        return c\n\n\nclass TransformerEmbedder(AbstractEncoder):\n    """Some transformer encoder layers"""\n    def __init__(self, n_embed, n_layer, vocab_size, max_seq_len=77, device="cuda"):\n        super().__init__()\n        self.device = device\n        self.transformer = TransformerWrapper(num_tokens=vocab_size, max_seq_len=max_seq_len,\n                                              attn_layers=Encoder(dim=n_embed, depth=n_layer))\n\n    def forward(self, tokens):\n        tokens = tokens.to(self.device)  # meh\n        z = self.transformer(tokens, return_embeddings=True)\n        return z\n\n    def encode(self, x):\n        return self(x)\n\n\nclass BERTTokenizer(AbstractEncoder):\n    """ Uses a pretrained BERT tokenizer by huggingface. Vocab size: 30522 (?)"""\n    def __init__(self, device="cuda", vq_interface=True, max_length=77):\n        super().__init__()\n        from transformers import BertTokenizerFast  # TODO: add to reuquirements\n        self.tokenizer = BertTokenizerFast.from_pretrained("bert-base-uncased")\n        self.device = device\n        self.vq_interface = vq_interface\n        self.max_length = max_length\n\n    def forward(self, text):\n        batch_encoding = self.tokenizer(text, truncation=True, max_length=self.max_length, return_length=True,\n                                        return_overflowing_tokens=False, padding="max_length", return_tensors="pt")\n        tokens = batch_encoding["input_ids"].to(self.device)\n        return tokens\n\n    @torch.no_grad()\n    def encode(self, text):\n        tokens = self(text)\n        if not self.vq_interface:\n            return tokens\n        return None, None, [None, None, tokens]\n\n    def decode(self, text):\n        return text\n\n\nclass BERTEmbedder(AbstractEncoder):\n    """Uses the BERT tokenizr model and add some transformer encoder layers"""\n    def __init__(self, n_embed, n_layer, vocab_size=30522, max_seq_len=77,\n                 device="cuda",use_tokenizer=True, embedding_dropout=0.0):\n        super().__init__()\n        self.use_tknz_fn = use_tokenizer\n        if self.use_tknz_fn:\n            self.tknz_fn = BERTTokenizer(vq_interface=False, max_length=max_seq_len)\n        self.device = device\n        self.transformer = TransformerWrapper(num_tokens=vocab_size, max_seq_len=max_seq_len,\n                                              attn_layers=Encoder(dim=n_embed, depth=n_layer),\n                                              emb_dropout=embedding_dropout)\n\n    def forward(self, text):\n        if self.use_tknz_fn:\n            tokens = self.tknz_fn(text)#.to(self.device)\n        else:\n            tokens = text\n        z = self.transformer(tokens, return_embeddings=True)\n        return z\n\n    def encode(self, text):\n        # output of length 77\n        return self(text)\n\n\nclass SpatialRescaler(nn.Module):\n    def __init__(self,\n                 n_stages=1,\n                 method=\'bilinear\',\n                 multiplier=0.5,\n                 in_channels=3,\n                 out_channels=None,\n                 bias=False):\n        super().__init__()\n        self.n_stages = n_stages\n        assert self.n_stages >= 0\n        assert method in [\'nearest\',\'linear\',\'bilinear\',\'trilinear\',\'bicubic\',\'area\']\n        self.multiplier = multiplier\n        self.interpolator = partial(torch.nn.functional.interpolate, mode=method)\n        self.remap_output = out_channels is not None\n        if self.remap_output:\n            print(f\'Spatial Rescaler mapping from {in_channels} to {out_channels} channels after resizing.\')\n            self.channel_mapper = nn.Conv2d(in_channels,out_channels,1,bias=bias)\n\n    def forward(self,x):\n        for stage in range(self.n_stages):\n            x = self.interpolator(x, scale_factor=self.multiplier)\n\n\n        if self.remap_output:\n            x = self.channel_mapper(x)\n        return x\n\n    def encode(self, x):\n        return self(x)\n\n\nclass FrozenCLIPTextEmbedder(nn.Module):\n    """\n    Uses the CLIP transformer encoder for text.\n    """\n    def __init__(self, version=\'ViT-L/14\', device="cuda", max_length=77, n_repeat=1, normalize=True):\n        super().__init__()\n        self.model, _ = clip.load(version, jit=False, device="cpu")\n        self.device = device\n        self.max_length = max_length\n        self.n_repeat = n_repeat\n        self.normalize = normalize\n\n    def freeze(self):\n        self.model = self.model.eval()\n        for param in self.parameters():\n            param.requires_grad = False\n\n    def forward(self, text):\n        tokens = clip.tokenize(text).to(self.device)\n        z = self.model.encode_text(tokens)\n        if self.normalize:\n            z = z / torch.linalg.norm(z, dim=1, keepdim=True)\n        return z\n\n    def encode(self, text):\n        z = self(text)\n        if z.ndim==2:\n            z = z[:, None, :]\n        z = repeat(z, \'b 1 d -> b k d\', k=self.n_repeat)\n        return z\n\n\nclass FrozenClipImageEmbedder(nn.Module):\n    """\n        Uses the CLIP image encoder.\n        """\n    def __init__(\n            self,\n            model,\n            jit=False,\n            device=\'cuda\' if torch.cuda.is_available() else \'cpu\',\n            antialias=False,\n        ):\n        super().__init__()\n        self.model, _ = clip.load(name=model, device=device, jit=jit)\n\n        self.antialias = antialias\n\n        self.register_buffer(\'mean\', torch.Tensor([0.48145466, 0.4578275, 0.40821073]), persistent=False)\n        self.register_buffer(\'std\', torch.Tensor([0.26862954, 0.26130258, 0.27577711]), persistent=False)\n\n    def preprocess(self, x):\n        # normalize to [0,1]\n        x = kornia.geometry.resize(x, (224, 224),\n                                   interpolation=\'bicubic\',align_corners=True,\n                                   antialias=self.antialias)\n        x = (x + 1.) / 2.\n        # renormalize according to clip\n        x = kornia.enhance.normalize(x, self.mean, self.std)\n        return x\n\n    def forward(self, x):\n        # x is assumed to be in range [-1,1]\n        return self.model.encode_image(self.preprocess(x))\n\n',
    'model.ldm.modules.image_degradation': 'from model.ldm.modules.image_degradation.bsrgan import degradation_bsrgan_variant as degradation_fn_bsr\nfrom model.ldm.modules.image_degradation.bsrgan_light import degradation_bsrgan_variant as degradation_fn_bsr_light\n',
    'model.ldm.modules.image_degradation.bsrgan': '# -*- coding: utf-8 -*-\n"""\n# --------------------------------------------\n# Super-Resolution\n# --------------------------------------------\n#\n# Kai Zhang (cskaizhang@gmail.com)\n# https://github.com/cszn\n# From 2019/03--2021/08\n# --------------------------------------------\n"""\n\nimport numpy as np\nimport cv2\nimport torch\n\nfrom functools import partial\nimport random\nfrom scipy import ndimage\nimport scipy\nimport scipy.stats as ss\nfrom scipy.interpolate import interp2d\nfrom scipy.linalg import orth\nimport albumentations\n\nimport ldm.modules.image_degradation.utils_image as util\n\n\ndef modcrop_np(img, sf):\n    \'\'\'\n    Args:\n        img: numpy image, WxH or WxHxC\n        sf: scale factor\n    Return:\n        cropped image\n    \'\'\'\n    w, h = img.shape[:2]\n    im = np.copy(img)\n    return im[:w - w % sf, :h - h % sf, ...]\n\n\n"""\n# --------------------------------------------\n# anisotropic Gaussian kernels\n# --------------------------------------------\n"""\n\n\ndef analytic_kernel(k):\n    """Calculate the X4 kernel from the X2 kernel (for proof see appendix in paper)"""\n    k_size = k.shape[0]\n    # Calculate the big kernels size\n    big_k = np.zeros((3 * k_size - 2, 3 * k_size - 2))\n    # Loop over the small kernel to fill the big one\n    for r in range(k_size):\n        for c in range(k_size):\n            big_k[2 * r:2 * r + k_size, 2 * c:2 * c + k_size] += k[r, c] * k\n    # Crop the edges of the big kernel to ignore very small values and increase run time of SR\n    crop = k_size // 2\n    cropped_big_k = big_k[crop:-crop, crop:-crop]\n    # Normalize to 1\n    return cropped_big_k / cropped_big_k.sum()\n\n\ndef anisotropic_Gaussian(ksize=15, theta=np.pi, l1=6, l2=6):\n    """ generate an anisotropic Gaussian kernel\n    Args:\n        ksize : e.g., 15, kernel size\n        theta : [0,  pi], rotation angle range\n        l1    : [0.1,50], scaling of eigenvalues\n        l2    : [0.1,l1], scaling of eigenvalues\n        If l1 = l2, will get an isotropic Gaussian kernel.\n    Returns:\n        k     : kernel\n    """\n\n    v = np.dot(np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]]), np.array([1., 0.]))\n    V = np.array([[v[0], v[1]], [v[1], -v[0]]])\n    D = np.array([[l1, 0], [0, l2]])\n    Sigma = np.dot(np.dot(V, D), np.linalg.inv(V))\n    k = gm_blur_kernel(mean=[0, 0], cov=Sigma, size=ksize)\n\n    return k\n\n\ndef gm_blur_kernel(mean, cov, size=15):\n    center = size / 2.0 + 0.5\n    k = np.zeros([size, size])\n    for y in range(size):\n        for x in range(size):\n            cy = y - center + 1\n            cx = x - center + 1\n            k[y, x] = ss.multivariate_normal.pdf([cx, cy], mean=mean, cov=cov)\n\n    k = k / np.sum(k)\n    return k\n\n\ndef shift_pixel(x, sf, upper_left=True):\n    """shift pixel for super-resolution with different scale factors\n    Args:\n        x: WxHxC or WxH\n        sf: scale factor\n        upper_left: shift direction\n    """\n    h, w = x.shape[:2]\n    shift = (sf - 1) * 0.5\n    xv, yv = np.arange(0, w, 1.0), np.arange(0, h, 1.0)\n    if upper_left:\n        x1 = xv + shift\n        y1 = yv + shift\n    else:\n        x1 = xv - shift\n        y1 = yv - shift\n\n    x1 = np.clip(x1, 0, w - 1)\n    y1 = np.clip(y1, 0, h - 1)\n\n    if x.ndim == 2:\n        x = interp2d(xv, yv, x)(x1, y1)\n    if x.ndim == 3:\n        for i in range(x.shape[-1]):\n            x[:, :, i] = interp2d(xv, yv, x[:, :, i])(x1, y1)\n\n    return x\n\n\ndef blur(x, k):\n    \'\'\'\n    x: image, NxcxHxW\n    k: kernel, Nx1xhxw\n    \'\'\'\n    n, c = x.shape[:2]\n    p1, p2 = (k.shape[-2] - 1) // 2, (k.shape[-1] - 1) // 2\n    x = torch.nn.functional.pad(x, pad=(p1, p2, p1, p2), mode=\'replicate\')\n    k = k.repeat(1, c, 1, 1)\n    k = k.view(-1, 1, k.shape[2], k.shape[3])\n    x = x.view(1, -1, x.shape[2], x.shape[3])\n    x = torch.nn.functional.conv2d(x, k, bias=None, stride=1, padding=0, groups=n * c)\n    x = x.view(n, c, x.shape[2], x.shape[3])\n\n    return x\n\n\ndef gen_kernel(k_size=np.array([15, 15]), scale_factor=np.array([4, 4]), min_var=0.6, max_var=10., noise_level=0):\n    """"\n    # modified version of https://github.com/assafshocher/BlindSR_dataset_generator\n    # Kai Zhang\n    # min_var = 0.175 * sf  # variance of the gaussian kernel will be sampled between min_var and max_var\n    # max_var = 2.5 * sf\n    """\n    # Set random eigen-vals (lambdas) and angle (theta) for COV matrix\n    lambda_1 = min_var + np.random.rand() * (max_var - min_var)\n    lambda_2 = min_var + np.random.rand() * (max_var - min_var)\n    theta = np.random.rand() * np.pi  # random theta\n    noise = -noise_level + np.random.rand(*k_size) * noise_level * 2\n\n    # Set COV matrix using Lambdas and Theta\n    LAMBDA = np.diag([lambda_1, lambda_2])\n    Q = np.array([[np.cos(theta), -np.sin(theta)],\n                  [np.sin(theta), np.cos(theta)]])\n    SIGMA = Q @ LAMBDA @ Q.T\n    INV_SIGMA = np.linalg.inv(SIGMA)[None, None, :, :]\n\n    # Set expectation position (shifting kernel for aligned image)\n    MU = k_size // 2 - 0.5 * (scale_factor - 1)  # - 0.5 * (scale_factor - k_size % 2)\n    MU = MU[None, None, :, None]\n\n    # Create meshgrid for Gaussian\n    [X, Y] = np.meshgrid(range(k_size[0]), range(k_size[1]))\n    Z = np.stack([X, Y], 2)[:, :, :, None]\n\n    # Calcualte Gaussian for every pixel of the kernel\n    ZZ = Z - MU\n    ZZ_t = ZZ.transpose(0, 1, 3, 2)\n    raw_kernel = np.exp(-0.5 * np.squeeze(ZZ_t @ INV_SIGMA @ ZZ)) * (1 + noise)\n\n    # shift the kernel so it will be centered\n    # raw_kernel_centered = kernel_shift(raw_kernel, scale_factor)\n\n    # Normalize the kernel and return\n    # kernel = raw_kernel_centered / np.sum(raw_kernel_centered)\n    kernel = raw_kernel / np.sum(raw_kernel)\n    return kernel\n\n\ndef fspecial_gaussian(hsize, sigma):\n    hsize = [hsize, hsize]\n    siz = [(hsize[0] - 1.0) / 2.0, (hsize[1] - 1.0) / 2.0]\n    std = sigma\n    [x, y] = np.meshgrid(np.arange(-siz[1], siz[1] + 1), np.arange(-siz[0], siz[0] + 1))\n    arg = -(x * x + y * y) / (2 * std * std)\n    h = np.exp(arg)\n    h[h < scipy.finfo(float).eps * h.max()] = 0\n    sumh = h.sum()\n    if sumh != 0:\n        h = h / sumh\n    return h\n\n\ndef fspecial_laplacian(alpha):\n    alpha = max([0, min([alpha, 1])])\n    h1 = alpha / (alpha + 1)\n    h2 = (1 - alpha) / (alpha + 1)\n    h = [[h1, h2, h1], [h2, -4 / (alpha + 1), h2], [h1, h2, h1]]\n    h = np.array(h)\n    return h\n\n\ndef fspecial(filter_type, *args, **kwargs):\n    \'\'\'\n    python code from:\n    https://github.com/ronaldosena/imagens-medicas-2/blob/40171a6c259edec7827a6693a93955de2bd39e76/Aulas/aula_2_-_uniform_filter/matlab_fspecial.py\n    \'\'\'\n    if filter_type == \'gaussian\':\n        return fspecial_gaussian(*args, **kwargs)\n    if filter_type == \'laplacian\':\n        return fspecial_laplacian(*args, **kwargs)\n\n\n"""\n# --------------------------------------------\n# degradation models\n# --------------------------------------------\n"""\n\n\ndef bicubic_degradation(x, sf=3):\n    \'\'\'\n    Args:\n        x: HxWxC image, [0, 1]\n        sf: down-scale factor\n    Return:\n        bicubicly downsampled LR image\n    \'\'\'\n    x = util.imresize_np(x, scale=1 / sf)\n    return x\n\n\ndef srmd_degradation(x, k, sf=3):\n    \'\'\' blur + bicubic downsampling\n    Args:\n        x: HxWxC image, [0, 1]\n        k: hxw, double\n        sf: down-scale factor\n    Return:\n        downsampled LR image\n    Reference:\n        @inproceedings{zhang2018learning,\n          title={Learning a single convolutional super-resolution network for multiple degradations},\n          author={Zhang, Kai and Zuo, Wangmeng and Zhang, Lei},\n          booktitle={IEEE Conference on Computer Vision and Pattern Recognition},\n          pages={3262--3271},\n          year={2018}\n        }\n    \'\'\'\n    x = ndimage.filters.convolve(x, np.expand_dims(k, axis=2), mode=\'wrap\')  # \'nearest\' | \'mirror\'\n    x = bicubic_degradation(x, sf=sf)\n    return x\n\n\ndef dpsr_degradation(x, k, sf=3):\n    \'\'\' bicubic downsampling + blur\n    Args:\n        x: HxWxC image, [0, 1]\n        k: hxw, double\n        sf: down-scale factor\n    Return:\n        downsampled LR image\n    Reference:\n        @inproceedings{zhang2019deep,\n          title={Deep Plug-and-Play Super-Resolution for Arbitrary Blur Kernels},\n          author={Zhang, Kai and Zuo, Wangmeng and Zhang, Lei},\n          booktitle={IEEE Conference on Computer Vision and Pattern Recognition},\n          pages={1671--1681},\n          year={2019}\n        }\n    \'\'\'\n    x = bicubic_degradation(x, sf=sf)\n    x = ndimage.filters.convolve(x, np.expand_dims(k, axis=2), mode=\'wrap\')\n    return x\n\n\ndef classical_degradation(x, k, sf=3):\n    \'\'\' blur + downsampling\n    Args:\n        x: HxWxC image, [0, 1]/[0, 255]\n        k: hxw, double\n        sf: down-scale factor\n    Return:\n        downsampled LR image\n    \'\'\'\n    x = ndimage.filters.convolve(x, np.expand_dims(k, axis=2), mode=\'wrap\')\n    # x = filters.correlate(x, np.expand_dims(np.flip(k), axis=2))\n    st = 0\n    return x[st::sf, st::sf, ...]\n\n\ndef add_sharpening(img, weight=0.5, radius=50, threshold=10):\n    """USM sharpening. borrowed from real-ESRGAN\n    Input image: I; Blurry image: B.\n    1. K = I + weight * (I - B)\n    2. Mask = 1 if abs(I - B) > threshold, else: 0\n    3. Blur mask:\n    4. Out = Mask * K + (1 - Mask) * I\n    Args:\n        img (Numpy array): Input image, HWC, BGR; float32, [0, 1].\n        weight (float): Sharp weight. Default: 1.\n        radius (float): Kernel size of Gaussian blur. Default: 50.\n        threshold (int):\n    """\n    if radius % 2 == 0:\n        radius += 1\n    blur = cv2.GaussianBlur(img, (radius, radius), 0)\n    residual = img - blur\n    mask = np.abs(residual) * 255 > threshold\n    mask = mask.astype(\'float32\')\n    soft_mask = cv2.GaussianBlur(mask, (radius, radius), 0)\n\n    K = img + weight * residual\n    K = np.clip(K, 0, 1)\n    return soft_mask * K + (1 - soft_mask) * img\n\n\ndef add_blur(img, sf=4):\n    wd2 = 4.0 + sf\n    wd = 2.0 + 0.2 * sf\n    if random.random() < 0.5:\n        l1 = wd2 * random.random()\n        l2 = wd2 * random.random()\n        k = anisotropic_Gaussian(ksize=2 * random.randint(2, 11) + 3, theta=random.random() * np.pi, l1=l1, l2=l2)\n    else:\n        k = fspecial(\'gaussian\', 2 * random.randint(2, 11) + 3, wd * random.random())\n    img = ndimage.filters.convolve(img, np.expand_dims(k, axis=2), mode=\'mirror\')\n\n    return img\n\n\ndef add_resize(img, sf=4):\n    rnum = np.random.rand()\n    if rnum > 0.8:  # up\n        sf1 = random.uniform(1, 2)\n    elif rnum < 0.7:  # down\n        sf1 = random.uniform(0.5 / sf, 1)\n    else:\n        sf1 = 1.0\n    img = cv2.resize(img, (int(sf1 * img.shape[1]), int(sf1 * img.shape[0])), interpolation=random.choice([1, 2, 3]))\n    img = np.clip(img, 0.0, 1.0)\n\n    return img\n\n\n# def add_Gaussian_noise(img, noise_level1=2, noise_level2=25):\n#     noise_level = random.randint(noise_level1, noise_level2)\n#     rnum = np.random.rand()\n#     if rnum > 0.6:  # add color Gaussian noise\n#         img += np.random.normal(0, noise_level / 255.0, img.shape).astype(np.float32)\n#     elif rnum < 0.4:  # add grayscale Gaussian noise\n#         img += np.random.normal(0, noise_level / 255.0, (*img.shape[:2], 1)).astype(np.float32)\n#     else:  # add  noise\n#         L = noise_level2 / 255.\n#         D = np.diag(np.random.rand(3))\n#         U = orth(np.random.rand(3, 3))\n#         conv = np.dot(np.dot(np.transpose(U), D), U)\n#         img += np.random.multivariate_normal([0, 0, 0], np.abs(L ** 2 * conv), img.shape[:2]).astype(np.float32)\n#     img = np.clip(img, 0.0, 1.0)\n#     return img\n\ndef add_Gaussian_noise(img, noise_level1=2, noise_level2=25):\n    noise_level = random.randint(noise_level1, noise_level2)\n    rnum = np.random.rand()\n    if rnum > 0.6:  # add color Gaussian noise\n        img = img + np.random.normal(0, noise_level / 255.0, img.shape).astype(np.float32)\n    elif rnum < 0.4:  # add grayscale Gaussian noise\n        img = img + np.random.normal(0, noise_level / 255.0, (*img.shape[:2], 1)).astype(np.float32)\n    else:  # add  noise\n        L = noise_level2 / 255.\n        D = np.diag(np.random.rand(3))\n        U = orth(np.random.rand(3, 3))\n        conv = np.dot(np.dot(np.transpose(U), D), U)\n        img = img + np.random.multivariate_normal([0, 0, 0], np.abs(L ** 2 * conv), img.shape[:2]).astype(np.float32)\n    img = np.clip(img, 0.0, 1.0)\n    return img\n\n\ndef add_speckle_noise(img, noise_level1=2, noise_level2=25):\n    noise_level = random.randint(noise_level1, noise_level2)\n    img = np.clip(img, 0.0, 1.0)\n    rnum = random.random()\n    if rnum > 0.6:\n        img += img * np.random.normal(0, noise_level / 255.0, img.shape).astype(np.float32)\n    elif rnum < 0.4:\n        img += img * np.random.normal(0, noise_level / 255.0, (*img.shape[:2], 1)).astype(np.float32)\n    else:\n        L = noise_level2 / 255.\n        D = np.diag(np.random.rand(3))\n        U = orth(np.random.rand(3, 3))\n        conv = np.dot(np.dot(np.transpose(U), D), U)\n        img += img * np.random.multivariate_normal([0, 0, 0], np.abs(L ** 2 * conv), img.shape[:2]).astype(np.float32)\n    img = np.clip(img, 0.0, 1.0)\n    return img\n\n\ndef add_Poisson_noise(img):\n    img = np.clip((img * 255.0).round(), 0, 255) / 255.\n    vals = 10 ** (2 * random.random() + 2.0)  # [2, 4]\n    if random.random() < 0.5:\n        img = np.random.poisson(img * vals).astype(np.float32) / vals\n    else:\n        img_gray = np.dot(img[..., :3], [0.299, 0.587, 0.114])\n        img_gray = np.clip((img_gray * 255.0).round(), 0, 255) / 255.\n        noise_gray = np.random.poisson(img_gray * vals).astype(np.float32) / vals - img_gray\n        img += noise_gray[:, :, np.newaxis]\n    img = np.clip(img, 0.0, 1.0)\n    return img\n\n\ndef add_JPEG_noise(img):\n    quality_factor = random.randint(30, 95)\n    img = cv2.cvtColor(util.single2uint(img), cv2.COLOR_RGB2BGR)\n    result, encimg = cv2.imencode(\'.jpg\', img, [int(cv2.IMWRITE_JPEG_QUALITY), quality_factor])\n    img = cv2.imdecode(encimg, 1)\n    img = cv2.cvtColor(util.uint2single(img), cv2.COLOR_BGR2RGB)\n    return img\n\n\ndef random_crop(lq, hq, sf=4, lq_patchsize=64):\n    h, w = lq.shape[:2]\n    rnd_h = random.randint(0, h - lq_patchsize)\n    rnd_w = random.randint(0, w - lq_patchsize)\n    lq = lq[rnd_h:rnd_h + lq_patchsize, rnd_w:rnd_w + lq_patchsize, :]\n\n    rnd_h_H, rnd_w_H = int(rnd_h * sf), int(rnd_w * sf)\n    hq = hq[rnd_h_H:rnd_h_H + lq_patchsize * sf, rnd_w_H:rnd_w_H + lq_patchsize * sf, :]\n    return lq, hq\n\n\ndef degradation_bsrgan(img, sf=4, lq_patchsize=72, isp_model=None):\n    """\n    This is the degradation model of BSRGAN from the paper\n    "Designing a Practical Degradation Model for Deep Blind Image Super-Resolution"\n    ----------\n    img: HXWXC, [0, 1], its size should be large than (lq_patchsizexsf)x(lq_patchsizexsf)\n    sf: scale factor\n    isp_model: camera ISP model\n    Returns\n    -------\n    img: low-quality patch, size: lq_patchsizeXlq_patchsizeXC, range: [0, 1]\n    hq: corresponding high-quality patch, size: (lq_patchsizexsf)X(lq_patchsizexsf)XC, range: [0, 1]\n    """\n    isp_prob, jpeg_prob, scale2_prob = 0.25, 0.9, 0.25\n    sf_ori = sf\n\n    h1, w1 = img.shape[:2]\n    img = img.copy()[:w1 - w1 % sf, :h1 - h1 % sf, ...]  # mod crop\n    h, w = img.shape[:2]\n\n    if h < lq_patchsize * sf or w < lq_patchsize * sf:\n        raise ValueError(f\'img size ({h1}X{w1}) is too small!\')\n\n    hq = img.copy()\n\n    if sf == 4 and random.random() < scale2_prob:  # downsample1\n        if np.random.rand() < 0.5:\n            img = cv2.resize(img, (int(1 / 2 * img.shape[1]), int(1 / 2 * img.shape[0])),\n                             interpolation=random.choice([1, 2, 3]))\n        else:\n            img = util.imresize_np(img, 1 / 2, True)\n        img = np.clip(img, 0.0, 1.0)\n        sf = 2\n\n    shuffle_order = random.sample(range(7), 7)\n    idx1, idx2 = shuffle_order.index(2), shuffle_order.index(3)\n    if idx1 > idx2:  # keep downsample3 last\n        shuffle_order[idx1], shuffle_order[idx2] = shuffle_order[idx2], shuffle_order[idx1]\n\n    for i in shuffle_order:\n\n        if i == 0:\n            img = add_blur(img, sf=sf)\n\n        elif i == 1:\n            img = add_blur(img, sf=sf)\n\n        elif i == 2:\n            a, b = img.shape[1], img.shape[0]\n            # downsample2\n            if random.random() < 0.75:\n                sf1 = random.uniform(1, 2 * sf)\n                img = cv2.resize(img, (int(1 / sf1 * img.shape[1]), int(1 / sf1 * img.shape[0])),\n                                 interpolation=random.choice([1, 2, 3]))\n            else:\n                k = fspecial(\'gaussian\', 25, random.uniform(0.1, 0.6 * sf))\n                k_shifted = shift_pixel(k, sf)\n                k_shifted = k_shifted / k_shifted.sum()  # blur with shifted kernel\n                img = ndimage.filters.convolve(img, np.expand_dims(k_shifted, axis=2), mode=\'mirror\')\n                img = img[0::sf, 0::sf, ...]  # nearest downsampling\n            img = np.clip(img, 0.0, 1.0)\n\n        elif i == 3:\n            # downsample3\n            img = cv2.resize(img, (int(1 / sf * a), int(1 / sf * b)), interpolation=random.choice([1, 2, 3]))\n            img = np.clip(img, 0.0, 1.0)\n\n        elif i == 4:\n            # add Gaussian noise\n            img = add_Gaussian_noise(img, noise_level1=2, noise_level2=25)\n\n        elif i == 5:\n            # add JPEG noise\n            if random.random() < jpeg_prob:\n                img = add_JPEG_noise(img)\n\n        elif i == 6:\n            # add processed camera sensor noise\n            if random.random() < isp_prob and isp_model is not None:\n                with torch.no_grad():\n                    img, hq = isp_model.forward(img.copy(), hq)\n\n    # add final JPEG compression noise\n    img = add_JPEG_noise(img)\n\n    # random crop\n    img, hq = random_crop(img, hq, sf_ori, lq_patchsize)\n\n    return img, hq\n\n\n# todo no isp_model?\ndef degradation_bsrgan_variant(image, sf=4, isp_model=None):\n    """\n    This is the degradation model of BSRGAN from the paper\n    "Designing a Practical Degradation Model for Deep Blind Image Super-Resolution"\n    ----------\n    sf: scale factor\n    isp_model: camera ISP model\n    Returns\n    -------\n    img: low-quality patch, size: lq_patchsizeXlq_patchsizeXC, range: [0, 1]\n    hq: corresponding high-quality patch, size: (lq_patchsizexsf)X(lq_patchsizexsf)XC, range: [0, 1]\n    """\n    image = util.uint2single(image)\n    isp_prob, jpeg_prob, scale2_prob = 0.25, 0.9, 0.25\n    sf_ori = sf\n\n    h1, w1 = image.shape[:2]\n    image = image.copy()[:w1 - w1 % sf, :h1 - h1 % sf, ...]  # mod crop\n    h, w = image.shape[:2]\n\n    hq = image.copy()\n\n    if sf == 4 and random.random() < scale2_prob:  # downsample1\n        if np.random.rand() < 0.5:\n            image = cv2.resize(image, (int(1 / 2 * image.shape[1]), int(1 / 2 * image.shape[0])),\n                               interpolation=random.choice([1, 2, 3]))\n        else:\n            image = util.imresize_np(image, 1 / 2, True)\n        image = np.clip(image, 0.0, 1.0)\n        sf = 2\n\n    shuffle_order = random.sample(range(7), 7)\n    idx1, idx2 = shuffle_order.index(2), shuffle_order.index(3)\n    if idx1 > idx2:  # keep downsample3 last\n        shuffle_order[idx1], shuffle_order[idx2] = shuffle_order[idx2], shuffle_order[idx1]\n\n    for i in shuffle_order:\n\n        if i == 0:\n            image = add_blur(image, sf=sf)\n\n        elif i == 1:\n            image = add_blur(image, sf=sf)\n\n        elif i == 2:\n            a, b = image.shape[1], image.shape[0]\n            # downsample2\n            if random.random() < 0.75:\n                sf1 = random.uniform(1, 2 * sf)\n                image = cv2.resize(image, (int(1 / sf1 * image.shape[1]), int(1 / sf1 * image.shape[0])),\n                                   interpolation=random.choice([1, 2, 3]))\n            else:\n                k = fspecial(\'gaussian\', 25, random.uniform(0.1, 0.6 * sf))\n                k_shifted = shift_pixel(k, sf)\n                k_shifted = k_shifted / k_shifted.sum()  # blur with shifted kernel\n                image = ndimage.filters.convolve(image, np.expand_dims(k_shifted, axis=2), mode=\'mirror\')\n                image = image[0::sf, 0::sf, ...]  # nearest downsampling\n            image = np.clip(image, 0.0, 1.0)\n\n        elif i == 3:\n            # downsample3\n            image = cv2.resize(image, (int(1 / sf * a), int(1 / sf * b)), interpolation=random.choice([1, 2, 3]))\n            image = np.clip(image, 0.0, 1.0)\n\n        elif i == 4:\n            # add Gaussian noise\n            image = add_Gaussian_noise(image, noise_level1=2, noise_level2=25)\n\n        elif i == 5:\n            # add JPEG noise\n            if random.random() < jpeg_prob:\n                image = add_JPEG_noise(image)\n\n        # elif i == 6:\n        #     # add processed camera sensor noise\n        #     if random.random() < isp_prob and isp_model is not None:\n        #         with torch.no_grad():\n        #             img, hq = isp_model.forward(img.copy(), hq)\n\n    # add final JPEG compression noise\n    image = add_JPEG_noise(image)\n    image = util.single2uint(image)\n    example = {"image":image}\n    return example\n\n\n# TODO incase there is a pickle error one needs to replace a += x with a = a + x in add_speckle_noise etc...\ndef degradation_bsrgan_plus(img, sf=4, shuffle_prob=0.5, use_sharp=True, lq_patchsize=64, isp_model=None):\n    """\n    This is an extended degradation model by combining\n    the degradation models of BSRGAN and Real-ESRGAN\n    ----------\n    img: HXWXC, [0, 1], its size should be large than (lq_patchsizexsf)x(lq_patchsizexsf)\n    sf: scale factor\n    use_shuffle: the degradation shuffle\n    use_sharp: sharpening the img\n    Returns\n    -------\n    img: low-quality patch, size: lq_patchsizeXlq_patchsizeXC, range: [0, 1]\n    hq: corresponding high-quality patch, size: (lq_patchsizexsf)X(lq_patchsizexsf)XC, range: [0, 1]\n    """\n\n    h1, w1 = img.shape[:2]\n    img = img.copy()[:w1 - w1 % sf, :h1 - h1 % sf, ...]  # mod crop\n    h, w = img.shape[:2]\n\n    if h < lq_patchsize * sf or w < lq_patchsize * sf:\n        raise ValueError(f\'img size ({h1}X{w1}) is too small!\')\n\n    if use_sharp:\n        img = add_sharpening(img)\n    hq = img.copy()\n\n    if random.random() < shuffle_prob:\n        shuffle_order = random.sample(range(13), 13)\n    else:\n        shuffle_order = list(range(13))\n        # local shuffle for noise, JPEG is always the last one\n        shuffle_order[2:6] = random.sample(shuffle_order[2:6], len(range(2, 6)))\n        shuffle_order[9:13] = random.sample(shuffle_order[9:13], len(range(9, 13)))\n\n    poisson_prob, speckle_prob, isp_prob = 0.1, 0.1, 0.1\n\n    for i in shuffle_order:\n        if i == 0:\n            img = add_blur(img, sf=sf)\n        elif i == 1:\n            img = add_resize(img, sf=sf)\n        elif i == 2:\n            img = add_Gaussian_noise(img, noise_level1=2, noise_level2=25)\n        elif i == 3:\n            if random.random() < poisson_prob:\n                img = add_Poisson_noise(img)\n        elif i == 4:\n            if random.random() < speckle_prob:\n                img = add_speckle_noise(img)\n        elif i == 5:\n            if random.random() < isp_prob and isp_model is not None:\n                with torch.no_grad():\n                    img, hq = isp_model.forward(img.copy(), hq)\n        elif i == 6:\n            img = add_JPEG_noise(img)\n        elif i == 7:\n            img = add_blur(img, sf=sf)\n        elif i == 8:\n            img = add_resize(img, sf=sf)\n        elif i == 9:\n            img = add_Gaussian_noise(img, noise_level1=2, noise_level2=25)\n        elif i == 10:\n            if random.random() < poisson_prob:\n                img = add_Poisson_noise(img)\n        elif i == 11:\n            if random.random() < speckle_prob:\n                img = add_speckle_noise(img)\n        elif i == 12:\n            if random.random() < isp_prob and isp_model is not None:\n                with torch.no_grad():\n                    img, hq = isp_model.forward(img.copy(), hq)\n        else:\n            print(\'check the shuffle!\')\n\n    # resize to desired size\n    img = cv2.resize(img, (int(1 / sf * hq.shape[1]), int(1 / sf * hq.shape[0])),\n                     interpolation=random.choice([1, 2, 3]))\n\n    # add final JPEG compression noise\n    img = add_JPEG_noise(img)\n\n    # random crop\n    img, hq = random_crop(img, hq, sf, lq_patchsize)\n\n    return img, hq\n\n\nif __name__ == \'__main__\':\n\tprint("hey")\n\timg = util.imread_uint(\'utils/test.png\', 3)\n\tprint(img)\n\timg = util.uint2single(img)\n\tprint(img)\n\timg = img[:448, :448]\n\th = img.shape[0] // 4\n\tprint("resizing to", h)\n\tsf = 4\n\tdeg_fn = partial(degradation_bsrgan_variant, sf=sf)\n\tfor i in range(20):\n\t\tprint(i)\n\t\timg_lq = deg_fn(img)\n\t\tprint(img_lq)\n\t\timg_lq_bicubic = albumentations.SmallestMaxSize(max_size=h, interpolation=cv2.INTER_CUBIC)(image=img)["image"]\n\t\tprint(img_lq.shape)\n\t\tprint("bicubic", img_lq_bicubic.shape)\n\t\tprint(img_hq.shape)\n\t\tlq_nearest = cv2.resize(util.single2uint(img_lq), (int(sf * img_lq.shape[1]), int(sf * img_lq.shape[0])),\n\t\t                        interpolation=0)\n\t\tlq_bicubic_nearest = cv2.resize(util.single2uint(img_lq_bicubic), (int(sf * img_lq.shape[1]), int(sf * img_lq.shape[0])),\n\t\t                        interpolation=0)\n\t\timg_concat = np.concatenate([lq_bicubic_nearest, lq_nearest, util.single2uint(img_hq)], axis=1)\n\t\tutil.imsave(img_concat, str(i) + \'.png\')\n\n\n',
    'model.ldm.modules.image_degradation.bsrgan_light': '# -*- coding: utf-8 -*-\nimport numpy as np\nimport cv2\nimport torch\n\nfrom functools import partial\nimport random\nfrom scipy import ndimage\nimport scipy\nimport scipy.stats as ss\nfrom scipy.interpolate import interp2d\nfrom scipy.linalg import orth\nimport albumentations\n\nimport ldm.modules.image_degradation.utils_image as util\n\n"""\n# --------------------------------------------\n# Super-Resolution\n# --------------------------------------------\n#\n# Kai Zhang (cskaizhang@gmail.com)\n# https://github.com/cszn\n# From 2019/03--2021/08\n# --------------------------------------------\n"""\n\n\ndef modcrop_np(img, sf):\n    \'\'\'\n    Args:\n        img: numpy image, WxH or WxHxC\n        sf: scale factor\n    Return:\n        cropped image\n    \'\'\'\n    w, h = img.shape[:2]\n    im = np.copy(img)\n    return im[:w - w % sf, :h - h % sf, ...]\n\n\n"""\n# --------------------------------------------\n# anisotropic Gaussian kernels\n# --------------------------------------------\n"""\n\n\ndef analytic_kernel(k):\n    """Calculate the X4 kernel from the X2 kernel (for proof see appendix in paper)"""\n    k_size = k.shape[0]\n    # Calculate the big kernels size\n    big_k = np.zeros((3 * k_size - 2, 3 * k_size - 2))\n    # Loop over the small kernel to fill the big one\n    for r in range(k_size):\n        for c in range(k_size):\n            big_k[2 * r:2 * r + k_size, 2 * c:2 * c + k_size] += k[r, c] * k\n    # Crop the edges of the big kernel to ignore very small values and increase run time of SR\n    crop = k_size // 2\n    cropped_big_k = big_k[crop:-crop, crop:-crop]\n    # Normalize to 1\n    return cropped_big_k / cropped_big_k.sum()\n\n\ndef anisotropic_Gaussian(ksize=15, theta=np.pi, l1=6, l2=6):\n    """ generate an anisotropic Gaussian kernel\n    Args:\n        ksize : e.g., 15, kernel size\n        theta : [0,  pi], rotation angle range\n        l1    : [0.1,50], scaling of eigenvalues\n        l2    : [0.1,l1], scaling of eigenvalues\n        If l1 = l2, will get an isotropic Gaussian kernel.\n    Returns:\n        k     : kernel\n    """\n\n    v = np.dot(np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]]), np.array([1., 0.]))\n    V = np.array([[v[0], v[1]], [v[1], -v[0]]])\n    D = np.array([[l1, 0], [0, l2]])\n    Sigma = np.dot(np.dot(V, D), np.linalg.inv(V))\n    k = gm_blur_kernel(mean=[0, 0], cov=Sigma, size=ksize)\n\n    return k\n\n\ndef gm_blur_kernel(mean, cov, size=15):\n    center = size / 2.0 + 0.5\n    k = np.zeros([size, size])\n    for y in range(size):\n        for x in range(size):\n            cy = y - center + 1\n            cx = x - center + 1\n            k[y, x] = ss.multivariate_normal.pdf([cx, cy], mean=mean, cov=cov)\n\n    k = k / np.sum(k)\n    return k\n\n\ndef shift_pixel(x, sf, upper_left=True):\n    """shift pixel for super-resolution with different scale factors\n    Args:\n        x: WxHxC or WxH\n        sf: scale factor\n        upper_left: shift direction\n    """\n    h, w = x.shape[:2]\n    shift = (sf - 1) * 0.5\n    xv, yv = np.arange(0, w, 1.0), np.arange(0, h, 1.0)\n    if upper_left:\n        x1 = xv + shift\n        y1 = yv + shift\n    else:\n        x1 = xv - shift\n        y1 = yv - shift\n\n    x1 = np.clip(x1, 0, w - 1)\n    y1 = np.clip(y1, 0, h - 1)\n\n    if x.ndim == 2:\n        x = interp2d(xv, yv, x)(x1, y1)\n    if x.ndim == 3:\n        for i in range(x.shape[-1]):\n            x[:, :, i] = interp2d(xv, yv, x[:, :, i])(x1, y1)\n\n    return x\n\n\ndef blur(x, k):\n    \'\'\'\n    x: image, NxcxHxW\n    k: kernel, Nx1xhxw\n    \'\'\'\n    n, c = x.shape[:2]\n    p1, p2 = (k.shape[-2] - 1) // 2, (k.shape[-1] - 1) // 2\n    x = torch.nn.functional.pad(x, pad=(p1, p2, p1, p2), mode=\'replicate\')\n    k = k.repeat(1, c, 1, 1)\n    k = k.view(-1, 1, k.shape[2], k.shape[3])\n    x = x.view(1, -1, x.shape[2], x.shape[3])\n    x = torch.nn.functional.conv2d(x, k, bias=None, stride=1, padding=0, groups=n * c)\n    x = x.view(n, c, x.shape[2], x.shape[3])\n\n    return x\n\n\ndef gen_kernel(k_size=np.array([15, 15]), scale_factor=np.array([4, 4]), min_var=0.6, max_var=10., noise_level=0):\n    """"\n    # modified version of https://github.com/assafshocher/BlindSR_dataset_generator\n    # Kai Zhang\n    # min_var = 0.175 * sf  # variance of the gaussian kernel will be sampled between min_var and max_var\n    # max_var = 2.5 * sf\n    """\n    # Set random eigen-vals (lambdas) and angle (theta) for COV matrix\n    lambda_1 = min_var + np.random.rand() * (max_var - min_var)\n    lambda_2 = min_var + np.random.rand() * (max_var - min_var)\n    theta = np.random.rand() * np.pi  # random theta\n    noise = -noise_level + np.random.rand(*k_size) * noise_level * 2\n\n    # Set COV matrix using Lambdas and Theta\n    LAMBDA = np.diag([lambda_1, lambda_2])\n    Q = np.array([[np.cos(theta), -np.sin(theta)],\n                  [np.sin(theta), np.cos(theta)]])\n    SIGMA = Q @ LAMBDA @ Q.T\n    INV_SIGMA = np.linalg.inv(SIGMA)[None, None, :, :]\n\n    # Set expectation position (shifting kernel for aligned image)\n    MU = k_size // 2 - 0.5 * (scale_factor - 1)  # - 0.5 * (scale_factor - k_size % 2)\n    MU = MU[None, None, :, None]\n\n    # Create meshgrid for Gaussian\n    [X, Y] = np.meshgrid(range(k_size[0]), range(k_size[1]))\n    Z = np.stack([X, Y], 2)[:, :, :, None]\n\n    # Calcualte Gaussian for every pixel of the kernel\n    ZZ = Z - MU\n    ZZ_t = ZZ.transpose(0, 1, 3, 2)\n    raw_kernel = np.exp(-0.5 * np.squeeze(ZZ_t @ INV_SIGMA @ ZZ)) * (1 + noise)\n\n    # shift the kernel so it will be centered\n    # raw_kernel_centered = kernel_shift(raw_kernel, scale_factor)\n\n    # Normalize the kernel and return\n    # kernel = raw_kernel_centered / np.sum(raw_kernel_centered)\n    kernel = raw_kernel / np.sum(raw_kernel)\n    return kernel\n\n\ndef fspecial_gaussian(hsize, sigma):\n    hsize = [hsize, hsize]\n    siz = [(hsize[0] - 1.0) / 2.0, (hsize[1] - 1.0) / 2.0]\n    std = sigma\n    [x, y] = np.meshgrid(np.arange(-siz[1], siz[1] + 1), np.arange(-siz[0], siz[0] + 1))\n    arg = -(x * x + y * y) / (2 * std * std)\n    h = np.exp(arg)\n    h[h < scipy.finfo(float).eps * h.max()] = 0\n    sumh = h.sum()\n    if sumh != 0:\n        h = h / sumh\n    return h\n\n\ndef fspecial_laplacian(alpha):\n    alpha = max([0, min([alpha, 1])])\n    h1 = alpha / (alpha + 1)\n    h2 = (1 - alpha) / (alpha + 1)\n    h = [[h1, h2, h1], [h2, -4 / (alpha + 1), h2], [h1, h2, h1]]\n    h = np.array(h)\n    return h\n\n\ndef fspecial(filter_type, *args, **kwargs):\n    \'\'\'\n    python code from:\n    https://github.com/ronaldosena/imagens-medicas-2/blob/40171a6c259edec7827a6693a93955de2bd39e76/Aulas/aula_2_-_uniform_filter/matlab_fspecial.py\n    \'\'\'\n    if filter_type == \'gaussian\':\n        return fspecial_gaussian(*args, **kwargs)\n    if filter_type == \'laplacian\':\n        return fspecial_laplacian(*args, **kwargs)\n\n\n"""\n# --------------------------------------------\n# degradation models\n# --------------------------------------------\n"""\n\n\ndef bicubic_degradation(x, sf=3):\n    \'\'\'\n    Args:\n        x: HxWxC image, [0, 1]\n        sf: down-scale factor\n    Return:\n        bicubicly downsampled LR image\n    \'\'\'\n    x = util.imresize_np(x, scale=1 / sf)\n    return x\n\n\ndef srmd_degradation(x, k, sf=3):\n    \'\'\' blur + bicubic downsampling\n    Args:\n        x: HxWxC image, [0, 1]\n        k: hxw, double\n        sf: down-scale factor\n    Return:\n        downsampled LR image\n    Reference:\n        @inproceedings{zhang2018learning,\n          title={Learning a single convolutional super-resolution network for multiple degradations},\n          author={Zhang, Kai and Zuo, Wangmeng and Zhang, Lei},\n          booktitle={IEEE Conference on Computer Vision and Pattern Recognition},\n          pages={3262--3271},\n          year={2018}\n        }\n    \'\'\'\n    x = ndimage.filters.convolve(x, np.expand_dims(k, axis=2), mode=\'wrap\')  # \'nearest\' | \'mirror\'\n    x = bicubic_degradation(x, sf=sf)\n    return x\n\n\ndef dpsr_degradation(x, k, sf=3):\n    \'\'\' bicubic downsampling + blur\n    Args:\n        x: HxWxC image, [0, 1]\n        k: hxw, double\n        sf: down-scale factor\n    Return:\n        downsampled LR image\n    Reference:\n        @inproceedings{zhang2019deep,\n          title={Deep Plug-and-Play Super-Resolution for Arbitrary Blur Kernels},\n          author={Zhang, Kai and Zuo, Wangmeng and Zhang, Lei},\n          booktitle={IEEE Conference on Computer Vision and Pattern Recognition},\n          pages={1671--1681},\n          year={2019}\n        }\n    \'\'\'\n    x = bicubic_degradation(x, sf=sf)\n    x = ndimage.filters.convolve(x, np.expand_dims(k, axis=2), mode=\'wrap\')\n    return x\n\n\ndef classical_degradation(x, k, sf=3):\n    \'\'\' blur + downsampling\n    Args:\n        x: HxWxC image, [0, 1]/[0, 255]\n        k: hxw, double\n        sf: down-scale factor\n    Return:\n        downsampled LR image\n    \'\'\'\n    x = ndimage.filters.convolve(x, np.expand_dims(k, axis=2), mode=\'wrap\')\n    # x = filters.correlate(x, np.expand_dims(np.flip(k), axis=2))\n    st = 0\n    return x[st::sf, st::sf, ...]\n\n\ndef add_sharpening(img, weight=0.5, radius=50, threshold=10):\n    """USM sharpening. borrowed from real-ESRGAN\n    Input image: I; Blurry image: B.\n    1. K = I + weight * (I - B)\n    2. Mask = 1 if abs(I - B) > threshold, else: 0\n    3. Blur mask:\n    4. Out = Mask * K + (1 - Mask) * I\n    Args:\n        img (Numpy array): Input image, HWC, BGR; float32, [0, 1].\n        weight (float): Sharp weight. Default: 1.\n        radius (float): Kernel size of Gaussian blur. Default: 50.\n        threshold (int):\n    """\n    if radius % 2 == 0:\n        radius += 1\n    blur = cv2.GaussianBlur(img, (radius, radius), 0)\n    residual = img - blur\n    mask = np.abs(residual) * 255 > threshold\n    mask = mask.astype(\'float32\')\n    soft_mask = cv2.GaussianBlur(mask, (radius, radius), 0)\n\n    K = img + weight * residual\n    K = np.clip(K, 0, 1)\n    return soft_mask * K + (1 - soft_mask) * img\n\n\ndef add_blur(img, sf=4):\n    wd2 = 4.0 + sf\n    wd = 2.0 + 0.2 * sf\n\n    wd2 = wd2/4\n    wd = wd/4\n\n    if random.random() < 0.5:\n        l1 = wd2 * random.random()\n        l2 = wd2 * random.random()\n        k = anisotropic_Gaussian(ksize=random.randint(2, 11) + 3, theta=random.random() * np.pi, l1=l1, l2=l2)\n    else:\n        k = fspecial(\'gaussian\', random.randint(2, 4) + 3, wd * random.random())\n    img = ndimage.filters.convolve(img, np.expand_dims(k, axis=2), mode=\'mirror\')\n\n    return img\n\n\ndef add_resize(img, sf=4):\n    rnum = np.random.rand()\n    if rnum > 0.8:  # up\n        sf1 = random.uniform(1, 2)\n    elif rnum < 0.7:  # down\n        sf1 = random.uniform(0.5 / sf, 1)\n    else:\n        sf1 = 1.0\n    img = cv2.resize(img, (int(sf1 * img.shape[1]), int(sf1 * img.shape[0])), interpolation=random.choice([1, 2, 3]))\n    img = np.clip(img, 0.0, 1.0)\n\n    return img\n\n\n# def add_Gaussian_noise(img, noise_level1=2, noise_level2=25):\n#     noise_level = random.randint(noise_level1, noise_level2)\n#     rnum = np.random.rand()\n#     if rnum > 0.6:  # add color Gaussian noise\n#         img += np.random.normal(0, noise_level / 255.0, img.shape).astype(np.float32)\n#     elif rnum < 0.4:  # add grayscale Gaussian noise\n#         img += np.random.normal(0, noise_level / 255.0, (*img.shape[:2], 1)).astype(np.float32)\n#     else:  # add  noise\n#         L = noise_level2 / 255.\n#         D = np.diag(np.random.rand(3))\n#         U = orth(np.random.rand(3, 3))\n#         conv = np.dot(np.dot(np.transpose(U), D), U)\n#         img += np.random.multivariate_normal([0, 0, 0], np.abs(L ** 2 * conv), img.shape[:2]).astype(np.float32)\n#     img = np.clip(img, 0.0, 1.0)\n#     return img\n\ndef add_Gaussian_noise(img, noise_level1=2, noise_level2=25):\n    noise_level = random.randint(noise_level1, noise_level2)\n    rnum = np.random.rand()\n    if rnum > 0.6:  # add color Gaussian noise\n        img = img + np.random.normal(0, noise_level / 255.0, img.shape).astype(np.float32)\n    elif rnum < 0.4:  # add grayscale Gaussian noise\n        img = img + np.random.normal(0, noise_level / 255.0, (*img.shape[:2], 1)).astype(np.float32)\n    else:  # add  noise\n        L = noise_level2 / 255.\n        D = np.diag(np.random.rand(3))\n        U = orth(np.random.rand(3, 3))\n        conv = np.dot(np.dot(np.transpose(U), D), U)\n        img = img + np.random.multivariate_normal([0, 0, 0], np.abs(L ** 2 * conv), img.shape[:2]).astype(np.float32)\n    img = np.clip(img, 0.0, 1.0)\n    return img\n\n\ndef add_speckle_noise(img, noise_level1=2, noise_level2=25):\n    noise_level = random.randint(noise_level1, noise_level2)\n    img = np.clip(img, 0.0, 1.0)\n    rnum = random.random()\n    if rnum > 0.6:\n        img += img * np.random.normal(0, noise_level / 255.0, img.shape).astype(np.float32)\n    elif rnum < 0.4:\n        img += img * np.random.normal(0, noise_level / 255.0, (*img.shape[:2], 1)).astype(np.float32)\n    else:\n        L = noise_level2 / 255.\n        D = np.diag(np.random.rand(3))\n        U = orth(np.random.rand(3, 3))\n        conv = np.dot(np.dot(np.transpose(U), D), U)\n        img += img * np.random.multivariate_normal([0, 0, 0], np.abs(L ** 2 * conv), img.shape[:2]).astype(np.float32)\n    img = np.clip(img, 0.0, 1.0)\n    return img\n\n\ndef add_Poisson_noise(img):\n    img = np.clip((img * 255.0).round(), 0, 255) / 255.\n    vals = 10 ** (2 * random.random() + 2.0)  # [2, 4]\n    if random.random() < 0.5:\n        img = np.random.poisson(img * vals).astype(np.float32) / vals\n    else:\n        img_gray = np.dot(img[..., :3], [0.299, 0.587, 0.114])\n        img_gray = np.clip((img_gray * 255.0).round(), 0, 255) / 255.\n        noise_gray = np.random.poisson(img_gray * vals).astype(np.float32) / vals - img_gray\n        img += noise_gray[:, :, np.newaxis]\n    img = np.clip(img, 0.0, 1.0)\n    return img\n\n\ndef add_JPEG_noise(img):\n    quality_factor = random.randint(80, 95)\n    img = cv2.cvtColor(util.single2uint(img), cv2.COLOR_RGB2BGR)\n    result, encimg = cv2.imencode(\'.jpg\', img, [int(cv2.IMWRITE_JPEG_QUALITY), quality_factor])\n    img = cv2.imdecode(encimg, 1)\n    img = cv2.cvtColor(util.uint2single(img), cv2.COLOR_BGR2RGB)\n    return img\n\n\ndef random_crop(lq, hq, sf=4, lq_patchsize=64):\n    h, w = lq.shape[:2]\n    rnd_h = random.randint(0, h - lq_patchsize)\n    rnd_w = random.randint(0, w - lq_patchsize)\n    lq = lq[rnd_h:rnd_h + lq_patchsize, rnd_w:rnd_w + lq_patchsize, :]\n\n    rnd_h_H, rnd_w_H = int(rnd_h * sf), int(rnd_w * sf)\n    hq = hq[rnd_h_H:rnd_h_H + lq_patchsize * sf, rnd_w_H:rnd_w_H + lq_patchsize * sf, :]\n    return lq, hq\n\n\ndef degradation_bsrgan(img, sf=4, lq_patchsize=72, isp_model=None):\n    """\n    This is the degradation model of BSRGAN from the paper\n    "Designing a Practical Degradation Model for Deep Blind Image Super-Resolution"\n    ----------\n    img: HXWXC, [0, 1], its size should be large than (lq_patchsizexsf)x(lq_patchsizexsf)\n    sf: scale factor\n    isp_model: camera ISP model\n    Returns\n    -------\n    img: low-quality patch, size: lq_patchsizeXlq_patchsizeXC, range: [0, 1]\n    hq: corresponding high-quality patch, size: (lq_patchsizexsf)X(lq_patchsizexsf)XC, range: [0, 1]\n    """\n    isp_prob, jpeg_prob, scale2_prob = 0.25, 0.9, 0.25\n    sf_ori = sf\n\n    h1, w1 = img.shape[:2]\n    img = img.copy()[:w1 - w1 % sf, :h1 - h1 % sf, ...]  # mod crop\n    h, w = img.shape[:2]\n\n    if h < lq_patchsize * sf or w < lq_patchsize * sf:\n        raise ValueError(f\'img size ({h1}X{w1}) is too small!\')\n\n    hq = img.copy()\n\n    if sf == 4 and random.random() < scale2_prob:  # downsample1\n        if np.random.rand() < 0.5:\n            img = cv2.resize(img, (int(1 / 2 * img.shape[1]), int(1 / 2 * img.shape[0])),\n                             interpolation=random.choice([1, 2, 3]))\n        else:\n            img = util.imresize_np(img, 1 / 2, True)\n        img = np.clip(img, 0.0, 1.0)\n        sf = 2\n\n    shuffle_order = random.sample(range(7), 7)\n    idx1, idx2 = shuffle_order.index(2), shuffle_order.index(3)\n    if idx1 > idx2:  # keep downsample3 last\n        shuffle_order[idx1], shuffle_order[idx2] = shuffle_order[idx2], shuffle_order[idx1]\n\n    for i in shuffle_order:\n\n        if i == 0:\n            img = add_blur(img, sf=sf)\n\n        elif i == 1:\n            img = add_blur(img, sf=sf)\n\n        elif i == 2:\n            a, b = img.shape[1], img.shape[0]\n            # downsample2\n            if random.random() < 0.75:\n                sf1 = random.uniform(1, 2 * sf)\n                img = cv2.resize(img, (int(1 / sf1 * img.shape[1]), int(1 / sf1 * img.shape[0])),\n                                 interpolation=random.choice([1, 2, 3]))\n            else:\n                k = fspecial(\'gaussian\', 25, random.uniform(0.1, 0.6 * sf))\n                k_shifted = shift_pixel(k, sf)\n                k_shifted = k_shifted / k_shifted.sum()  # blur with shifted kernel\n                img = ndimage.filters.convolve(img, np.expand_dims(k_shifted, axis=2), mode=\'mirror\')\n                img = img[0::sf, 0::sf, ...]  # nearest downsampling\n            img = np.clip(img, 0.0, 1.0)\n\n        elif i == 3:\n            # downsample3\n            img = cv2.resize(img, (int(1 / sf * a), int(1 / sf * b)), interpolation=random.choice([1, 2, 3]))\n            img = np.clip(img, 0.0, 1.0)\n\n        elif i == 4:\n            # add Gaussian noise\n            img = add_Gaussian_noise(img, noise_level1=2, noise_level2=8)\n\n        elif i == 5:\n            # add JPEG noise\n            if random.random() < jpeg_prob:\n                img = add_JPEG_noise(img)\n\n        elif i == 6:\n            # add processed camera sensor noise\n            if random.random() < isp_prob and isp_model is not None:\n                with torch.no_grad():\n                    img, hq = isp_model.forward(img.copy(), hq)\n\n    # add final JPEG compression noise\n    img = add_JPEG_noise(img)\n\n    # random crop\n    img, hq = random_crop(img, hq, sf_ori, lq_patchsize)\n\n    return img, hq\n\n\n# todo no isp_model?\ndef degradation_bsrgan_variant(image, sf=4, isp_model=None):\n    """\n    This is the degradation model of BSRGAN from the paper\n    "Designing a Practical Degradation Model for Deep Blind Image Super-Resolution"\n    ----------\n    sf: scale factor\n    isp_model: camera ISP model\n    Returns\n    -------\n    img: low-quality patch, size: lq_patchsizeXlq_patchsizeXC, range: [0, 1]\n    hq: corresponding high-quality patch, size: (lq_patchsizexsf)X(lq_patchsizexsf)XC, range: [0, 1]\n    """\n    image = util.uint2single(image)\n    isp_prob, jpeg_prob, scale2_prob = 0.25, 0.9, 0.25\n    sf_ori = sf\n\n    h1, w1 = image.shape[:2]\n    image = image.copy()[:w1 - w1 % sf, :h1 - h1 % sf, ...]  # mod crop\n    h, w = image.shape[:2]\n\n    hq = image.copy()\n\n    if sf == 4 and random.random() < scale2_prob:  # downsample1\n        if np.random.rand() < 0.5:\n            image = cv2.resize(image, (int(1 / 2 * image.shape[1]), int(1 / 2 * image.shape[0])),\n                               interpolation=random.choice([1, 2, 3]))\n        else:\n            image = util.imresize_np(image, 1 / 2, True)\n        image = np.clip(image, 0.0, 1.0)\n        sf = 2\n\n    shuffle_order = random.sample(range(7), 7)\n    idx1, idx2 = shuffle_order.index(2), shuffle_order.index(3)\n    if idx1 > idx2:  # keep downsample3 last\n        shuffle_order[idx1], shuffle_order[idx2] = shuffle_order[idx2], shuffle_order[idx1]\n\n    for i in shuffle_order:\n\n        if i == 0:\n            image = add_blur(image, sf=sf)\n\n        # elif i == 1:\n        #     image = add_blur(image, sf=sf)\n\n        if i == 0:\n            pass\n\n        elif i == 2:\n            a, b = image.shape[1], image.shape[0]\n            # downsample2\n            if random.random() < 0.8:\n                sf1 = random.uniform(1, 2 * sf)\n                image = cv2.resize(image, (int(1 / sf1 * image.shape[1]), int(1 / sf1 * image.shape[0])),\n                                   interpolation=random.choice([1, 2, 3]))\n            else:\n                k = fspecial(\'gaussian\', 25, random.uniform(0.1, 0.6 * sf))\n                k_shifted = shift_pixel(k, sf)\n                k_shifted = k_shifted / k_shifted.sum()  # blur with shifted kernel\n                image = ndimage.filters.convolve(image, np.expand_dims(k_shifted, axis=2), mode=\'mirror\')\n                image = image[0::sf, 0::sf, ...]  # nearest downsampling\n\n            image = np.clip(image, 0.0, 1.0)\n\n        elif i == 3:\n            # downsample3\n            image = cv2.resize(image, (int(1 / sf * a), int(1 / sf * b)), interpolation=random.choice([1, 2, 3]))\n            image = np.clip(image, 0.0, 1.0)\n\n        elif i == 4:\n            # add Gaussian noise\n            image = add_Gaussian_noise(image, noise_level1=1, noise_level2=2)\n\n        elif i == 5:\n            # add JPEG noise\n            if random.random() < jpeg_prob:\n                image = add_JPEG_noise(image)\n        #\n        # elif i == 6:\n        #     # add processed camera sensor noise\n        #     if random.random() < isp_prob and isp_model is not None:\n        #         with torch.no_grad():\n        #             img, hq = isp_model.forward(img.copy(), hq)\n\n    # add final JPEG compression noise\n    image = add_JPEG_noise(image)\n    image = util.single2uint(image)\n    example = {"image": image}\n    return example\n\n\n\n\nif __name__ == \'__main__\':\n    print("hey")\n    img = util.imread_uint(\'utils/test.png\', 3)\n    img = img[:448, :448]\n    h = img.shape[0] // 4\n    print("resizing to", h)\n    sf = 4\n    deg_fn = partial(degradation_bsrgan_variant, sf=sf)\n    for i in range(20):\n        print(i)\n        img_hq = img\n        img_lq = deg_fn(img)["image"]\n        img_hq, img_lq = util.uint2single(img_hq), util.uint2single(img_lq)\n        print(img_lq)\n        img_lq_bicubic = albumentations.SmallestMaxSize(max_size=h, interpolation=cv2.INTER_CUBIC)(image=img_hq)["image"]\n        print(img_lq.shape)\n        print("bicubic", img_lq_bicubic.shape)\n        print(img_hq.shape)\n        lq_nearest = cv2.resize(util.single2uint(img_lq), (int(sf * img_lq.shape[1]), int(sf * img_lq.shape[0])),\n                                interpolation=0)\n        lq_bicubic_nearest = cv2.resize(util.single2uint(img_lq_bicubic),\n                                        (int(sf * img_lq.shape[1]), int(sf * img_lq.shape[0])),\n                                        interpolation=0)\n        img_concat = np.concatenate([lq_bicubic_nearest, lq_nearest, util.single2uint(img_hq)], axis=1)\n        util.imsave(img_concat, str(i) + \'.png\')\n',
    'model.ldm.modules.image_degradation.utils_image': 'import os\nimport math\nimport random\nimport numpy as np\nimport torch\nimport cv2\nfrom torchvision.utils import make_grid\nfrom datetime import datetime\n#import matplotlib.pyplot as plt   # TODO: check with Dominik, also bsrgan.py vs bsrgan_light.py\n\n\nos.environ["KMP_DUPLICATE_LIB_OK"]="TRUE"\n\n\n\'\'\'\n# --------------------------------------------\n# Kai Zhang (github: https://github.com/cszn)\n# 03/Mar/2019\n# --------------------------------------------\n# https://github.com/twhui/SRGAN-pyTorch\n# https://github.com/xinntao/BasicSR\n# --------------------------------------------\n\'\'\'\n\n\nIMG_EXTENSIONS = [\'.jpg\', \'.JPG\', \'.jpeg\', \'.JPEG\', \'.png\', \'.PNG\', \'.ppm\', \'.PPM\', \'.bmp\', \'.BMP\', \'.tif\']\n\n\ndef is_image_file(filename):\n    return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)\n\n\ndef get_timestamp():\n    return datetime.now().strftime(\'%y%m%d-%H%M%S\')\n\n\ndef imshow(x, title=None, cbar=False, figsize=None):\n    plt.figure(figsize=figsize)\n    plt.imshow(np.squeeze(x), interpolation=\'nearest\', cmap=\'gray\')\n    if title:\n        plt.title(title)\n    if cbar:\n        plt.colorbar()\n    plt.show()\n\n\ndef surf(Z, cmap=\'rainbow\', figsize=None):\n    plt.figure(figsize=figsize)\n    ax3 = plt.axes(projection=\'3d\')\n\n    w, h = Z.shape[:2]\n    xx = np.arange(0,w,1)\n    yy = np.arange(0,h,1)\n    X, Y = np.meshgrid(xx, yy)\n    ax3.plot_surface(X,Y,Z,cmap=cmap)\n    #ax3.contour(X,Y,Z, zdim=\'z\',offset=-2cmap=cmap)\n    plt.show()\n\n\n\'\'\'\n# --------------------------------------------\n# get image pathes\n# --------------------------------------------\n\'\'\'\n\n\ndef get_image_paths(dataroot):\n    paths = None  # return None if dataroot is None\n    if dataroot is not None:\n        paths = sorted(_get_paths_from_images(dataroot))\n    return paths\n\n\ndef _get_paths_from_images(path):\n    assert os.path.isdir(path), \'{:s} is not a valid directory\'.format(path)\n    images = []\n    for dirpath, _, fnames in sorted(os.walk(path)):\n        for fname in sorted(fnames):\n            if is_image_file(fname):\n                img_path = os.path.join(dirpath, fname)\n                images.append(img_path)\n    assert images, \'{:s} has no valid image file\'.format(path)\n    return images\n\n\n\'\'\'\n# --------------------------------------------\n# split large images into small images \n# --------------------------------------------\n\'\'\'\n\n\ndef patches_from_image(img, p_size=512, p_overlap=64, p_max=800):\n    w, h = img.shape[:2]\n    patches = []\n    if w > p_max and h > p_max:\n        w1 = list(np.arange(0, w-p_size, p_size-p_overlap, dtype=np.int))\n        h1 = list(np.arange(0, h-p_size, p_size-p_overlap, dtype=np.int))\n        w1.append(w-p_size)\n        h1.append(h-p_size)\n#        print(w1)\n#        print(h1)\n        for i in w1:\n            for j in h1:\n                patches.append(img[i:i+p_size, j:j+p_size,:])\n    else:\n        patches.append(img)\n\n    return patches\n\n\ndef imssave(imgs, img_path):\n    """\n    imgs: list, N images of size WxHxC\n    """\n    img_name, ext = os.path.splitext(os.path.basename(img_path))\n\n    for i, img in enumerate(imgs):\n        if img.ndim == 3:\n            img = img[:, :, [2, 1, 0]]\n        new_path = os.path.join(os.path.dirname(img_path), img_name+str(\'_s{:04d}\'.format(i))+\'.png\')\n        cv2.imwrite(new_path, img)\n\n\ndef split_imageset(original_dataroot, taget_dataroot, n_channels=3, p_size=800, p_overlap=96, p_max=1000):\n    """\n    split the large images from original_dataroot into small overlapped images with size (p_size)x(p_size),\n    and save them into taget_dataroot; only the images with larger size than (p_max)x(p_max)\n    will be splitted.\n    Args:\n        original_dataroot:\n        taget_dataroot:\n        p_size: size of small images\n        p_overlap: patch size in training is a good choice\n        p_max: images with smaller size than (p_max)x(p_max) keep unchanged.\n    """\n    paths = get_image_paths(original_dataroot)\n    for img_path in paths:\n        # img_name, ext = os.path.splitext(os.path.basename(img_path))\n        img = imread_uint(img_path, n_channels=n_channels)\n        patches = patches_from_image(img, p_size, p_overlap, p_max)\n        imssave(patches, os.path.join(taget_dataroot,os.path.basename(img_path)))\n        #if original_dataroot == taget_dataroot:\n        #del img_path\n\n\'\'\'\n# --------------------------------------------\n# makedir\n# --------------------------------------------\n\'\'\'\n\n\ndef mkdir(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n\n\ndef mkdirs(paths):\n    if isinstance(paths, str):\n        mkdir(paths)\n    else:\n        for path in paths:\n            mkdir(path)\n\n\ndef mkdir_and_rename(path):\n    if os.path.exists(path):\n        new_name = path + \'_archived_\' + get_timestamp()\n        print(\'Path already exists. Rename it to [{:s}]\'.format(new_name))\n        os.rename(path, new_name)\n    os.makedirs(path)\n\n\n\'\'\'\n# --------------------------------------------\n# read image from path\n# opencv is fast, but read BGR numpy image\n# --------------------------------------------\n\'\'\'\n\n\n# --------------------------------------------\n# get uint8 image of size HxWxn_channles (RGB)\n# --------------------------------------------\ndef imread_uint(path, n_channels=3):\n    #  input: path\n    # output: HxWx3(RGB or GGG), or HxWx1 (G)\n    if n_channels == 1:\n        img = cv2.imread(path, 0)  # cv2.IMREAD_GRAYSCALE\n        img = np.expand_dims(img, axis=2)  # HxWx1\n    elif n_channels == 3:\n        img = cv2.imread(path, cv2.IMREAD_UNCHANGED)  # BGR or G\n        if img.ndim == 2:\n            img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)  # GGG\n        else:\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # RGB\n    return img\n\n\n# --------------------------------------------\n# matlab\'s imwrite\n# --------------------------------------------\ndef imsave(img, img_path):\n    img = np.squeeze(img)\n    if img.ndim == 3:\n        img = img[:, :, [2, 1, 0]]\n    cv2.imwrite(img_path, img)\n\ndef imwrite(img, img_path):\n    img = np.squeeze(img)\n    if img.ndim == 3:\n        img = img[:, :, [2, 1, 0]]\n    cv2.imwrite(img_path, img)\n\n\n\n# --------------------------------------------\n# get single image of size HxWxn_channles (BGR)\n# --------------------------------------------\ndef read_img(path):\n    # read image by cv2\n    # return: Numpy float32, HWC, BGR, [0,1]\n    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)  # cv2.IMREAD_GRAYSCALE\n    img = img.astype(np.float32) / 255.\n    if img.ndim == 2:\n        img = np.expand_dims(img, axis=2)\n    # some images have 4 channels\n    if img.shape[2] > 3:\n        img = img[:, :, :3]\n    return img\n\n\n\'\'\'\n# --------------------------------------------\n# image format conversion\n# --------------------------------------------\n# numpy(single) <--->  numpy(unit)\n# numpy(single) <--->  tensor\n# numpy(unit)   <--->  tensor\n# --------------------------------------------\n\'\'\'\n\n\n# --------------------------------------------\n# numpy(single) [0, 1] <--->  numpy(unit)\n# --------------------------------------------\n\n\ndef uint2single(img):\n\n    return np.float32(img/255.)\n\n\ndef single2uint(img):\n\n    return np.uint8((img.clip(0, 1)*255.).round())\n\n\ndef uint162single(img):\n\n    return np.float32(img/65535.)\n\n\ndef single2uint16(img):\n\n    return np.uint16((img.clip(0, 1)*65535.).round())\n\n\n# --------------------------------------------\n# numpy(unit) (HxWxC or HxW) <--->  tensor\n# --------------------------------------------\n\n\n# convert uint to 4-dimensional torch tensor\ndef uint2tensor4(img):\n    if img.ndim == 2:\n        img = np.expand_dims(img, axis=2)\n    return torch.from_numpy(np.ascontiguousarray(img)).permute(2, 0, 1).float().div(255.).unsqueeze(0)\n\n\n# convert uint to 3-dimensional torch tensor\ndef uint2tensor3(img):\n    if img.ndim == 2:\n        img = np.expand_dims(img, axis=2)\n    return torch.from_numpy(np.ascontiguousarray(img)).permute(2, 0, 1).float().div(255.)\n\n\n# convert 2/3/4-dimensional torch tensor to uint\ndef tensor2uint(img):\n    img = img.data.squeeze().float().clamp_(0, 1).cpu().numpy()\n    if img.ndim == 3:\n        img = np.transpose(img, (1, 2, 0))\n    return np.uint8((img*255.0).round())\n\n\n# --------------------------------------------\n# numpy(single) (HxWxC) <--->  tensor\n# --------------------------------------------\n\n\n# convert single (HxWxC) to 3-dimensional torch tensor\ndef single2tensor3(img):\n    return torch.from_numpy(np.ascontiguousarray(img)).permute(2, 0, 1).float()\n\n\n# convert single (HxWxC) to 4-dimensional torch tensor\ndef single2tensor4(img):\n    return torch.from_numpy(np.ascontiguousarray(img)).permute(2, 0, 1).float().unsqueeze(0)\n\n\n# convert torch tensor to single\ndef tensor2single(img):\n    img = img.data.squeeze().float().cpu().numpy()\n    if img.ndim == 3:\n        img = np.transpose(img, (1, 2, 0))\n\n    return img\n\n# convert torch tensor to single\ndef tensor2single3(img):\n    img = img.data.squeeze().float().cpu().numpy()\n    if img.ndim == 3:\n        img = np.transpose(img, (1, 2, 0))\n    elif img.ndim == 2:\n        img = np.expand_dims(img, axis=2)\n    return img\n\n\ndef single2tensor5(img):\n    return torch.from_numpy(np.ascontiguousarray(img)).permute(2, 0, 1, 3).float().unsqueeze(0)\n\n\ndef single32tensor5(img):\n    return torch.from_numpy(np.ascontiguousarray(img)).float().unsqueeze(0).unsqueeze(0)\n\n\ndef single42tensor4(img):\n    return torch.from_numpy(np.ascontiguousarray(img)).permute(2, 0, 1, 3).float()\n\n\n# from skimage.io import imread, imsave\ndef tensor2img(tensor, out_type=np.uint8, min_max=(0, 1)):\n    \'\'\'\n    Converts a torch Tensor into an image Numpy array of BGR channel order\n    Input: 4D(B,(3/1),H,W), 3D(C,H,W), or 2D(H,W), any range, RGB channel order\n    Output: 3D(H,W,C) or 2D(H,W), [0,255], np.uint8 (default)\n    \'\'\'\n    tensor = tensor.squeeze().float().cpu().clamp_(*min_max)  # squeeze first, then clamp\n    tensor = (tensor - min_max[0]) / (min_max[1] - min_max[0])  # to range [0,1]\n    n_dim = tensor.dim()\n    if n_dim == 4:\n        n_img = len(tensor)\n        img_np = make_grid(tensor, nrow=int(math.sqrt(n_img)), normalize=False).numpy()\n        img_np = np.transpose(img_np[[2, 1, 0], :, :], (1, 2, 0))  # HWC, BGR\n    elif n_dim == 3:\n        img_np = tensor.numpy()\n        img_np = np.transpose(img_np[[2, 1, 0], :, :], (1, 2, 0))  # HWC, BGR\n    elif n_dim == 2:\n        img_np = tensor.numpy()\n    else:\n        raise TypeError(\n            \'Only support 4D, 3D and 2D tensor. But received with dimension: {:d}\'.format(n_dim))\n    if out_type == np.uint8:\n        img_np = (img_np * 255.0).round()\n        # Important. Unlike matlab, numpy.unit8() WILL NOT round by default.\n    return img_np.astype(out_type)\n\n\n\'\'\'\n# --------------------------------------------\n# Augmentation, flipe and/or rotate\n# --------------------------------------------\n# The following two are enough.\n# (1) augmet_img: numpy image of WxHxC or WxH\n# (2) augment_img_tensor4: tensor image 1xCxWxH\n# --------------------------------------------\n\'\'\'\n\n\ndef augment_img(img, mode=0):\n    \'\'\'Kai Zhang (github: https://github.com/cszn)\n    \'\'\'\n    if mode == 0:\n        return img\n    elif mode == 1:\n        return np.flipud(np.rot90(img))\n    elif mode == 2:\n        return np.flipud(img)\n    elif mode == 3:\n        return np.rot90(img, k=3)\n    elif mode == 4:\n        return np.flipud(np.rot90(img, k=2))\n    elif mode == 5:\n        return np.rot90(img)\n    elif mode == 6:\n        return np.rot90(img, k=2)\n    elif mode == 7:\n        return np.flipud(np.rot90(img, k=3))\n\n\ndef augment_img_tensor4(img, mode=0):\n    \'\'\'Kai Zhang (github: https://github.com/cszn)\n    \'\'\'\n    if mode == 0:\n        return img\n    elif mode == 1:\n        return img.rot90(1, [2, 3]).flip([2])\n    elif mode == 2:\n        return img.flip([2])\n    elif mode == 3:\n        return img.rot90(3, [2, 3])\n    elif mode == 4:\n        return img.rot90(2, [2, 3]).flip([2])\n    elif mode == 5:\n        return img.rot90(1, [2, 3])\n    elif mode == 6:\n        return img.rot90(2, [2, 3])\n    elif mode == 7:\n        return img.rot90(3, [2, 3]).flip([2])\n\n\ndef augment_img_tensor(img, mode=0):\n    \'\'\'Kai Zhang (github: https://github.com/cszn)\n    \'\'\'\n    img_size = img.size()\n    img_np = img.data.cpu().numpy()\n    if len(img_size) == 3:\n        img_np = np.transpose(img_np, (1, 2, 0))\n    elif len(img_size) == 4:\n        img_np = np.transpose(img_np, (2, 3, 1, 0))\n    img_np = augment_img(img_np, mode=mode)\n    img_tensor = torch.from_numpy(np.ascontiguousarray(img_np))\n    if len(img_size) == 3:\n        img_tensor = img_tensor.permute(2, 0, 1)\n    elif len(img_size) == 4:\n        img_tensor = img_tensor.permute(3, 2, 0, 1)\n\n    return img_tensor.type_as(img)\n\n\ndef augment_img_np3(img, mode=0):\n    if mode == 0:\n        return img\n    elif mode == 1:\n        return img.transpose(1, 0, 2)\n    elif mode == 2:\n        return img[::-1, :, :]\n    elif mode == 3:\n        img = img[::-1, :, :]\n        img = img.transpose(1, 0, 2)\n        return img\n    elif mode == 4:\n        return img[:, ::-1, :]\n    elif mode == 5:\n        img = img[:, ::-1, :]\n        img = img.transpose(1, 0, 2)\n        return img\n    elif mode == 6:\n        img = img[:, ::-1, :]\n        img = img[::-1, :, :]\n        return img\n    elif mode == 7:\n        img = img[:, ::-1, :]\n        img = img[::-1, :, :]\n        img = img.transpose(1, 0, 2)\n        return img\n\n\ndef augment_imgs(img_list, hflip=True, rot=True):\n    # horizontal flip OR rotate\n    hflip = hflip and random.random() < 0.5\n    vflip = rot and random.random() < 0.5\n    rot90 = rot and random.random() < 0.5\n\n    def _augment(img):\n        if hflip:\n            img = img[:, ::-1, :]\n        if vflip:\n            img = img[::-1, :, :]\n        if rot90:\n            img = img.transpose(1, 0, 2)\n        return img\n\n    return [_augment(img) for img in img_list]\n\n\n\'\'\'\n# --------------------------------------------\n# modcrop and shave\n# --------------------------------------------\n\'\'\'\n\n\ndef modcrop(img_in, scale):\n    # img_in: Numpy, HWC or HW\n    img = np.copy(img_in)\n    if img.ndim == 2:\n        H, W = img.shape\n        H_r, W_r = H % scale, W % scale\n        img = img[:H - H_r, :W - W_r]\n    elif img.ndim == 3:\n        H, W, C = img.shape\n        H_r, W_r = H % scale, W % scale\n        img = img[:H - H_r, :W - W_r, :]\n    else:\n        raise ValueError(\'Wrong img ndim: [{:d}].\'.format(img.ndim))\n    return img\n\n\ndef shave(img_in, border=0):\n    # img_in: Numpy, HWC or HW\n    img = np.copy(img_in)\n    h, w = img.shape[:2]\n    img = img[border:h-border, border:w-border]\n    return img\n\n\n\'\'\'\n# --------------------------------------------\n# image processing process on numpy image\n# channel_convert(in_c, tar_type, img_list):\n# rgb2ycbcr(img, only_y=True):\n# bgr2ycbcr(img, only_y=True):\n# ycbcr2rgb(img):\n# --------------------------------------------\n\'\'\'\n\n\ndef rgb2ycbcr(img, only_y=True):\n    \'\'\'same as matlab rgb2ycbcr\n    only_y: only return Y channel\n    Input:\n        uint8, [0, 255]\n        float, [0, 1]\n    \'\'\'\n    in_img_type = img.dtype\n    img.astype(np.float32)\n    if in_img_type != np.uint8:\n        img *= 255.\n    # convert\n    if only_y:\n        rlt = np.dot(img, [65.481, 128.553, 24.966]) / 255.0 + 16.0\n    else:\n        rlt = np.matmul(img, [[65.481, -37.797, 112.0], [128.553, -74.203, -93.786],\n                              [24.966, 112.0, -18.214]]) / 255.0 + [16, 128, 128]\n    if in_img_type == np.uint8:\n        rlt = rlt.round()\n    else:\n        rlt /= 255.\n    return rlt.astype(in_img_type)\n\n\ndef ycbcr2rgb(img):\n    \'\'\'same as matlab ycbcr2rgb\n    Input:\n        uint8, [0, 255]\n        float, [0, 1]\n    \'\'\'\n    in_img_type = img.dtype\n    img.astype(np.float32)\n    if in_img_type != np.uint8:\n        img *= 255.\n    # convert\n    rlt = np.matmul(img, [[0.00456621, 0.00456621, 0.00456621], [0, -0.00153632, 0.00791071],\n                          [0.00625893, -0.00318811, 0]]) * 255.0 + [-222.921, 135.576, -276.836]\n    if in_img_type == np.uint8:\n        rlt = rlt.round()\n    else:\n        rlt /= 255.\n    return rlt.astype(in_img_type)\n\n\ndef bgr2ycbcr(img, only_y=True):\n    \'\'\'bgr version of rgb2ycbcr\n    only_y: only return Y channel\n    Input:\n        uint8, [0, 255]\n        float, [0, 1]\n    \'\'\'\n    in_img_type = img.dtype\n    img.astype(np.float32)\n    if in_img_type != np.uint8:\n        img *= 255.\n    # convert\n    if only_y:\n        rlt = np.dot(img, [24.966, 128.553, 65.481]) / 255.0 + 16.0\n    else:\n        rlt = np.matmul(img, [[24.966, 112.0, -18.214], [128.553, -74.203, -93.786],\n                              [65.481, -37.797, 112.0]]) / 255.0 + [16, 128, 128]\n    if in_img_type == np.uint8:\n        rlt = rlt.round()\n    else:\n        rlt /= 255.\n    return rlt.astype(in_img_type)\n\n\ndef channel_convert(in_c, tar_type, img_list):\n    # conversion among BGR, gray and y\n    if in_c == 3 and tar_type == \'gray\':  # BGR to gray\n        gray_list = [cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in img_list]\n        return [np.expand_dims(img, axis=2) for img in gray_list]\n    elif in_c == 3 and tar_type == \'y\':  # BGR to y\n        y_list = [bgr2ycbcr(img, only_y=True) for img in img_list]\n        return [np.expand_dims(img, axis=2) for img in y_list]\n    elif in_c == 1 and tar_type == \'RGB\':  # gray/y to BGR\n        return [cv2.cvtColor(img, cv2.COLOR_GRAY2BGR) for img in img_list]\n    else:\n        return img_list\n\n\n\'\'\'\n# --------------------------------------------\n# metric, PSNR and SSIM\n# --------------------------------------------\n\'\'\'\n\n\n# --------------------------------------------\n# PSNR\n# --------------------------------------------\ndef calculate_psnr(img1, img2, border=0):\n    # img1 and img2 have range [0, 255]\n    #img1 = img1.squeeze()\n    #img2 = img2.squeeze()\n    if not img1.shape == img2.shape:\n        raise ValueError(\'Input images must have the same dimensions.\')\n    h, w = img1.shape[:2]\n    img1 = img1[border:h-border, border:w-border]\n    img2 = img2[border:h-border, border:w-border]\n\n    img1 = img1.astype(np.float64)\n    img2 = img2.astype(np.float64)\n    mse = np.mean((img1 - img2)**2)\n    if mse == 0:\n        return float(\'inf\')\n    return 20 * math.log10(255.0 / math.sqrt(mse))\n\n\n# --------------------------------------------\n# SSIM\n# --------------------------------------------\ndef calculate_ssim(img1, img2, border=0):\n    \'\'\'calculate SSIM\n    the same outputs as MATLAB\'s\n    img1, img2: [0, 255]\n    \'\'\'\n    #img1 = img1.squeeze()\n    #img2 = img2.squeeze()\n    if not img1.shape == img2.shape:\n        raise ValueError(\'Input images must have the same dimensions.\')\n    h, w = img1.shape[:2]\n    img1 = img1[border:h-border, border:w-border]\n    img2 = img2[border:h-border, border:w-border]\n\n    if img1.ndim == 2:\n        return ssim(img1, img2)\n    elif img1.ndim == 3:\n        if img1.shape[2] == 3:\n            ssims = []\n            for i in range(3):\n                ssims.append(ssim(img1[:,:,i], img2[:,:,i]))\n            return np.array(ssims).mean()\n        elif img1.shape[2] == 1:\n            return ssim(np.squeeze(img1), np.squeeze(img2))\n    else:\n        raise ValueError(\'Wrong input image dimensions.\')\n\n\ndef ssim(img1, img2):\n    C1 = (0.01 * 255)**2\n    C2 = (0.03 * 255)**2\n\n    img1 = img1.astype(np.float64)\n    img2 = img2.astype(np.float64)\n    kernel = cv2.getGaussianKernel(11, 1.5)\n    window = np.outer(kernel, kernel.transpose())\n\n    mu1 = cv2.filter2D(img1, -1, window)[5:-5, 5:-5]  # valid\n    mu2 = cv2.filter2D(img2, -1, window)[5:-5, 5:-5]\n    mu1_sq = mu1**2\n    mu2_sq = mu2**2\n    mu1_mu2 = mu1 * mu2\n    sigma1_sq = cv2.filter2D(img1**2, -1, window)[5:-5, 5:-5] - mu1_sq\n    sigma2_sq = cv2.filter2D(img2**2, -1, window)[5:-5, 5:-5] - mu2_sq\n    sigma12 = cv2.filter2D(img1 * img2, -1, window)[5:-5, 5:-5] - mu1_mu2\n\n    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) *\n                                                            (sigma1_sq + sigma2_sq + C2))\n    return ssim_map.mean()\n\n\n\'\'\'\n# --------------------------------------------\n# matlab\'s bicubic imresize (numpy and torch) [0, 1]\n# --------------------------------------------\n\'\'\'\n\n\n# matlab \'imresize\' function, now only support \'bicubic\'\ndef cubic(x):\n    absx = torch.abs(x)\n    absx2 = absx**2\n    absx3 = absx**3\n    return (1.5*absx3 - 2.5*absx2 + 1) * ((absx <= 1).type_as(absx)) + \\\n        (-0.5*absx3 + 2.5*absx2 - 4*absx + 2) * (((absx > 1)*(absx <= 2)).type_as(absx))\n\n\ndef calculate_weights_indices(in_length, out_length, scale, kernel, kernel_width, antialiasing):\n    if (scale < 1) and (antialiasing):\n        # Use a modified kernel to simultaneously interpolate and antialias- larger kernel width\n        kernel_width = kernel_width / scale\n\n    # Output-space coordinates\n    x = torch.linspace(1, out_length, out_length)\n\n    # Input-space coordinates. Calculate the inverse mapping such that 0.5\n    # in output space maps to 0.5 in input space, and 0.5+scale in output\n    # space maps to 1.5 in input space.\n    u = x / scale + 0.5 * (1 - 1 / scale)\n\n    # What is the left-most pixel that can be involved in the computation?\n    left = torch.floor(u - kernel_width / 2)\n\n    # What is the maximum number of pixels that can be involved in the\n    # computation?  Note: it\'s OK to use an extra pixel here; if the\n    # corresponding weights are all zero, it will be eliminated at the end\n    # of this function.\n    P = math.ceil(kernel_width) + 2\n\n    # The indices of the input pixels involved in computing the k-th output\n    # pixel are in row k of the indices matrix.\n    indices = left.view(out_length, 1).expand(out_length, P) + torch.linspace(0, P - 1, P).view(\n        1, P).expand(out_length, P)\n\n    # The weights used to compute the k-th output pixel are in row k of the\n    # weights matrix.\n    distance_to_center = u.view(out_length, 1).expand(out_length, P) - indices\n    # apply cubic kernel\n    if (scale < 1) and (antialiasing):\n        weights = scale * cubic(distance_to_center * scale)\n    else:\n        weights = cubic(distance_to_center)\n    # Normalize the weights matrix so that each row sums to 1.\n    weights_sum = torch.sum(weights, 1).view(out_length, 1)\n    weights = weights / weights_sum.expand(out_length, P)\n\n    # If a column in weights is all zero, get rid of it. only consider the first and last column.\n    weights_zero_tmp = torch.sum((weights == 0), 0)\n    if not math.isclose(weights_zero_tmp[0], 0, rel_tol=1e-6):\n        indices = indices.narrow(1, 1, P - 2)\n        weights = weights.narrow(1, 1, P - 2)\n    if not math.isclose(weights_zero_tmp[-1], 0, rel_tol=1e-6):\n        indices = indices.narrow(1, 0, P - 2)\n        weights = weights.narrow(1, 0, P - 2)\n    weights = weights.contiguous()\n    indices = indices.contiguous()\n    sym_len_s = -indices.min() + 1\n    sym_len_e = indices.max() - in_length\n    indices = indices + sym_len_s - 1\n    return weights, indices, int(sym_len_s), int(sym_len_e)\n\n\n# --------------------------------------------\n# imresize for tensor image [0, 1]\n# --------------------------------------------\ndef imresize(img, scale, antialiasing=True):\n    # Now the scale should be the same for H and W\n    # input: img: pytorch tensor, CHW or HW [0,1]\n    # output: CHW or HW [0,1] w/o round\n    need_squeeze = True if img.dim() == 2 else False\n    if need_squeeze:\n        img.unsqueeze_(0)\n    in_C, in_H, in_W = img.size()\n    out_C, out_H, out_W = in_C, math.ceil(in_H * scale), math.ceil(in_W * scale)\n    kernel_width = 4\n    kernel = \'cubic\'\n\n    # Return the desired dimension order for performing the resize.  The\n    # strategy is to perform the resize first along the dimension with the\n    # smallest scale factor.\n    # Now we do not support this.\n\n    # get weights and indices\n    weights_H, indices_H, sym_len_Hs, sym_len_He = calculate_weights_indices(\n        in_H, out_H, scale, kernel, kernel_width, antialiasing)\n    weights_W, indices_W, sym_len_Ws, sym_len_We = calculate_weights_indices(\n        in_W, out_W, scale, kernel, kernel_width, antialiasing)\n    # process H dimension\n    # symmetric copying\n    img_aug = torch.FloatTensor(in_C, in_H + sym_len_Hs + sym_len_He, in_W)\n    img_aug.narrow(1, sym_len_Hs, in_H).copy_(img)\n\n    sym_patch = img[:, :sym_len_Hs, :]\n    inv_idx = torch.arange(sym_patch.size(1) - 1, -1, -1).long()\n    sym_patch_inv = sym_patch.index_select(1, inv_idx)\n    img_aug.narrow(1, 0, sym_len_Hs).copy_(sym_patch_inv)\n\n    sym_patch = img[:, -sym_len_He:, :]\n    inv_idx = torch.arange(sym_patch.size(1) - 1, -1, -1).long()\n    sym_patch_inv = sym_patch.index_select(1, inv_idx)\n    img_aug.narrow(1, sym_len_Hs + in_H, sym_len_He).copy_(sym_patch_inv)\n\n    out_1 = torch.FloatTensor(in_C, out_H, in_W)\n    kernel_width = weights_H.size(1)\n    for i in range(out_H):\n        idx = int(indices_H[i][0])\n        for j in range(out_C):\n            out_1[j, i, :] = img_aug[j, idx:idx + kernel_width, :].transpose(0, 1).mv(weights_H[i])\n\n    # process W dimension\n    # symmetric copying\n    out_1_aug = torch.FloatTensor(in_C, out_H, in_W + sym_len_Ws + sym_len_We)\n    out_1_aug.narrow(2, sym_len_Ws, in_W).copy_(out_1)\n\n    sym_patch = out_1[:, :, :sym_len_Ws]\n    inv_idx = torch.arange(sym_patch.size(2) - 1, -1, -1).long()\n    sym_patch_inv = sym_patch.index_select(2, inv_idx)\n    out_1_aug.narrow(2, 0, sym_len_Ws).copy_(sym_patch_inv)\n\n    sym_patch = out_1[:, :, -sym_len_We:]\n    inv_idx = torch.arange(sym_patch.size(2) - 1, -1, -1).long()\n    sym_patch_inv = sym_patch.index_select(2, inv_idx)\n    out_1_aug.narrow(2, sym_len_Ws + in_W, sym_len_We).copy_(sym_patch_inv)\n\n    out_2 = torch.FloatTensor(in_C, out_H, out_W)\n    kernel_width = weights_W.size(1)\n    for i in range(out_W):\n        idx = int(indices_W[i][0])\n        for j in range(out_C):\n            out_2[j, :, i] = out_1_aug[j, :, idx:idx + kernel_width].mv(weights_W[i])\n    if need_squeeze:\n        out_2.squeeze_()\n    return out_2\n\n\n# --------------------------------------------\n# imresize for numpy image [0, 1]\n# --------------------------------------------\ndef imresize_np(img, scale, antialiasing=True):\n    # Now the scale should be the same for H and W\n    # input: img: Numpy, HWC or HW [0,1]\n    # output: HWC or HW [0,1] w/o round\n    img = torch.from_numpy(img)\n    need_squeeze = True if img.dim() == 2 else False\n    if need_squeeze:\n        img.unsqueeze_(2)\n\n    in_H, in_W, in_C = img.size()\n    out_C, out_H, out_W = in_C, math.ceil(in_H * scale), math.ceil(in_W * scale)\n    kernel_width = 4\n    kernel = \'cubic\'\n\n    # Return the desired dimension order for performing the resize.  The\n    # strategy is to perform the resize first along the dimension with the\n    # smallest scale factor.\n    # Now we do not support this.\n\n    # get weights and indices\n    weights_H, indices_H, sym_len_Hs, sym_len_He = calculate_weights_indices(\n        in_H, out_H, scale, kernel, kernel_width, antialiasing)\n    weights_W, indices_W, sym_len_Ws, sym_len_We = calculate_weights_indices(\n        in_W, out_W, scale, kernel, kernel_width, antialiasing)\n    # process H dimension\n    # symmetric copying\n    img_aug = torch.FloatTensor(in_H + sym_len_Hs + sym_len_He, in_W, in_C)\n    img_aug.narrow(0, sym_len_Hs, in_H).copy_(img)\n\n    sym_patch = img[:sym_len_Hs, :, :]\n    inv_idx = torch.arange(sym_patch.size(0) - 1, -1, -1).long()\n    sym_patch_inv = sym_patch.index_select(0, inv_idx)\n    img_aug.narrow(0, 0, sym_len_Hs).copy_(sym_patch_inv)\n\n    sym_patch = img[-sym_len_He:, :, :]\n    inv_idx = torch.arange(sym_patch.size(0) - 1, -1, -1).long()\n    sym_patch_inv = sym_patch.index_select(0, inv_idx)\n    img_aug.narrow(0, sym_len_Hs + in_H, sym_len_He).copy_(sym_patch_inv)\n\n    out_1 = torch.FloatTensor(out_H, in_W, in_C)\n    kernel_width = weights_H.size(1)\n    for i in range(out_H):\n        idx = int(indices_H[i][0])\n        for j in range(out_C):\n            out_1[i, :, j] = img_aug[idx:idx + kernel_width, :, j].transpose(0, 1).mv(weights_H[i])\n\n    # process W dimension\n    # symmetric copying\n    out_1_aug = torch.FloatTensor(out_H, in_W + sym_len_Ws + sym_len_We, in_C)\n    out_1_aug.narrow(1, sym_len_Ws, in_W).copy_(out_1)\n\n    sym_patch = out_1[:, :sym_len_Ws, :]\n    inv_idx = torch.arange(sym_patch.size(1) - 1, -1, -1).long()\n    sym_patch_inv = sym_patch.index_select(1, inv_idx)\n    out_1_aug.narrow(1, 0, sym_len_Ws).copy_(sym_patch_inv)\n\n    sym_patch = out_1[:, -sym_len_We:, :]\n    inv_idx = torch.arange(sym_patch.size(1) - 1, -1, -1).long()\n    sym_patch_inv = sym_patch.index_select(1, inv_idx)\n    out_1_aug.narrow(1, sym_len_Ws + in_W, sym_len_We).copy_(sym_patch_inv)\n\n    out_2 = torch.FloatTensor(out_H, out_W, in_C)\n    kernel_width = weights_W.size(1)\n    for i in range(out_W):\n        idx = int(indices_W[i][0])\n        for j in range(out_C):\n            out_2[:, i, j] = out_1_aug[:, idx:idx + kernel_width, j].mv(weights_W[i])\n    if need_squeeze:\n        out_2.squeeze_()\n\n    return out_2.numpy()\n\n\nif __name__ == \'__main__\':\n    print(\'---\')\n#    img = imread_uint(\'test.bmp\', 3)\n#    img = uint2single(img)\n#    img_bicubic = imresize_np(img, 1/4)',
    'model.ldm.modules.losses': 'from model.ldm.modules.losses.contperceptual import LPIPSWithDiscriminator',
    'model.ldm.modules.losses.contperceptual': 'import torch\nimport torch.nn as nn\n\nfrom taming.modules.losses.vqperceptual import *  # TODO: taming dependency yes/no?\n\n\nclass LPIPSWithDiscriminator(nn.Module):\n    def __init__(self, disc_start, logvar_init=0.0, kl_weight=1.0, pixelloss_weight=1.0,\n                 disc_num_layers=3, disc_in_channels=3, disc_factor=1.0, disc_weight=1.0,\n                 perceptual_weight=1.0, use_actnorm=False, disc_conditional=False,\n                 disc_loss="hinge"):\n\n        super().__init__()\n        assert disc_loss in ["hinge", "vanilla"]\n        self.kl_weight = kl_weight\n        self.pixel_weight = pixelloss_weight\n        self.perceptual_loss = LPIPS().eval()\n        self.perceptual_weight = perceptual_weight\n        # output log variance\n        self.logvar = nn.Parameter(torch.ones(size=()) * logvar_init)\n\n        self.discriminator = NLayerDiscriminator(input_nc=disc_in_channels,\n                                                 n_layers=disc_num_layers,\n                                                 use_actnorm=use_actnorm\n                                                 ).apply(weights_init)\n        self.discriminator_iter_start = disc_start\n        self.disc_loss = hinge_d_loss if disc_loss == "hinge" else vanilla_d_loss\n        self.disc_factor = disc_factor\n        self.discriminator_weight = disc_weight\n        self.disc_conditional = disc_conditional\n\n    def calculate_adaptive_weight(self, nll_loss, g_loss, last_layer=None):\n        if last_layer is not None:\n            nll_grads = torch.autograd.grad(nll_loss, last_layer, retain_graph=True)[0]\n            g_grads = torch.autograd.grad(g_loss, last_layer, retain_graph=True)[0]\n        else:\n            nll_grads = torch.autograd.grad(nll_loss, self.last_layer[0], retain_graph=True)[0]\n            g_grads = torch.autograd.grad(g_loss, self.last_layer[0], retain_graph=True)[0]\n\n        d_weight = torch.norm(nll_grads) / (torch.norm(g_grads) + 1e-4)\n        d_weight = torch.clamp(d_weight, 0.0, 1e4).detach()\n        d_weight = d_weight * self.discriminator_weight\n        return d_weight\n\n    def forward(self, inputs, reconstructions, posteriors, optimizer_idx,\n                global_step, last_layer=None, cond=None, split="train",\n                weights=None):\n        rec_loss = torch.abs(inputs.contiguous() - reconstructions.contiguous())\n        if self.perceptual_weight > 0:\n            p_loss = self.perceptual_loss(inputs.contiguous(), reconstructions.contiguous())\n            rec_loss = rec_loss + self.perceptual_weight * p_loss\n\n        nll_loss = rec_loss / torch.exp(self.logvar) + self.logvar\n        weighted_nll_loss = nll_loss\n        if weights is not None:\n            weighted_nll_loss = weights*nll_loss\n        weighted_nll_loss = torch.sum(weighted_nll_loss) / weighted_nll_loss.shape[0]\n        nll_loss = torch.sum(nll_loss) / nll_loss.shape[0]\n        kl_loss = posteriors.kl()\n        kl_loss = torch.sum(kl_loss) / kl_loss.shape[0]\n\n        # now the GAN part\n        if optimizer_idx == 0:\n            # generator update\n            if cond is None:\n                assert not self.disc_conditional\n                logits_fake = self.discriminator(reconstructions.contiguous())\n            else:\n                assert self.disc_conditional\n                logits_fake = self.discriminator(torch.cat((reconstructions.contiguous(), cond), dim=1))\n            g_loss = -torch.mean(logits_fake)\n\n            if self.disc_factor > 0.0:\n                try:\n                    d_weight = self.calculate_adaptive_weight(nll_loss, g_loss, last_layer=last_layer)\n                except RuntimeError:\n                    assert not self.training\n                    d_weight = torch.tensor(0.0)\n            else:\n                d_weight = torch.tensor(0.0)\n\n            disc_factor = adopt_weight(self.disc_factor, global_step, threshold=self.discriminator_iter_start)\n            loss = weighted_nll_loss + self.kl_weight * kl_loss + d_weight * disc_factor * g_loss\n\n            log = {"{}/total_loss".format(split): loss.clone().detach().mean(), "{}/logvar".format(split): self.logvar.detach(),\n                   "{}/kl_loss".format(split): kl_loss.detach().mean(), "{}/nll_loss".format(split): nll_loss.detach().mean(),\n                   "{}/rec_loss".format(split): rec_loss.detach().mean(),\n                   "{}/d_weight".format(split): d_weight.detach(),\n                   "{}/disc_factor".format(split): torch.tensor(disc_factor),\n                   "{}/g_loss".format(split): g_loss.detach().mean(),\n                   }\n            return loss, log\n\n        if optimizer_idx == 1:\n            # second pass for discriminator update\n            if cond is None:\n                logits_real = self.discriminator(inputs.contiguous().detach())\n                logits_fake = self.discriminator(reconstructions.contiguous().detach())\n            else:\n                logits_real = self.discriminator(torch.cat((inputs.contiguous().detach(), cond), dim=1))\n                logits_fake = self.discriminator(torch.cat((reconstructions.contiguous().detach(), cond), dim=1))\n\n            disc_factor = adopt_weight(self.disc_factor, global_step, threshold=self.discriminator_iter_start)\n            d_loss = disc_factor * self.disc_loss(logits_real, logits_fake)\n\n            log = {"{}/disc_loss".format(split): d_loss.clone().detach().mean(),\n                   "{}/logits_real".format(split): logits_real.detach().mean(),\n                   "{}/logits_fake".format(split): logits_fake.detach().mean()\n                   }\n            return d_loss, log\n\n',
    'model.ldm.modules.losses.vqperceptual': 'import torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom einops import repeat\n\nfrom taming.modules.discriminator.model import NLayerDiscriminator, weights_init\nfrom taming.modules.losses.lpips import LPIPS\nfrom taming.modules.losses.vqperceptual import hinge_d_loss, vanilla_d_loss\n\n\ndef hinge_d_loss_with_exemplar_weights(logits_real, logits_fake, weights):\n    assert weights.shape[0] == logits_real.shape[0] == logits_fake.shape[0]\n    loss_real = torch.mean(F.relu(1. - logits_real), dim=[1,2,3])\n    loss_fake = torch.mean(F.relu(1. + logits_fake), dim=[1,2,3])\n    loss_real = (weights * loss_real).sum() / weights.sum()\n    loss_fake = (weights * loss_fake).sum() / weights.sum()\n    d_loss = 0.5 * (loss_real + loss_fake)\n    return d_loss\n\ndef adopt_weight(weight, global_step, threshold=0, value=0.):\n    if global_step < threshold:\n        weight = value\n    return weight\n\n\ndef measure_perplexity(predicted_indices, n_embed):\n    # src: https://github.com/karpathy/deep-vector-quantization/blob/main/model.py\n    # eval cluster perplexity. when perplexity == num_embeddings then all clusters are used exactly equally\n    encodings = F.one_hot(predicted_indices, n_embed).float().reshape(-1, n_embed)\n    avg_probs = encodings.mean(0)\n    perplexity = (-(avg_probs * torch.log(avg_probs + 1e-10)).sum()).exp()\n    cluster_use = torch.sum(avg_probs > 0)\n    return perplexity, cluster_use\n\ndef l1(x, y):\n    return torch.abs(x-y)\n\n\ndef l2(x, y):\n    return torch.pow((x-y), 2)\n\n\nclass VQLPIPSWithDiscriminator(nn.Module):\n    def __init__(self, disc_start, codebook_weight=1.0, pixelloss_weight=1.0,\n                 disc_num_layers=3, disc_in_channels=3, disc_factor=1.0, disc_weight=1.0,\n                 perceptual_weight=1.0, use_actnorm=False, disc_conditional=False,\n                 disc_ndf=64, disc_loss="hinge", n_classes=None, perceptual_loss="lpips",\n                 pixel_loss="l1"):\n        super().__init__()\n        assert disc_loss in ["hinge", "vanilla"]\n        assert perceptual_loss in ["lpips", "clips", "dists"]\n        assert pixel_loss in ["l1", "l2"]\n        self.codebook_weight = codebook_weight\n        self.pixel_weight = pixelloss_weight\n        if perceptual_loss == "lpips":\n            print(f"{self.__class__.__name__}: Running with LPIPS.")\n            self.perceptual_loss = LPIPS().eval()\n        else:\n            raise ValueError(f"Unknown perceptual loss: >> {perceptual_loss} <<")\n        self.perceptual_weight = perceptual_weight\n\n        if pixel_loss == "l1":\n            self.pixel_loss = l1\n        else:\n            self.pixel_loss = l2\n\n        self.discriminator = NLayerDiscriminator(input_nc=disc_in_channels,\n                                                 n_layers=disc_num_layers,\n                                                 use_actnorm=use_actnorm,\n                                                 ndf=disc_ndf\n                                                 ).apply(weights_init)\n        self.discriminator_iter_start = disc_start\n        if disc_loss == "hinge":\n            self.disc_loss = hinge_d_loss\n        elif disc_loss == "vanilla":\n            self.disc_loss = vanilla_d_loss\n        else:\n            raise ValueError(f"Unknown GAN loss \'{disc_loss}\'.")\n        print(f"VQLPIPSWithDiscriminator running with {disc_loss} loss.")\n        self.disc_factor = disc_factor\n        self.discriminator_weight = disc_weight\n        self.disc_conditional = disc_conditional\n        self.n_classes = n_classes\n\n    def calculate_adaptive_weight(self, nll_loss, g_loss, last_layer=None):\n        if last_layer is not None:\n            nll_grads = torch.autograd.grad(nll_loss, last_layer, retain_graph=True)[0]\n            g_grads = torch.autograd.grad(g_loss, last_layer, retain_graph=True)[0]\n        else:\n            nll_grads = torch.autograd.grad(nll_loss, self.last_layer[0], retain_graph=True)[0]\n            g_grads = torch.autograd.grad(g_loss, self.last_layer[0], retain_graph=True)[0]\n\n        d_weight = torch.norm(nll_grads) / (torch.norm(g_grads) + 1e-4)\n        d_weight = torch.clamp(d_weight, 0.0, 1e4).detach()\n        d_weight = d_weight * self.discriminator_weight\n        return d_weight\n\n    def forward(self, codebook_loss, inputs, reconstructions, optimizer_idx,\n                global_step, last_layer=None, cond=None, split="train", predicted_indices=None):\n        if not exists(codebook_loss):\n            codebook_loss = torch.tensor([0.]).to(inputs.device)\n        #rec_loss = torch.abs(inputs.contiguous() - reconstructions.contiguous())\n        rec_loss = self.pixel_loss(inputs.contiguous(), reconstructions.contiguous())\n        if self.perceptual_weight > 0:\n            p_loss = self.perceptual_loss(inputs.contiguous(), reconstructions.contiguous())\n            rec_loss = rec_loss + self.perceptual_weight * p_loss\n        else:\n            p_loss = torch.tensor([0.0])\n\n        nll_loss = rec_loss\n        #nll_loss = torch.sum(nll_loss) / nll_loss.shape[0]\n        nll_loss = torch.mean(nll_loss)\n\n        # now the GAN part\n        if optimizer_idx == 0:\n            # generator update\n            if cond is None:\n                assert not self.disc_conditional\n                logits_fake = self.discriminator(reconstructions.contiguous())\n            else:\n                assert self.disc_conditional\n                logits_fake = self.discriminator(torch.cat((reconstructions.contiguous(), cond), dim=1))\n            g_loss = -torch.mean(logits_fake)\n\n            try:\n                d_weight = self.calculate_adaptive_weight(nll_loss, g_loss, last_layer=last_layer)\n            except RuntimeError:\n                assert not self.training\n                d_weight = torch.tensor(0.0)\n\n            disc_factor = adopt_weight(self.disc_factor, global_step, threshold=self.discriminator_iter_start)\n            loss = nll_loss + d_weight * disc_factor * g_loss + self.codebook_weight * codebook_loss.mean()\n\n            log = {"{}/total_loss".format(split): loss.clone().detach().mean(),\n                   "{}/quant_loss".format(split): codebook_loss.detach().mean(),\n                   "{}/nll_loss".format(split): nll_loss.detach().mean(),\n                   "{}/rec_loss".format(split): rec_loss.detach().mean(),\n                   "{}/p_loss".format(split): p_loss.detach().mean(),\n                   "{}/d_weight".format(split): d_weight.detach(),\n                   "{}/disc_factor".format(split): torch.tensor(disc_factor),\n                   "{}/g_loss".format(split): g_loss.detach().mean(),\n                   }\n            if predicted_indices is not None:\n                assert self.n_classes is not None\n                with torch.no_grad():\n                    perplexity, cluster_usage = measure_perplexity(predicted_indices, self.n_classes)\n                log[f"{split}/perplexity"] = perplexity\n                log[f"{split}/cluster_usage"] = cluster_usage\n            return loss, log\n\n        if optimizer_idx == 1:\n            # second pass for discriminator update\n            if cond is None:\n                logits_real = self.discriminator(inputs.contiguous().detach())\n                logits_fake = self.discriminator(reconstructions.contiguous().detach())\n            else:\n                logits_real = self.discriminator(torch.cat((inputs.contiguous().detach(), cond), dim=1))\n                logits_fake = self.discriminator(torch.cat((reconstructions.contiguous().detach(), cond), dim=1))\n\n            disc_factor = adopt_weight(self.disc_factor, global_step, threshold=self.discriminator_iter_start)\n            d_loss = disc_factor * self.disc_loss(logits_real, logits_fake)\n\n            log = {"{}/disc_loss".format(split): d_loss.clone().detach().mean(),\n                   "{}/logits_real".format(split): logits_real.detach().mean(),\n                   "{}/logits_fake".format(split): logits_fake.detach().mean()\n                   }\n            return d_loss, log\n',
    'model.ldm.modules.x_transformer': '"""shout-out to https://github.com/lucidrains/x-transformers/tree/main/x_transformers"""\nimport torch\nfrom torch import nn, einsum\nimport torch.nn.functional as F\nfrom functools import partial\nfrom inspect import isfunction\nfrom collections import namedtuple\nfrom einops import rearrange, repeat, reduce\n\n# constants\n\nDEFAULT_DIM_HEAD = 64\n\nIntermediates = namedtuple(\'Intermediates\', [\n    \'pre_softmax_attn\',\n    \'post_softmax_attn\'\n])\n\nLayerIntermediates = namedtuple(\'Intermediates\', [\n    \'hiddens\',\n    \'attn_intermediates\'\n])\n\n\nclass AbsolutePositionalEmbedding(nn.Module):\n    def __init__(self, dim, max_seq_len):\n        super().__init__()\n        self.emb = nn.Embedding(max_seq_len, dim)\n        self.init_()\n\n    def init_(self):\n        nn.init.normal_(self.emb.weight, std=0.02)\n\n    def forward(self, x):\n        n = torch.arange(x.shape[1], device=x.device)\n        return self.emb(n)[None, :, :]\n\n\nclass FixedPositionalEmbedding(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        inv_freq = 1. / (10000 ** (torch.arange(0, dim, 2).float() / dim))\n        self.register_buffer(\'inv_freq\', inv_freq)\n\n    def forward(self, x, seq_dim=1, offset=0):\n        t = torch.arange(x.shape[seq_dim], device=x.device).type_as(self.inv_freq) + offset\n        sinusoid_inp = torch.einsum(\'i , j -> i j\', t, self.inv_freq)\n        emb = torch.cat((sinusoid_inp.sin(), sinusoid_inp.cos()), dim=-1)\n        return emb[None, :, :]\n\n\n# helpers\n\ndef exists(val):\n    return val is not None\n\n\ndef default(val, d):\n    if exists(val):\n        return val\n    return d() if isfunction(d) else d\n\n\ndef always(val):\n    def inner(*args, **kwargs):\n        return val\n    return inner\n\n\ndef not_equals(val):\n    def inner(x):\n        return x != val\n    return inner\n\n\ndef equals(val):\n    def inner(x):\n        return x == val\n    return inner\n\n\ndef max_neg_value(tensor):\n    return -torch.finfo(tensor.dtype).max\n\n\n# keyword argument helpers\n\ndef pick_and_pop(keys, d):\n    values = list(map(lambda key: d.pop(key), keys))\n    return dict(zip(keys, values))\n\n\ndef group_dict_by_key(cond, d):\n    return_val = [dict(), dict()]\n    for key in d.keys():\n        match = bool(cond(key))\n        ind = int(not match)\n        return_val[ind][key] = d[key]\n    return (*return_val,)\n\n\ndef string_begins_with(prefix, str):\n    return str.startswith(prefix)\n\n\ndef group_by_key_prefix(prefix, d):\n    return group_dict_by_key(partial(string_begins_with, prefix), d)\n\n\ndef groupby_prefix_and_trim(prefix, d):\n    kwargs_with_prefix, kwargs = group_dict_by_key(partial(string_begins_with, prefix), d)\n    kwargs_without_prefix = dict(map(lambda x: (x[0][len(prefix):], x[1]), tuple(kwargs_with_prefix.items())))\n    return kwargs_without_prefix, kwargs\n\n\n# classes\nclass Scale(nn.Module):\n    def __init__(self, value, fn):\n        super().__init__()\n        self.value = value\n        self.fn = fn\n\n    def forward(self, x, **kwargs):\n        x, *rest = self.fn(x, **kwargs)\n        return (x * self.value, *rest)\n\n\nclass Rezero(nn.Module):\n    def __init__(self, fn):\n        super().__init__()\n        self.fn = fn\n        self.g = nn.Parameter(torch.zeros(1))\n\n    def forward(self, x, **kwargs):\n        x, *rest = self.fn(x, **kwargs)\n        return (x * self.g, *rest)\n\n\nclass ScaleNorm(nn.Module):\n    def __init__(self, dim, eps=1e-5):\n        super().__init__()\n        self.scale = dim ** -0.5\n        self.eps = eps\n        self.g = nn.Parameter(torch.ones(1))\n\n    def forward(self, x):\n        norm = torch.norm(x, dim=-1, keepdim=True) * self.scale\n        return x / norm.clamp(min=self.eps) * self.g\n\n\nclass RMSNorm(nn.Module):\n    def __init__(self, dim, eps=1e-8):\n        super().__init__()\n        self.scale = dim ** -0.5\n        self.eps = eps\n        self.g = nn.Parameter(torch.ones(dim))\n\n    def forward(self, x):\n        norm = torch.norm(x, dim=-1, keepdim=True) * self.scale\n        return x / norm.clamp(min=self.eps) * self.g\n\n\nclass Residual(nn.Module):\n    def forward(self, x, residual):\n        return x + residual\n\n\nclass GRUGating(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        self.gru = nn.GRUCell(dim, dim)\n\n    def forward(self, x, residual):\n        gated_output = self.gru(\n            rearrange(x, \'b n d -> (b n) d\'),\n            rearrange(residual, \'b n d -> (b n) d\')\n        )\n\n        return gated_output.reshape_as(x)\n\n\n# feedforward\n\nclass GEGLU(nn.Module):\n    def __init__(self, dim_in, dim_out):\n        super().__init__()\n        self.proj = nn.Linear(dim_in, dim_out * 2)\n\n    def forward(self, x):\n        x, gate = self.proj(x).chunk(2, dim=-1)\n        return x * F.gelu(gate)\n\n\nclass FeedForward(nn.Module):\n    def __init__(self, dim, dim_out=None, mult=4, glu=False, dropout=0.):\n        super().__init__()\n        inner_dim = int(dim * mult)\n        dim_out = default(dim_out, dim)\n        project_in = nn.Sequential(\n            nn.Linear(dim, inner_dim),\n            nn.GELU()\n        ) if not glu else GEGLU(dim, inner_dim)\n\n        self.net = nn.Sequential(\n            project_in,\n            nn.Dropout(dropout),\n            nn.Linear(inner_dim, dim_out)\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\n\n# attention.\nclass Attention(nn.Module):\n    def __init__(\n            self,\n            dim,\n            dim_head=DEFAULT_DIM_HEAD,\n            heads=8,\n            causal=False,\n            mask=None,\n            talking_heads=False,\n            sparse_topk=None,\n            use_entmax15=False,\n            num_mem_kv=0,\n            dropout=0.,\n            on_attn=False\n    ):\n        super().__init__()\n        if use_entmax15:\n            raise NotImplementedError("Check out entmax activation instead of softmax activation!")\n        self.scale = dim_head ** -0.5\n        self.heads = heads\n        self.causal = causal\n        self.mask = mask\n\n        inner_dim = dim_head * heads\n\n        self.to_q = nn.Linear(dim, inner_dim, bias=False)\n        self.to_k = nn.Linear(dim, inner_dim, bias=False)\n        self.to_v = nn.Linear(dim, inner_dim, bias=False)\n        self.dropout = nn.Dropout(dropout)\n\n        # talking heads\n        self.talking_heads = talking_heads\n        if talking_heads:\n            self.pre_softmax_proj = nn.Parameter(torch.randn(heads, heads))\n            self.post_softmax_proj = nn.Parameter(torch.randn(heads, heads))\n\n        # explicit topk sparse attention\n        self.sparse_topk = sparse_topk\n\n        # entmax\n        #self.attn_fn = entmax15 if use_entmax15 else F.softmax\n        self.attn_fn = F.softmax\n\n        # add memory key / values\n        self.num_mem_kv = num_mem_kv\n        if num_mem_kv > 0:\n            self.mem_k = nn.Parameter(torch.randn(heads, num_mem_kv, dim_head))\n            self.mem_v = nn.Parameter(torch.randn(heads, num_mem_kv, dim_head))\n\n        # attention on attention\n        self.attn_on_attn = on_attn\n        self.to_out = nn.Sequential(nn.Linear(inner_dim, dim * 2), nn.GLU()) if on_attn else nn.Linear(inner_dim, dim)\n\n    def forward(\n            self,\n            x,\n            context=None,\n            mask=None,\n            context_mask=None,\n            rel_pos=None,\n            sinusoidal_emb=None,\n            prev_attn=None,\n            mem=None\n    ):\n        b, n, _, h, talking_heads, device = *x.shape, self.heads, self.talking_heads, x.device\n        kv_input = default(context, x)\n\n        q_input = x\n        k_input = kv_input\n        v_input = kv_input\n\n        if exists(mem):\n            k_input = torch.cat((mem, k_input), dim=-2)\n            v_input = torch.cat((mem, v_input), dim=-2)\n\n        if exists(sinusoidal_emb):\n            # in shortformer, the query would start at a position offset depending on the past cached memory\n            offset = k_input.shape[-2] - q_input.shape[-2]\n            q_input = q_input + sinusoidal_emb(q_input, offset=offset)\n            k_input = k_input + sinusoidal_emb(k_input)\n\n        q = self.to_q(q_input)\n        k = self.to_k(k_input)\n        v = self.to_v(v_input)\n\n        q, k, v = map(lambda t: rearrange(t, \'b n (h d) -> b h n d\', h=h), (q, k, v))\n\n        input_mask = None\n        if any(map(exists, (mask, context_mask))):\n            q_mask = default(mask, lambda: torch.ones((b, n), device=device).bool())\n            k_mask = q_mask if not exists(context) else context_mask\n            k_mask = default(k_mask, lambda: torch.ones((b, k.shape[-2]), device=device).bool())\n            q_mask = rearrange(q_mask, \'b i -> b () i ()\')\n            k_mask = rearrange(k_mask, \'b j -> b () () j\')\n            input_mask = q_mask * k_mask\n\n        if self.num_mem_kv > 0:\n            mem_k, mem_v = map(lambda t: repeat(t, \'h n d -> b h n d\', b=b), (self.mem_k, self.mem_v))\n            k = torch.cat((mem_k, k), dim=-2)\n            v = torch.cat((mem_v, v), dim=-2)\n            if exists(input_mask):\n                input_mask = F.pad(input_mask, (self.num_mem_kv, 0), value=True)\n\n        dots = einsum(\'b h i d, b h j d -> b h i j\', q, k) * self.scale\n        mask_value = max_neg_value(dots)\n\n        if exists(prev_attn):\n            dots = dots + prev_attn\n\n        pre_softmax_attn = dots\n\n        if talking_heads:\n            dots = einsum(\'b h i j, h k -> b k i j\', dots, self.pre_softmax_proj).contiguous()\n\n        if exists(rel_pos):\n            dots = rel_pos(dots)\n\n        if exists(input_mask):\n            dots.masked_fill_(~input_mask, mask_value)\n            del input_mask\n\n        if self.causal:\n            i, j = dots.shape[-2:]\n            r = torch.arange(i, device=device)\n            mask = rearrange(r, \'i -> () () i ()\') < rearrange(r, \'j -> () () () j\')\n            mask = F.pad(mask, (j - i, 0), value=False)\n            dots.masked_fill_(mask, mask_value)\n            del mask\n\n        if exists(self.sparse_topk) and self.sparse_topk < dots.shape[-1]:\n            top, _ = dots.topk(self.sparse_topk, dim=-1)\n            vk = top[..., -1].unsqueeze(-1).expand_as(dots)\n            mask = dots < vk\n            dots.masked_fill_(mask, mask_value)\n            del mask\n\n        attn = self.attn_fn(dots, dim=-1)\n        post_softmax_attn = attn\n\n        attn = self.dropout(attn)\n\n        if talking_heads:\n            attn = einsum(\'b h i j, h k -> b k i j\', attn, self.post_softmax_proj).contiguous()\n\n        out = einsum(\'b h i j, b h j d -> b h i d\', attn, v)\n        out = rearrange(out, \'b h n d -> b n (h d)\')\n\n        intermediates = Intermediates(\n            pre_softmax_attn=pre_softmax_attn,\n            post_softmax_attn=post_softmax_attn\n        )\n\n        return self.to_out(out), intermediates\n\n\nclass AttentionLayers(nn.Module):\n    def __init__(\n            self,\n            dim,\n            depth,\n            heads=8,\n            causal=False,\n            cross_attend=False,\n            only_cross=False,\n            use_scalenorm=False,\n            use_rmsnorm=False,\n            use_rezero=False,\n            rel_pos_num_buckets=32,\n            rel_pos_max_distance=128,\n            position_infused_attn=False,\n            custom_layers=None,\n            sandwich_coef=None,\n            par_ratio=None,\n            residual_attn=False,\n            cross_residual_attn=False,\n            macaron=False,\n            pre_norm=True,\n            gate_residual=False,\n            **kwargs\n    ):\n        super().__init__()\n        ff_kwargs, kwargs = groupby_prefix_and_trim(\'ff_\', kwargs)\n        attn_kwargs, _ = groupby_prefix_and_trim(\'attn_\', kwargs)\n\n        dim_head = attn_kwargs.get(\'dim_head\', DEFAULT_DIM_HEAD)\n\n        self.dim = dim\n        self.depth = depth\n        self.layers = nn.ModuleList([])\n\n        self.has_pos_emb = position_infused_attn\n        self.pia_pos_emb = FixedPositionalEmbedding(dim) if position_infused_attn else None\n        self.rotary_pos_emb = always(None)\n\n        assert rel_pos_num_buckets <= rel_pos_max_distance, \'number of relative position buckets must be less than the relative position max distance\'\n        self.rel_pos = None\n\n        self.pre_norm = pre_norm\n\n        self.residual_attn = residual_attn\n        self.cross_residual_attn = cross_residual_attn\n\n        norm_class = ScaleNorm if use_scalenorm else nn.LayerNorm\n        norm_class = RMSNorm if use_rmsnorm else norm_class\n        norm_fn = partial(norm_class, dim)\n\n        norm_fn = nn.Identity if use_rezero else norm_fn\n        branch_fn = Rezero if use_rezero else None\n\n        if cross_attend and not only_cross:\n            default_block = (\'a\', \'c\', \'f\')\n        elif cross_attend and only_cross:\n            default_block = (\'c\', \'f\')\n        else:\n            default_block = (\'a\', \'f\')\n\n        if macaron:\n            default_block = (\'f\',) + default_block\n\n        if exists(custom_layers):\n            layer_types = custom_layers\n        elif exists(par_ratio):\n            par_depth = depth * len(default_block)\n            assert 1 < par_ratio <= par_depth, \'par ratio out of range\'\n            default_block = tuple(filter(not_equals(\'f\'), default_block))\n            par_attn = par_depth // par_ratio\n            depth_cut = par_depth * 2 // 3  # 2 / 3 attention layer cutoff suggested by PAR paper\n            par_width = (depth_cut + depth_cut // par_attn) // par_attn\n            assert len(default_block) <= par_width, \'default block is too large for par_ratio\'\n            par_block = default_block + (\'f\',) * (par_width - len(default_block))\n            par_head = par_block * par_attn\n            layer_types = par_head + (\'f\',) * (par_depth - len(par_head))\n        elif exists(sandwich_coef):\n            assert sandwich_coef > 0 and sandwich_coef <= depth, \'sandwich coefficient should be less than the depth\'\n            layer_types = (\'a\',) * sandwich_coef + default_block * (depth - sandwich_coef) + (\'f\',) * sandwich_coef\n        else:\n            layer_types = default_block * depth\n\n        self.layer_types = layer_types\n        self.num_attn_layers = len(list(filter(equals(\'a\'), layer_types)))\n\n        for layer_type in self.layer_types:\n            if layer_type == \'a\':\n                layer = Attention(dim, heads=heads, causal=causal, **attn_kwargs)\n            elif layer_type == \'c\':\n                layer = Attention(dim, heads=heads, **attn_kwargs)\n            elif layer_type == \'f\':\n                layer = FeedForward(dim, **ff_kwargs)\n                layer = layer if not macaron else Scale(0.5, layer)\n            else:\n                raise Exception(f\'invalid layer type {layer_type}\')\n\n            if isinstance(layer, Attention) and exists(branch_fn):\n                layer = branch_fn(layer)\n\n            if gate_residual:\n                residual_fn = GRUGating(dim)\n            else:\n                residual_fn = Residual()\n\n            self.layers.append(nn.ModuleList([\n                norm_fn(),\n                layer,\n                residual_fn\n            ]))\n\n    def forward(\n            self,\n            x,\n            context=None,\n            mask=None,\n            context_mask=None,\n            mems=None,\n            return_hiddens=False\n    ):\n        hiddens = []\n        intermediates = []\n        prev_attn = None\n        prev_cross_attn = None\n\n        mems = mems.copy() if exists(mems) else [None] * self.num_attn_layers\n\n        for ind, (layer_type, (norm, block, residual_fn)) in enumerate(zip(self.layer_types, self.layers)):\n            is_last = ind == (len(self.layers) - 1)\n\n            if layer_type == \'a\':\n                hiddens.append(x)\n                layer_mem = mems.pop(0)\n\n            residual = x\n\n            if self.pre_norm:\n                x = norm(x)\n\n            if layer_type == \'a\':\n                out, inter = block(x, mask=mask, sinusoidal_emb=self.pia_pos_emb, rel_pos=self.rel_pos,\n                                   prev_attn=prev_attn, mem=layer_mem)\n            elif layer_type == \'c\':\n                out, inter = block(x, context=context, mask=mask, context_mask=context_mask, prev_attn=prev_cross_attn)\n            elif layer_type == \'f\':\n                out = block(x)\n\n            x = residual_fn(out, residual)\n\n            if layer_type in (\'a\', \'c\'):\n                intermediates.append(inter)\n\n            if layer_type == \'a\' and self.residual_attn:\n                prev_attn = inter.pre_softmax_attn\n            elif layer_type == \'c\' and self.cross_residual_attn:\n                prev_cross_attn = inter.pre_softmax_attn\n\n            if not self.pre_norm and not is_last:\n                x = norm(x)\n\n        if return_hiddens:\n            intermediates = LayerIntermediates(\n                hiddens=hiddens,\n                attn_intermediates=intermediates\n            )\n\n            return x, intermediates\n\n        return x\n\n\nclass Encoder(AttentionLayers):\n    def __init__(self, **kwargs):\n        assert \'causal\' not in kwargs, \'cannot set causality on encoder\'\n        super().__init__(causal=False, **kwargs)\n\n\n\nclass TransformerWrapper(nn.Module):\n    def __init__(\n            self,\n            *,\n            num_tokens,\n            max_seq_len,\n            attn_layers,\n            emb_dim=None,\n            max_mem_len=0.,\n            emb_dropout=0.,\n            num_memory_tokens=None,\n            tie_embedding=False,\n            use_pos_emb=True\n    ):\n        super().__init__()\n        assert isinstance(attn_layers, AttentionLayers), \'attention layers must be one of Encoder or Decoder\'\n\n        dim = attn_layers.dim\n        emb_dim = default(emb_dim, dim)\n\n        self.max_seq_len = max_seq_len\n        self.max_mem_len = max_mem_len\n        self.num_tokens = num_tokens\n\n        self.token_emb = nn.Embedding(num_tokens, emb_dim)\n        self.pos_emb = AbsolutePositionalEmbedding(emb_dim, max_seq_len) if (\n                    use_pos_emb and not attn_layers.has_pos_emb) else always(0)\n        self.emb_dropout = nn.Dropout(emb_dropout)\n\n        self.project_emb = nn.Linear(emb_dim, dim) if emb_dim != dim else nn.Identity()\n        self.attn_layers = attn_layers\n        self.norm = nn.LayerNorm(dim)\n\n        self.init_()\n\n        self.to_logits = nn.Linear(dim, num_tokens) if not tie_embedding else lambda t: t @ self.token_emb.weight.t()\n\n        # memory tokens (like [cls]) from Memory Transformers paper\n        num_memory_tokens = default(num_memory_tokens, 0)\n        self.num_memory_tokens = num_memory_tokens\n        if num_memory_tokens > 0:\n            self.memory_tokens = nn.Parameter(torch.randn(num_memory_tokens, dim))\n\n            # let funnel encoder know number of memory tokens, if specified\n            if hasattr(attn_layers, \'num_memory_tokens\'):\n                attn_layers.num_memory_tokens = num_memory_tokens\n\n    def init_(self):\n        nn.init.normal_(self.token_emb.weight, std=0.02)\n\n    def forward(\n            self,\n            x,\n            return_embeddings=False,\n            mask=None,\n            return_mems=False,\n            return_attn=False,\n            mems=None,\n            **kwargs\n    ):\n        b, n, device, num_mem = *x.shape, x.device, self.num_memory_tokens\n        x = self.token_emb(x)\n        x += self.pos_emb(x)\n        x = self.emb_dropout(x)\n\n        x = self.project_emb(x)\n\n        if num_mem > 0:\n            mem = repeat(self.memory_tokens, \'n d -> b n d\', b=b)\n            x = torch.cat((mem, x), dim=1)\n\n            # auto-handle masking after appending memory tokens\n            if exists(mask):\n                mask = F.pad(mask, (num_mem, 0), value=True)\n\n        x, intermediates = self.attn_layers(x, mask=mask, mems=mems, return_hiddens=True, **kwargs)\n        x = self.norm(x)\n\n        mem, x = x[:, :num_mem], x[:, num_mem:]\n\n        out = self.to_logits(x) if not return_embeddings else x\n\n        if return_mems:\n            hiddens = intermediates.hiddens\n            new_mems = list(map(lambda pair: torch.cat(pair, dim=-2), zip(mems, hiddens))) if exists(mems) else hiddens\n            new_mems = list(map(lambda t: t[..., -self.max_mem_len:, :].detach(), new_mems))\n            return out, new_mems\n\n        if return_attn:\n            attn_maps = list(map(lambda t: t.post_softmax_attn, intermediates.attn_intermediates))\n            return out, attn_maps\n\n        return out\n\n',
    'model.ldm.util': 'import importlib\n\nimport torch\nimport numpy as np\nfrom collections import abc\nfrom einops import rearrange\nfrom functools import partial\n\nimport multiprocessing as mp\nfrom threading import Thread\nfrom queue import Queue\n\nfrom inspect import isfunction\nfrom PIL import Image, ImageDraw, ImageFont\n\n\ndef log_txt_as_img(wh, xc, size=10):\n    # wh a tuple of (width, height)\n    # xc a list of captions to plot\n    b = len(xc)\n    txts = list()\n    for bi in range(b):\n        txt = Image.new("RGB", wh, color="white")\n        draw = ImageDraw.Draw(txt)\n        font = ImageFont.truetype(\'data/DejaVuSans.ttf\', size=size)\n        nc = int(40 * (wh[0] / 256))\n        lines = "\\n".join(xc[bi][start:start + nc] for start in range(0, len(xc[bi]), nc))\n\n        try:\n            draw.text((0, 0), lines, fill="black", font=font)\n        except UnicodeEncodeError:\n            print("Cant encode string for logging. Skipping.")\n\n        txt = np.array(txt).transpose(2, 0, 1) / 127.5 - 1.0\n        txts.append(txt)\n    txts = np.stack(txts)\n    txts = torch.tensor(txts)\n    return txts\n\n\ndef ismap(x):\n    if not isinstance(x, torch.Tensor):\n        return False\n    return (len(x.shape) == 4) and (x.shape[1] > 3)\n\n\ndef isimage(x):\n    if not isinstance(x, torch.Tensor):\n        return False\n    return (len(x.shape) == 4) and (x.shape[1] == 3 or x.shape[1] == 1)\n\n\ndef exists(x):\n    return x is not None\n\n\ndef default(val, d):\n    if exists(val):\n        return val\n    return d() if isfunction(d) else d\n\n\ndef mean_flat(tensor):\n    """\n    https://github.com/openai/guided-diffusion/blob/27c20a8fab9cb472df5d6bdd6c8d11c8f430b924/guided_diffusion/nn.py#L86\n    Take the mean over all non-batch dimensions.\n    """\n    return tensor.mean(dim=list(range(1, len(tensor.shape))))\n\n\ndef count_params(model, verbose=False):\n    total_params = sum(p.numel() for p in model.parameters())\n    if verbose:\n        print(f"{model.__class__.__name__} has {total_params * 1.e-6:.2f} M params.")\n    return total_params\n\n\ndef instantiate_from_config(config):\n    if not "target" in config:\n        if config == \'__is_first_stage__\':\n            return None\n        elif config == "__is_unconditional__":\n            return None\n        raise KeyError("Expected key `target` to instantiate.")\n    return get_obj_from_str(config["target"])(**config.get("params", dict()))\n\n\ndef get_obj_from_str(string, reload=False):\n    module, cls = string.rsplit(".", 1)\n    if reload:\n        module_imp = importlib.import_module(module)\n        importlib.reload(module_imp)\n    return getattr(importlib.import_module(module, package=None), cls)\n\n\ndef _do_parallel_data_prefetch(func, Q, data, idx, idx_to_fn=False):\n    # create dummy dataset instance\n\n    # run prefetching\n    if idx_to_fn:\n        res = func(data, worker_id=idx)\n    else:\n        res = func(data)\n    Q.put([idx, res])\n    Q.put("Done")\n\n\ndef parallel_data_prefetch(\n        func: callable, data, n_proc, target_data_type="ndarray", cpu_intensive=True, use_worker_id=False\n):\n    # if target_data_type not in ["ndarray", "list"]:\n    #     raise ValueError(\n    #         "Data, which is passed to parallel_data_prefetch has to be either of type list or ndarray."\n    #     )\n    if isinstance(data, np.ndarray) and target_data_type == "list":\n        raise ValueError("list expected but function got ndarray.")\n    elif isinstance(data, abc.Iterable):\n        if isinstance(data, dict):\n            print(\n                f\'WARNING:"data" argument passed to parallel_data_prefetch is a dict: Using only its values and disregarding keys.\'\n            )\n            data = list(data.values())\n        if target_data_type == "ndarray":\n            data = np.asarray(data)\n        else:\n            data = list(data)\n    else:\n        raise TypeError(\n            f"The data, that shall be processed parallel has to be either an np.ndarray or an Iterable, but is actually {type(data)}."\n        )\n\n    if cpu_intensive:\n        Q = mp.Queue(1000)\n        proc = mp.Process\n    else:\n        Q = Queue(1000)\n        proc = Thread\n    # spawn processes\n    if target_data_type == "ndarray":\n        arguments = [\n            [func, Q, part, i, use_worker_id]\n            for i, part in enumerate(np.array_split(data, n_proc))\n        ]\n    else:\n        step = (\n            int(len(data) / n_proc + 1)\n            if len(data) % n_proc != 0\n            else int(len(data) / n_proc)\n        )\n        arguments = [\n            [func, Q, part, i, use_worker_id]\n            for i, part in enumerate(\n                [data[i: i + step] for i in range(0, len(data), step)]\n            )\n        ]\n    processes = []\n    for i in range(n_proc):\n        p = proc(target=_do_parallel_data_prefetch, args=arguments[i])\n        processes += [p]\n\n    # start processes\n    print(f"Start prefetching...")\n    import time\n\n    start = time.time()\n    gather_res = [[] for _ in range(n_proc)]\n    try:\n        for p in processes:\n            p.start()\n\n        k = 0\n        while k < n_proc:\n            # get result\n            res = Q.get()\n            if res == "Done":\n                k += 1\n            else:\n                gather_res[res[0]] = res[1]\n\n    except Exception as e:\n        print("Exception: ", e)\n        for p in processes:\n            p.terminate()\n\n        raise e\n    finally:\n        for p in processes:\n            p.join()\n        print(f"Prefetching complete. [{time.time() - start} sec.]")\n\n    if target_data_type == \'ndarray\':\n        if not isinstance(gather_res[0], np.ndarray):\n            return np.concatenate([np.asarray(r) for r in gather_res], axis=0)\n\n        # order outputs\n        return np.concatenate(gather_res, axis=0)\n    elif target_data_type == \'list\':\n        out = []\n        for r in gather_res:\n            out.extend(r)\n        return out\n    else:\n        return gather_res\n',
    'model.precond': '# Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n#\n# This work is licensed under a Creative Commons\n# Attribution-NonCommercial-ShareAlike 4.0 International License.\n# You should have received a copy of the license along with this\n# work. If not, see http://creativecommons.org/licenses/by-nc-sa/4.0/\n\n"""Model architectures and preconditioning schemes used in the paper\n"Elucidating the Design Space of Diffusion-Based Generative Models"."""\n\nimport numpy as np\nimport torch\nfrom torch.nn.functional import silu\n\n\n#----------------------------------------------------------------------------\n# Preconditioning corresponding to the variance preserving (VP) formulation\n# from the paper "Score-Based Generative Modeling through Stochastic\n# Differential Equations".\n\nclass VPPrecond(torch.nn.Module):\n    def __init__(self,\n        label_dim       = 0,            # Number of class labels, 0 = unconditional.\n        use_fp16        = False,        # Execute the underlying model at FP16 precision?\n        beta_d          = 19.9,         # Extent of the noise level schedule.\n        beta_min        = 0.1,          # Initial slope of the noise level schedule.\n        M               = 1000,         # Original number of timesteps in the DDPM formulation.\n        model           = None,         # Diffusion model.\n        conditional     = False,        # Use conditional model?\n        learn_sigma     = False,        # Learnable noise level?\n    ):\n        super().__init__()\n        self.label_dim = label_dim\n        self.use_fp16 = use_fp16\n        self.beta_d = beta_d\n        self.beta_min = beta_min\n        self.M = M\n        self.model = model\n        self.conditional = conditional\n        self.learn_sigma = learn_sigma\n\n    def forward(self, x, sigma, class_labels=None, force_fp32=False, **model_kwargs):\n        x = x.to(torch.float32)\n        sigma = sigma.to(torch.float32).reshape(-1, 1, 1, 1)\n        # class_labels = None if self.label_dim == 0 else torch.zeros([1, self.label_dim], device=x.device) if class_labels is None else class_labels.to(torch.float32).reshape(-1, self.label_dim)\n        dtype = torch.float16 if (self.use_fp16 and not force_fp32 and x.device.type == \'cuda\') else torch.float32\n\n        c_skip = 1\n        c_out = -sigma\n        c_in = 1 / (sigma ** 2 + 1).sqrt()\n        c_noise = (self.M - 1) * self.sigma_inv(sigma)\n\n        if self.conditional:\n            F_x = self.model((c_in * x).to(dtype), c_noise.flatten(), class_labels=class_labels, **model_kwargs)\n        else:\n            F_x = self.model((c_in * x).to(dtype), c_noise.flatten(), **model_kwargs)\n        if self.learn_sigma:\n            F_x, _ = torch.split(F_x, x.shape[1], dim=1)\n        assert F_x.dtype == dtype\n        D_x = c_skip * x + c_out * F_x.to(torch.float32)\n        return D_x\n\n    def sigma(self, t):\n        t = torch.as_tensor(t)\n        return ((0.5 * self.beta_d * (t ** 2) + self.beta_min * t).exp() - 1).sqrt()\n\n    def sigma_inv(self, sigma):\n        sigma = torch.as_tensor(sigma)\n        return ((self.beta_min ** 2 + 2 * self.beta_d * (1 + sigma ** 2).log()).sqrt() - self.beta_min) / self.beta_d\n\n    def round_sigma(self, sigma):\n        return torch.as_tensor(sigma)\n\n#----------------------------------------------------------------------------\n# Preconditioning corresponding to the variance exploding (VE) formulation\n# from the paper "Score-Based Generative Modeling through Stochastic\n# Differential Equations".\n\nclass VEPrecond(torch.nn.Module):\n    def __init__(self,\n        label_dim       = 0,            # Number of class labels, 0 = unconditional.\n        use_fp16        = False,        # Execute the underlying model at FP16 precision?\n        model           = None,          # Diffusion model.\n    ):\n        super().__init__()\n        self.label_dim = label_dim\n        self.use_fp16 = use_fp16\n        self.model = model\n\n    def forward(self, x, sigma, class_labels=None, force_fp32=False, **model_kwargs):\n        x = x.to(torch.float32)\n        sigma = sigma.to(torch.float32).reshape(-1, 1, 1, 1)\n        class_labels = None if self.label_dim == 0 else torch.zeros([1, self.label_dim], device=x.device) if class_labels is None else class_labels.to(torch.float32).reshape(-1, self.label_dim)\n        dtype = torch.float16 if (self.use_fp16 and not force_fp32 and x.device.type == \'cuda\') else torch.float32\n\n        c_skip = 1\n        c_out = sigma\n        c_in = 1\n        c_noise = (0.5 * sigma).log()\n\n        F_x = self.model((c_in * x).to(dtype), c_noise.flatten(), class_labels=class_labels, **model_kwargs)\n        assert F_x.dtype == dtype\n        D_x = c_skip * x + c_out * F_x.to(torch.float32)\n        return D_x\n\n    def round_sigma(self, sigma):\n        return torch.as_tensor(sigma)\n\n#----------------------------------------------------------------------------\n# Preconditioning corresponding to improved DDPM (iDDPM) formulation from\n# the paper "Improved Denoising Diffusion Probabilistic Models".\n\nclass iDDPMPrecond(torch.nn.Module):\n    def __init__(self,\n        img_resolution,                     # Image resolution.\n        img_channels,                       # Number of color channels.\n        label_dim       = 0,                # Number of class labels, 0 = unconditional.\n        use_fp16        = False,            # Execute the underlying model at FP16 precision?\n        C_1             = 0.001,            # Timestep adjustment at low noise levels.\n        C_2             = 0.008,            # Timestep adjustment at high noise levels.\n        M               = 1000,             # Original number of timesteps in the DDPM formulation.\n        model_type      = \'DhariwalUNet\',   # Class name of the underlying model.\n        **model_kwargs,                     # Keyword arguments for the underlying model.\n    ):\n        super().__init__()\n        self.img_resolution = img_resolution\n        self.img_channels = img_channels\n        self.label_dim = label_dim\n        self.use_fp16 = use_fp16\n        self.C_1 = C_1\n        self.C_2 = C_2\n        self.M = M\n        self.model = globals()[model_type](img_resolution=img_resolution, in_channels=img_channels, out_channels=img_channels*2, label_dim=label_dim, **model_kwargs)\n\n        u = torch.zeros(M + 1)\n        for j in range(M, 0, -1): # M, ..., 1\n            u[j - 1] = ((u[j] ** 2 + 1) / (self.alpha_bar(j - 1) / self.alpha_bar(j)).clip(min=C_1) - 1).sqrt()\n        self.register_buffer(\'u\', u)\n        self.sigma_min = float(u[M - 1])\n        self.sigma_max = float(u[0])\n\n    def forward(self, x, sigma, class_labels=None, force_fp32=False, **model_kwargs):\n        x = x.to(torch.float32)\n        sigma = sigma.to(torch.float32).reshape(-1, 1, 1, 1)\n        class_labels = None if self.label_dim == 0 else torch.zeros([1, self.label_dim], device=x.device) if class_labels is None else class_labels.to(torch.float32).reshape(-1, self.label_dim)\n        dtype = torch.float16 if (self.use_fp16 and not force_fp32 and x.device.type == \'cuda\') else torch.float32\n\n        c_skip = 1\n        c_out = -sigma\n        c_in = 1 / (sigma ** 2 + 1).sqrt()\n        c_noise = self.M - 1 - self.round_sigma(sigma, return_index=True).to(torch.float32)\n\n        F_x = self.model((c_in * x).to(dtype), c_noise.flatten(), class_labels=class_labels, **model_kwargs)\n        assert F_x.dtype == dtype\n        D_x = c_skip * x + c_out * F_x[:, :self.img_channels].to(torch.float32)\n        return D_x\n\n    def alpha_bar(self, j):\n        j = torch.as_tensor(j)\n        return (0.5 * np.pi * j / self.M / (self.C_2 + 1)).sin() ** 2\n\n    def round_sigma(self, sigma, return_index=False):\n        sigma = torch.as_tensor(sigma)\n        index = torch.cdist(sigma.to(self.u.device).to(torch.float32).reshape(1, -1, 1), self.u.reshape(1, -1, 1)).argmin(2)\n        result = index if return_index else self.u[index.flatten()].to(sigma.dtype)\n        return result.reshape(sigma.shape).to(sigma.device)\n\n#----------------------------------------------------------------------------\n# Improved preconditioning proposed in the paper "Elucidating the Design\n# Space of Diffusion-Based Generative Models" (EDM).\n\nclass EDMPrecond(torch.nn.Module):\n    def __init__(self,\n        img_resolution,                     # Image resolution.\n        img_channels,                       # Number of color channels.\n        label_dim       = 0,                # Number of class labels, 0 = unconditional.\n        use_fp16        = False,            # Execute the underlying model at FP16 precision?\n        sigma_min       = 0,                # Minimum supported noise level.\n        sigma_max       = float(\'inf\'),     # Maximum supported noise level.\n        sigma_data      = 0.5,              # Expected standard deviation of the training data.\n        model_type      = \'DhariwalUNet\',   # Class name of the underlying model.\n        **model_kwargs,                     # Keyword arguments for the underlying model.\n    ):\n        super().__init__()\n        self.img_resolution = img_resolution\n        self.img_channels = img_channels\n        self.label_dim = label_dim\n        self.use_fp16 = use_fp16\n        self.sigma_min = sigma_min\n        self.sigma_max = sigma_max\n        self.sigma_data = sigma_data\n        self.model = globals()[model_type](img_resolution=img_resolution, in_channels=img_channels, out_channels=img_channels, label_dim=label_dim, **model_kwargs)\n\n    def forward(self, x, sigma, class_labels=None, force_fp32=False, **model_kwargs):\n        x = x.to(torch.float32)\n        sigma = sigma.to(torch.float32).reshape(-1, 1, 1, 1)\n        class_labels = None if self.label_dim == 0 else torch.zeros([1, self.label_dim], device=x.device) if class_labels is None else class_labels.to(torch.float32).reshape(-1, self.label_dim)\n        dtype = torch.float16 if (self.use_fp16 and not force_fp32 and x.device.type == \'cuda\') else torch.float32\n\n        c_skip = self.sigma_data ** 2 / (sigma ** 2 + self.sigma_data ** 2)\n        c_out = sigma * self.sigma_data / (sigma ** 2 + self.sigma_data ** 2).sqrt()\n        c_in = 1 / (self.sigma_data ** 2 + sigma ** 2).sqrt()\n        c_noise = sigma.log() / 4\n\n        F_x = self.model((c_in * x).to(dtype), c_noise.flatten(), class_labels=class_labels, **model_kwargs)\n        assert F_x.dtype == dtype\n        D_x = c_skip * x + c_out * F_x.to(torch.float32)\n        return D_x\n\n    def round_sigma(self, sigma):\n        return torch.as_tensor(sigma)\n\n#----------------------------------------------------------------------------\n\nclass LatentDMWrapper(torch.nn.Module):\n    """\n    Wrapper class for latent diffusion models.\n\n    Attributes:\n        model (torch.nn.Module): \n            The underlying latent diffusion model.\n    """\n    def __init__(self, model):\n        super().__init__()\n        self.model = model\n\n    def decode(self, z0):\n        return self.model.differentiable_decode_first_stage(z0)\n    \n    def encode(self, x0):\n        return self.model.encode_first_stage(x0)\n    \n    def forward(self, z, t, class_labels=None):\n        return self.model.apply_model(z, t, class_labels)\n    \n    def get_condition(self, class_labels):\n        uc = self.model.get_learned_conditioning({self.model.cond_stage_key: class_labels})\n        return uc',
}

# Install importer at import time (idempotent).
_install_embedded_importer()
